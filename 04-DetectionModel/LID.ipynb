{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13433792,"sourceType":"datasetVersion","datasetId":8526629}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\nimport joblib\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n    confusion_matrix, classification_report\n)\n\n\ndef _save_json(p, obj):\n    p.parent.mkdir(parents=True, exist_ok=True)\n    with open(p, \"w\") as f:\n        json.dump(obj, f, indent=2)\n\n\ndef train_from_npy(\n    train_npy_path,\n    model_out_dir,\n    train_labels_npy_path,\n    random_seed=42,\n    mem_limit_bytes=100_000_000_000,\n    use_mmap=False,\n    classifier='LogisticRegression'\n):\n    train_npy_path = Path(train_npy_path)\n    if not train_npy_path.exists():\n        raise FileNotFoundError(f\"Train npy not found: {train_npy_path}\")\n\n    model_out_dir = Path(model_out_dir)\n    model_out_dir.mkdir(parents=True, exist_ok=True)\n\n    X_train = np.load(str(train_npy_path), mmap_mode=\"r\" if use_mmap else None)\n    if X_train.ndim != 2:\n        raise RuntimeError(f\"train array must be 2D. got shape={X_train.shape}\")\n\n    labels_path = Path(train_labels_npy_path)\n    if not labels_path.exists():\n        raise FileNotFoundError(f\"Provided train_labels_npy_path does not exist: {labels_path}\")\n    y_train = np.load(str(labels_path), mmap_mode=\"r\" if use_mmap else None)\n    if y_train.shape[0] != X_train.shape[0]:\n        raise RuntimeError(f\"train labels length ({y_train.shape[0]}) != train rows ({X_train.shape[0]})\")\n\n    y_train = y_train.astype(np.int64)\n    unique = np.unique(y_train)\n    if unique.size != 2 or not np.array_equal(np.sort(unique), np.array([0, 1])):\n        raise RuntimeError(f\"train labels must contain exactly two classes 0 and 1. found: {unique}\")\n    y_train = y_train.astype(np.uint8)\n\n    estimated_bytes = getattr(X_train, \"nbytes\", X_train.size * X_train.itemsize)\n    if estimated_bytes > mem_limit_bytes:\n        raise MemoryError(\n            f\"Estimated train bytes {estimated_bytes} > mem_limit_bytes {mem_limit_bytes}. \"\n            \"Either increase mem_limit_bytes, reduce dataset size, or use use_mmap=True and implement chunked/out-of-core training.\"\n        )\n\n    scaler = MinMaxScaler()\n\n    if classifier == 'LogisticRegression':\n        print ('Using LogisticRegression as classifier')\n        clf = LogisticRegression(random_state=random_seed, n_jobs=-1, verbose=1)\n    elif classifier == 'RandomForest':\n        print ('Using RandomForest as classifier')\n        clf = RandomForestClassifier(random_state=random_seed, n_jobs=-1, verbose=1)\n    else:\n        print ('Using SVC as classifier')\n        clf = SVC(random_state=random_seed, verbose=0)\n\n    pipeline = Pipeline([(\"scaler\", scaler), (\"clf\", clf)])\n\n    print(f\"Fitting pipeline\")\n    pipeline.fit(X_train, y_train)\n\n    try:\n        y_pred_train, y_score_train = _predict_and_score(pipeline, None, None, X_train)\n        train_metrics = _compute_metrics(y_train, y_pred_train, y_score_train)\n\n        print(\"TRAIN Eval results:\")\n        print(f\"  acc={train_metrics['accuracy']:.4f}  prec={train_metrics['precision']:.4f}  \"\n              f\"recall={train_metrics['recall']:.4f}  f1={train_metrics['f1']:.4f}\")\n        if train_metrics.get(\"roc_auc\") is not None:\n            print(f\"  roc_auc={train_metrics['roc_auc']:.4f}\")\n        print(\"  confusion_matrix:\", train_metrics[\"confusion_matrix\"])\n    except Exception as e:\n\n        print(\"Warning: failed to compute train metrics:\", e)\n        train_metrics = None\n\n    pipeline_path = model_out_dir / \"pipeline.joblib\"\n    scaler_path = model_out_dir / \"scaler.joblib\"\n    clf_path = model_out_dir / \"clf.joblib\"\n    meta_out = model_out_dir / \"train_meta.json\"\n\n    joblib.dump(pipeline, pipeline_path)\n    joblib.dump(pipeline.named_steps[\"scaler\"], scaler_path)\n    joblib.dump(pipeline.named_steps[\"clf\"], clf_path)\n\n    meta_obj = {\n        \"train_npy\": str(train_npy_path),\n        \"train_labels_npy\": str(train_labels_npy_path),\n        \"train_rows\": int(X_train.shape[0]),\n        \"C\": None,\n        \"random_seed\": int(random_seed),\n        \"use_mmap\": bool(use_mmap),\n        \"train_metrics\": train_metrics,\n    }\n    _save_json(meta_out, meta_obj)\n\n    print(\"Saved pipeline ->\", pipeline_path)\n    print(\"Saved scaler ->\", scaler_path)\n    print(\"Saved classifier ->\", clf_path)\n    return str(model_out_dir)\n\ndef _load_model(model_out_dir):\n    model_out_dir = Path(model_out_dir)\n    pipeline_path = model_out_dir / \"pipeline.joblib\"\n    scaler_path = model_out_dir / \"scaler.joblib\"\n    clf_path = model_out_dir / \"clf.joblib\"\n\n    pipeline = None\n    scaler = None\n    clf = None\n\n    if pipeline_path.exists():\n        pipeline = joblib.load(pipeline_path)\n    else:\n        if scaler_path.exists():\n            scaler = joblib.load(scaler_path)\n        if clf_path.exists():\n            clf = joblib.load(clf_path)\n        if scaler is None or clf is None:\n            raise FileNotFoundError(\"Could not find pipeline or scaler+clf in model_out_dir.\")\n    return pipeline, scaler, clf\n\n\ndef _compute_metrics(y_true, y_pred, y_score):\n    metrics = {}\n    metrics[\"accuracy\"] = float(accuracy_score(y_true, y_pred))\n    metrics[\"precision\"] = float(precision_score(y_true, y_pred, zero_division=0))\n    metrics[\"recall\"] = float(recall_score(y_true, y_pred, zero_division=0))\n    metrics[\"f1\"] = float(f1_score(y_true, y_pred, zero_division=0))\n    try:\n        if y_score is not None and len(np.unique(y_true)) == 2:\n            metrics[\"roc_auc\"] = float(roc_auc_score(y_true, y_score))\n        else:\n            metrics[\"roc_auc\"] = None\n    except Exception:\n        metrics[\"roc_auc\"] = None\n    metrics[\"confusion_matrix\"] = confusion_matrix(y_true, y_pred).tolist()\n    metrics[\"classification_report\"] = classification_report(y_true, y_pred, zero_division=0, output_dict=True)\n    return metrics\n\n\ndef _predict_and_score(pipeline, scaler, clf, X_test):\n    y_score = None\n    if pipeline is not None:\n        y_pred = pipeline.predict(X_test)\n        if hasattr(pipeline, \"predict_proba\"):\n            try:\n                y_score = pipeline.predict_proba(X_test)[:, 1]\n            except Exception:\n                y_score = None\n        else:\n            try:\n                clf_ = pipeline.named_steps[\"clf\"]\n                scaler_ = pipeline.named_steps[\"scaler\"]\n                if hasattr(clf_, \"decision_function\"):\n                    y_score = clf_.decision_function(scaler_.transform(X_test))\n            except Exception:\n                y_score = None\n    else:\n        X_t = scaler.transform(X_test)\n        y_pred = clf.predict(X_t)\n        if hasattr(clf, \"predict_proba\"):\n            y_score = clf.predict_proba(X_t)[:, 1]\n        elif hasattr(clf, \"decision_function\"):\n            y_score = clf.decision_function(X_t)\n    return y_pred, y_score\n\n\ndef eval_val_from_npy(\n    val_npy_path,\n    val_label_path,\n    model_out_dir=\"./models\",\n    return_predictions=False,\n    use_mmap=False,\n    csv_path=None, \n):\n    val_npy_path = Path(val_npy_path)\n    val_label_path = Path(val_label_path)\n    if not val_npy_path.exists():\n        raise FileNotFoundError(f\"val_npy not found: {val_npy_path}\")\n\n    X_test = np.load(str(val_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n    y_test = np.load(str(val_label_path), mmap_mode=\"r\" if use_mmap else None).astype(np.uint8)\n    \n    if X_test.shape[0] != y_test.shape[0]:\n        raise RuntimeError(f\"val X rows ({X_test.shape[0]}) != val labels length ({y_test.shape[0]})\")\n\n    pipeline, scaler, clf = _load_model(model_out_dir)\n\n    y_pred, y_score = _predict_and_score(pipeline, scaler, clf, X_test)\n\n    metrics = _compute_metrics(y_test, y_pred, y_score)\n\n    print(\"VAL Eval results:\")\n    print(f\"  acc={metrics['accuracy']:.4f}  prec={metrics['precision']:.4f}  recall={metrics['recall']:.4f}  f1={metrics['f1']:.4f}\")\n    if metrics[\"roc_auc\"] is not None:\n        print(f\"  roc_auc={metrics['roc_auc']:.4f}\")\n    print(\"  confusion_matrix:\", metrics[\"confusion_matrix\"])\n\n    if csv_path is not None:\n        csv_path = Path(csv_path)\n        csv_path.parent.mkdir(parents=True, exist_ok=True)\n\n        metrics_df = pd.DataFrame([metrics])\n        metrics_df.to_csv(csv_path, index=False)\n\n        if return_predictions:\n            preds_path = csv_path.with_name(csv_path.stem + \"_predictions.csv\")\n            preds_df = pd.DataFrame({\n                \"y_true\": y_test,\n                \"y_pred\": y_pred,\n                \"y_score\": y_score\n            })\n            preds_df.to_csv(preds_path, index=False)\n            print(f\"Predictions saved to: {preds_path}\")\n\n        print(f\"Metrics saved to: {csv_path}\")\n\n    return {\n        \"metrics\": metrics,\n        \"y_true\": y_test if return_predictions else None,\n        \"y_pred\": y_pred if return_predictions else None,\n        \"y_score\": y_score if return_predictions else None,\n    }\n\n\ndef eval_test_from_npy(\n    test_clean_npy_path,\n    test_adv_npy_path=None,\n    model_out_dir=\"./models\",\n    test_labels_npy_path=None,\n    return_predictions=False,\n    use_mmap=False,\n    csv_path=None,  \n):\n    test_clean_npy_path = Path(test_clean_npy_path)\n    if not test_clean_npy_path.exists():\n        raise FileNotFoundError(f\"test_clean npy not found: {test_clean_npy_path}\")\n\n    if test_adv_npy_path is None:\n        if test_labels_npy_path is None:\n            raise ValueError(\"Single-file mode requires test_labels_npy_path.\")\n        X_test = np.load(str(test_clean_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n        y_test = np.load(str(test_labels_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.uint8)\n        if X_test.shape[0] != y_test.shape[0]:\n            raise RuntimeError(f\"test X rows ({X_test.shape[0]}) != test labels length ({y_test.shape[0]})\")\n    else:\n        test_adv_npy_path = Path(test_adv_npy_path)\n        if not test_adv_npy_path.exists():\n            raise FileNotFoundError(f\"test_adv npy not found: {test_adv_npy_path}\")\n        X_clean = np.load(str(test_clean_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n        X_adv = np.load(str(test_adv_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n        X_test = np.vstack([X_clean, X_adv])\n        if test_labels_npy_path is not None:\n            y_test = np.load(str(test_labels_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.uint8)\n            if y_test.shape[0] != X_test.shape[0]:\n                raise RuntimeError(f\"test labels length ({y_test.shape[0]}) != stacked test rows ({X_test.shape[0]})\")\n        else:\n            y_test = np.concatenate([\n                np.zeros(X_clean.shape[0], dtype=np.uint8),\n                np.ones(X_adv.shape[0], dtype=np.uint8)\n            ])\n\n    pipeline, scaler, clf = _load_model(model_out_dir)\n    y_pred, y_score = _predict_and_score(pipeline, scaler, clf, X_test)\n    metrics = _compute_metrics(y_test, y_pred, y_score)\n\n    print(\"TEST Eval results:\")\n    print(f\"  acc={metrics['accuracy']:.4f}  prec={metrics['precision']:.4f}  recall={metrics['recall']:.4f}  f1={metrics['f1']:.4f}\")\n    if metrics[\"roc_auc\"] is not None:\n        print(f\"  roc_auc={metrics['roc_auc']:.4f}\")\n\n    if csv_path is not None:\n        csv_path = Path(csv_path)\n        csv_path.parent.mkdir(parents=True, exist_ok=True)\n\n        metrics_df = pd.DataFrame([metrics])\n        metrics_df.to_csv(csv_path, index=False)\n\n        if return_predictions:\n            preds_path = csv_path.with_name(csv_path.stem + \"_predictions.csv\")\n            preds_df = pd.DataFrame({\n                \"y_true\": y_test,\n                \"y_pred\": y_pred,\n                \"y_score\": y_score\n            })\n            preds_df.to_csv(preds_path, index=False)\n            print(f\"Predictions saved to: {preds_path}\")\n\n        print(f\"Metrics saved to: {csv_path}\")\n\n    return None\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-20T11:21:29.510922Z","iopub.execute_input":"2025-10-20T11:21:29.511295Z","iopub.status.idle":"2025-10-20T11:21:30.950522Z","shell.execute_reply.started":"2025-10-20T11:21:29.511261Z","shell.execute_reply":"2025-10-20T11:21:30.949606Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"IMG_SIZES = [32, 64, 128, 256, 512, 1024]\nATTACKS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\nclassifiers = ['LogisticRegression', 'RandomForest']\nfor IMG_SIZE in IMG_SIZES:\n    print(f'Image Size: {IMG_SIZE} \\n')\n    for classifier in classifiers:\n        print(f'Classifier: {classifier} \\n')\n        for ATTACK in ATTACKS:\n            print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n            train_from_npy( train_npy_path = f\"/kaggle/input/detectlid/Dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_raw.npy\",\n                            model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n                            train_labels_npy_path=f\"/kaggle/input/detectlid/Dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_labels.npy\",\n                            random_seed=42,\n                            use_mmap=False,\n                            classifier = classifier)\n            print ('_________________________________\\n')\n        print ('==============================\\n')\n    print ('++++++++++++++++++++++++++++++++++\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T14:38:21.365566Z","iopub.execute_input":"2025-10-19T14:38:21.365916Z","iopub.status.idle":"2025-10-19T14:38:44.861744Z","shell.execute_reply.started":"2025-10-19T14:38:21.365891Z","shell.execute_reply":"2025-10-19T14:38:44.860469Z"}},"outputs":[{"name":"stdout","text":"Image Size: 32 \n\nClassifier: LogisticRegression \n\nTraining: 32 - fgsm - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=0.5350  prec=0.5403  recall=0.4691  f1=0.5022\n  roc_auc=0.5613\n  confusion_matrix: [[292, 194], [258, 228]]\nSaved pipeline -> models/fgsm-32-LogisticRegression/pipeline.joblib\nSaved scaler -> models/fgsm-32-LogisticRegression/scaler.joblib\nSaved classifier -> models/fgsm-32-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 32 - bim - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=0.6543  prec=0.7206  recall=0.5041  f1=0.5932\n  roc_auc=0.7244\n  confusion_matrix: [[391, 95], [241, 245]]\nSaved pipeline -> models/bim-32-LogisticRegression/pipeline.joblib\nSaved scaler -> models/bim-32-LogisticRegression/scaler.joblib\nSaved classifier -> models/bim-32-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 32 - pgd - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=0.6903  prec=0.8013  recall=0.5062  f1=0.6204\n  roc_auc=0.7485\n  confusion_matrix: [[425, 61], [240, 246]]\nSaved pipeline -> models/pgd-32-LogisticRegression/pipeline.joblib\nSaved scaler -> models/pgd-32-LogisticRegression/scaler.joblib\nSaved classifier -> models/pgd-32-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 32 - df - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=0.5319  prec=0.5232  recall=0.7181  f1=0.6054\n  roc_auc=0.5439\n  confusion_matrix: [[168, 318], [137, 349]]\nSaved pipeline -> models/df-32-LogisticRegression/pipeline.joblib\nSaved scaler -> models/df-32-LogisticRegression/scaler.joblib\nSaved classifier -> models/df-32-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 32 - cw - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.5247  prec=0.5180  recall=0.7119  f1=0.5997\n  roc_auc=0.5350\n  confusion_matrix: [[164, 322], [140, 346]]\nSaved pipeline -> models/cw-32-LogisticRegression/pipeline.joblib\nSaved scaler -> models/cw-32-LogisticRegression/scaler.joblib\nSaved classifier -> models/cw-32-LogisticRegression/clf.joblib\n_________________________________\n\n==============================\n\nClassifier: RandomForest \n\nTraining: 32 - fgsm - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/fgsm-32-RandomForest/pipeline.joblib\nSaved scaler -> models/fgsm-32-RandomForest/scaler.joblib\nSaved classifier -> models/fgsm-32-RandomForest/clf.joblib\n_________________________________\n\nTraining: 32 - bim - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/bim-32-RandomForest/pipeline.joblib\nSaved scaler -> models/bim-32-RandomForest/scaler.joblib\nSaved classifier -> models/bim-32-RandomForest/clf.joblib\n_________________________________\n\nTraining: 32 - pgd - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/pgd-32-RandomForest/pipeline.joblib\nSaved scaler -> models/pgd-32-RandomForest/scaler.joblib\nSaved classifier -> models/pgd-32-RandomForest/clf.joblib\n_________________________________\n\nTraining: 32 - df - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/df-32-RandomForest/pipeline.joblib\nSaved scaler -> models/df-32-RandomForest/scaler.joblib\nSaved classifier -> models/df-32-RandomForest/clf.joblib\n_________________________________\n\nTraining: 32 - cw - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/cw-32-RandomForest/pipeline.joblib\nSaved scaler -> models/cw-32-RandomForest/scaler.joblib\nSaved classifier -> models/cw-32-RandomForest/clf.joblib\n_________________________________\n\n==============================\n\n++++++++++++++++++++++++++++++++++\n\nImage Size: 64 \n\nClassifier: LogisticRegression \n\nTraining: 64 - fgsm - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.5545  prec=0.5678  recall=0.4568  f1=0.5063\n  roc_auc=0.5950\n  confusion_matrix: [[317, 169], [264, 222]]\nSaved pipeline -> models/fgsm-64-LogisticRegression/pipeline.joblib\nSaved scaler -> models/fgsm-64-LogisticRegression/scaler.joblib\nSaved classifier -> models/fgsm-64-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 64 - bim - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=0.7747  prec=0.9293  recall=0.5947  f1=0.7252\n  roc_auc=0.8935\n  confusion_matrix: [[464, 22], [197, 289]]\nSaved pipeline -> models/bim-64-LogisticRegression/pipeline.joblib\nSaved scaler -> models/bim-64-LogisticRegression/scaler.joblib\nSaved classifier -> models/bim-64-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 64 - pgd - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.7757  prec=0.9379  recall=0.5905  f1=0.7247\n  roc_auc=0.9049\n  confusion_matrix: [[467, 19], [199, 287]]\nSaved pipeline -> models/pgd-64-LogisticRegression/pipeline.joblib\nSaved scaler -> models/pgd-64-LogisticRegression/scaler.joblib\nSaved classifier -> models/pgd-64-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 64 - df - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.5576  prec=0.5397  recall=0.7840  f1=0.6393\n  roc_auc=0.5961\n  confusion_matrix: [[161, 325], [105, 381]]\nSaved pipeline -> models/df-64-LogisticRegression/pipeline.joblib\nSaved scaler -> models/df-64-LogisticRegression/scaler.joblib\nSaved classifier -> models/df-64-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 64 - cw - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.5412  prec=0.5281  recall=0.7737  f1=0.6277\n  roc_auc=0.5774\n  confusion_matrix: [[150, 336], [110, 376]]\nSaved pipeline -> models/cw-64-LogisticRegression/pipeline.joblib\nSaved scaler -> models/cw-64-LogisticRegression/scaler.joblib\nSaved classifier -> models/cw-64-LogisticRegression/clf.joblib\n_________________________________\n\n==============================\n\nClassifier: RandomForest \n\nTraining: 64 - fgsm - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/fgsm-64-RandomForest/pipeline.joblib\nSaved scaler -> models/fgsm-64-RandomForest/scaler.joblib\nSaved classifier -> models/fgsm-64-RandomForest/clf.joblib\n_________________________________\n\nTraining: 64 - bim - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/bim-64-RandomForest/pipeline.joblib\nSaved scaler -> models/bim-64-RandomForest/scaler.joblib\nSaved classifier -> models/bim-64-RandomForest/clf.joblib\n_________________________________\n\nTraining: 64 - pgd - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/pgd-64-RandomForest/pipeline.joblib\nSaved scaler -> models/pgd-64-RandomForest/scaler.joblib\nSaved classifier -> models/pgd-64-RandomForest/clf.joblib\n_________________________________\n\nTraining: 64 - df - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/df-64-RandomForest/pipeline.joblib\nSaved scaler -> models/df-64-RandomForest/scaler.joblib\nSaved classifier -> models/df-64-RandomForest/clf.joblib\n_________________________________\n\nTraining: 64 - cw - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/cw-64-RandomForest/pipeline.joblib\nSaved scaler -> models/cw-64-RandomForest/scaler.joblib\nSaved classifier -> models/cw-64-RandomForest/clf.joblib\n_________________________________\n\n==============================\n\n++++++++++++++++++++++++++++++++++\n\nImage Size: 128 \n\nClassifier: LogisticRegression \n\nTraining: 128 - fgsm - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.6214  prec=0.6294  recall=0.5905  f1=0.6093\n  roc_auc=0.6675\n  confusion_matrix: [[317, 169], [199, 287]]\nSaved pipeline -> models/fgsm-128-LogisticRegression/pipeline.joblib\nSaved scaler -> models/fgsm-128-LogisticRegression/scaler.joblib\nSaved classifier -> models/fgsm-128-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 128 - bim - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.8848  prec=0.9722  recall=0.7922  f1=0.8730\n  roc_auc=0.9652\n  confusion_matrix: [[475, 11], [101, 385]]\nSaved pipeline -> models/bim-128-LogisticRegression/pipeline.joblib\nSaved scaler -> models/bim-128-LogisticRegression/scaler.joblib\nSaved classifier -> models/bim-128-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 128 - pgd - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=0.8920  prec=0.9872  recall=0.7942  f1=0.8803\n  roc_auc=0.9754\n  confusion_matrix: [[481, 5], [100, 386]]\nSaved pipeline -> models/pgd-128-LogisticRegression/pipeline.joblib\nSaved scaler -> models/pgd-128-LogisticRegression/scaler.joblib\nSaved classifier -> models/pgd-128-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 128 - df - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.6533  prec=0.6223  recall=0.7798  f1=0.6922\n  roc_auc=0.6773\n  confusion_matrix: [[256, 230], [107, 379]]\nSaved pipeline -> models/df-128-LogisticRegression/pipeline.joblib\nSaved scaler -> models/df-128-LogisticRegression/scaler.joblib\nSaved classifier -> models/df-128-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 128 - cw - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.6337  prec=0.6073  recall=0.7572  f1=0.6740\n  roc_auc=0.6567\n  confusion_matrix: [[248, 238], [118, 368]]\nSaved pipeline -> models/cw-128-LogisticRegression/pipeline.joblib\nSaved scaler -> models/cw-128-LogisticRegression/scaler.joblib\nSaved classifier -> models/cw-128-LogisticRegression/clf.joblib\n_________________________________\n\n==============================\n\nClassifier: RandomForest \n\nTraining: 128 - fgsm - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/fgsm-128-RandomForest/pipeline.joblib\nSaved scaler -> models/fgsm-128-RandomForest/scaler.joblib\nSaved classifier -> models/fgsm-128-RandomForest/clf.joblib\n_________________________________\n\nTraining: 128 - bim - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/bim-128-RandomForest/pipeline.joblib\nSaved scaler -> models/bim-128-RandomForest/scaler.joblib\nSaved classifier -> models/bim-128-RandomForest/clf.joblib\n_________________________________\n\nTraining: 128 - pgd - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/pgd-128-RandomForest/pipeline.joblib\nSaved scaler -> models/pgd-128-RandomForest/scaler.joblib\nSaved classifier -> models/pgd-128-RandomForest/clf.joblib\n_________________________________\n\nTraining: 128 - df - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/df-128-RandomForest/pipeline.joblib\nSaved scaler -> models/df-128-RandomForest/scaler.joblib\nSaved classifier -> models/df-128-RandomForest/clf.joblib\n_________________________________\n\nTraining: 128 - cw - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/cw-128-RandomForest/pipeline.joblib\nSaved scaler -> models/cw-128-RandomForest/scaler.joblib\nSaved classifier -> models/cw-128-RandomForest/clf.joblib\n_________________________________\n\n==============================\n\n++++++++++++++++++++++++++++++++++\n\nImage Size: 256 \n\nClassifier: LogisticRegression \n\nTraining: 256 - fgsm - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.6399  prec=0.6511  recall=0.6029  f1=0.6261\n  roc_auc=0.6838\n  confusion_matrix: [[329, 157], [193, 293]]\nSaved pipeline -> models/fgsm-256-LogisticRegression/pipeline.joblib\nSaved scaler -> models/fgsm-256-LogisticRegression/scaler.joblib\nSaved classifier -> models/fgsm-256-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 256 - bim - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=0.9115  prec=0.9630  recall=0.8560  f1=0.9063\n  roc_auc=0.9743\n  confusion_matrix: [[470, 16], [70, 416]]\nSaved pipeline -> models/bim-256-LogisticRegression/pipeline.joblib\nSaved scaler -> models/bim-256-LogisticRegression/scaler.joblib\nSaved classifier -> models/bim-256-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 256 - pgd - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.8560  prec=0.9240  recall=0.7757  f1=0.8434\n  roc_auc=0.9248\n  confusion_matrix: [[455, 31], [109, 377]]\nSaved pipeline -> models/pgd-256-LogisticRegression/pipeline.joblib\nSaved scaler -> models/pgd-256-LogisticRegression/scaler.joblib\nSaved classifier -> models/pgd-256-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 256 - df - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.6070  prec=0.5890  recall=0.7078  f1=0.6430\n  roc_auc=0.6617\n  confusion_matrix: [[246, 240], [142, 344]]\nSaved pipeline -> models/df-256-LogisticRegression/pipeline.joblib\nSaved scaler -> models/df-256-LogisticRegression/scaler.joblib\nSaved classifier -> models/df-256-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 256 - cw - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.5926  prec=0.5745  recall=0.7140  f1=0.6367\n  roc_auc=0.6291\n  confusion_matrix: [[229, 257], [139, 347]]\nSaved pipeline -> models/cw-256-LogisticRegression/pipeline.joblib\nSaved scaler -> models/cw-256-LogisticRegression/scaler.joblib\nSaved classifier -> models/cw-256-LogisticRegression/clf.joblib\n_________________________________\n\n==============================\n\nClassifier: RandomForest \n\nTraining: 256 - fgsm - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/fgsm-256-RandomForest/pipeline.joblib\nSaved scaler -> models/fgsm-256-RandomForest/scaler.joblib\nSaved classifier -> models/fgsm-256-RandomForest/clf.joblib\n_________________________________\n\nTraining: 256 - bim - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/bim-256-RandomForest/pipeline.joblib\nSaved scaler -> models/bim-256-RandomForest/scaler.joblib\nSaved classifier -> models/bim-256-RandomForest/clf.joblib\n_________________________________\n\nTraining: 256 - pgd - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/pgd-256-RandomForest/pipeline.joblib\nSaved scaler -> models/pgd-256-RandomForest/scaler.joblib\nSaved classifier -> models/pgd-256-RandomForest/clf.joblib\n_________________________________\n\nTraining: 256 - df - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/df-256-RandomForest/pipeline.joblib\nSaved scaler -> models/df-256-RandomForest/scaler.joblib\nSaved classifier -> models/df-256-RandomForest/clf.joblib\n_________________________________\n\nTraining: 256 - cw - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/cw-256-RandomForest/pipeline.joblib\nSaved scaler -> models/cw-256-RandomForest/scaler.joblib\nSaved classifier -> models/cw-256-RandomForest/clf.joblib\n_________________________________\n\n==============================\n\n++++++++++++++++++++++++++++++++++\n\nImage Size: 512 \n\nClassifier: LogisticRegression \n\nTraining: 512 - fgsm - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.6708  prec=0.6869  recall=0.6276  f1=0.6559\n  roc_auc=0.7518\n  confusion_matrix: [[347, 139], [181, 305]]\nSaved pipeline -> models/fgsm-512-LogisticRegression/pipeline.joblib\nSaved scaler -> models/fgsm-512-LogisticRegression/scaler.joblib\nSaved classifier -> models/fgsm-512-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 512 - bim - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=0.9537  prec=0.9933  recall=0.9136  f1=0.9518\n  roc_auc=0.9891\n  confusion_matrix: [[483, 3], [42, 444]]\nSaved pipeline -> models/bim-512-LogisticRegression/pipeline.joblib\nSaved scaler -> models/bim-512-LogisticRegression/scaler.joblib\nSaved classifier -> models/bim-512-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 512 - pgd - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.9424  prec=0.9864  recall=0.8971  f1=0.9397\n  roc_auc=0.9820\n  confusion_matrix: [[480, 6], [50, 436]]\nSaved pipeline -> models/pgd-512-LogisticRegression/pipeline.joblib\nSaved scaler -> models/pgd-512-LogisticRegression/scaler.joblib\nSaved classifier -> models/pgd-512-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 512 - df - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.6132  prec=0.5929  recall=0.7222  f1=0.6512\n  roc_auc=0.6469\n  confusion_matrix: [[245, 241], [135, 351]]\nSaved pipeline -> models/df-512-LogisticRegression/pipeline.joblib\nSaved scaler -> models/df-512-LogisticRegression/scaler.joblib\nSaved classifier -> models/df-512-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 512 - cw - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.5802  prec=0.5661  recall=0.6872  f1=0.6208\n  roc_auc=0.6024\n  confusion_matrix: [[230, 256], [152, 334]]\nSaved pipeline -> models/cw-512-LogisticRegression/pipeline.joblib\nSaved scaler -> models/cw-512-LogisticRegression/scaler.joblib\nSaved classifier -> models/cw-512-LogisticRegression/clf.joblib\n_________________________________\n\n==============================\n\nClassifier: RandomForest \n\nTraining: 512 - fgsm - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/fgsm-512-RandomForest/pipeline.joblib\nSaved scaler -> models/fgsm-512-RandomForest/scaler.joblib\nSaved classifier -> models/fgsm-512-RandomForest/clf.joblib\n_________________________________\n\nTraining: 512 - bim - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/bim-512-RandomForest/pipeline.joblib\nSaved scaler -> models/bim-512-RandomForest/scaler.joblib\nSaved classifier -> models/bim-512-RandomForest/clf.joblib\n_________________________________\n\nTraining: 512 - pgd - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/pgd-512-RandomForest/pipeline.joblib\nSaved scaler -> models/pgd-512-RandomForest/scaler.joblib\nSaved classifier -> models/pgd-512-RandomForest/clf.joblib\n_________________________________\n\nTraining: 512 - df - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/df-512-RandomForest/pipeline.joblib\nSaved scaler -> models/df-512-RandomForest/scaler.joblib\nSaved classifier -> models/df-512-RandomForest/clf.joblib\n_________________________________\n\nTraining: 512 - cw - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/cw-512-RandomForest/pipeline.joblib\nSaved scaler -> models/cw-512-RandomForest/scaler.joblib\nSaved classifier -> models/cw-512-RandomForest/clf.joblib\n_________________________________\n\n==============================\n\n++++++++++++++++++++++++++++++++++\n\nImage Size: 1024 \n\nClassifier: LogisticRegression \n\nTraining: 1024 - fgsm - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.7582  prec=0.7872  recall=0.7078  f1=0.7454\n  roc_auc=0.8522\n  confusion_matrix: [[393, 93], [142, 344]]\nSaved pipeline -> models/fgsm-1024-LogisticRegression/pipeline.joblib\nSaved scaler -> models/fgsm-1024-LogisticRegression/scaler.joblib\nSaved classifier -> models/fgsm-1024-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 1024 - bim - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=0.9856  prec=0.9979  recall=0.9733  f1=0.9854\n  roc_auc=0.9998\n  confusion_matrix: [[485, 1], [13, 473]]\nSaved pipeline -> models/bim-1024-LogisticRegression/pipeline.joblib\nSaved scaler -> models/bim-1024-LogisticRegression/scaler.joblib\nSaved classifier -> models/bim-1024-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 1024 - pgd - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.9887  prec=1.0000  recall=0.9774  f1=0.9886\n  roc_auc=0.9999\n  confusion_matrix: [[486, 0], [11, 475]]\nSaved pipeline -> models/pgd-1024-LogisticRegression/pipeline.joblib\nSaved scaler -> models/pgd-1024-LogisticRegression/scaler.joblib\nSaved classifier -> models/pgd-1024-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 1024 - df - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.5350  prec=0.5301  recall=0.6152  f1=0.5695\n  roc_auc=0.5519\n  confusion_matrix: [[221, 265], [187, 299]]\nSaved pipeline -> models/df-1024-LogisticRegression/pipeline.joblib\nSaved scaler -> models/df-1024-LogisticRegression/scaler.joblib\nSaved classifier -> models/df-1024-LogisticRegression/clf.joblib\n_________________________________\n\nTraining: 1024 - cw - LogisticRegression \n\nUsing LogisticRegression as classifier\nFitting pipeline\nTRAIN Eval results:\n  acc=0.5309  prec=0.5258  recall=0.6296  f1=0.5730\n  roc_auc=0.5327\n  confusion_matrix: [[210, 276], [180, 306]]\nSaved pipeline -> models/cw-1024-LogisticRegression/pipeline.joblib\nSaved scaler -> models/cw-1024-LogisticRegression/scaler.joblib\nSaved classifier -> models/cw-1024-LogisticRegression/clf.joblib\n_________________________________\n\n==============================\n\nClassifier: RandomForest \n\nTraining: 1024 - fgsm - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/fgsm-1024-RandomForest/pipeline.joblib\nSaved scaler -> models/fgsm-1024-RandomForest/scaler.joblib\nSaved classifier -> models/fgsm-1024-RandomForest/clf.joblib\n_________________________________\n\nTraining: 1024 - bim - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/bim-1024-RandomForest/pipeline.joblib\nSaved scaler -> models/bim-1024-RandomForest/scaler.joblib\nSaved classifier -> models/bim-1024-RandomForest/clf.joblib\n_________________________________\n\nTraining: 1024 - pgd - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/pgd-1024-RandomForest/pipeline.joblib\nSaved scaler -> models/pgd-1024-RandomForest/scaler.joblib\nSaved classifier -> models/pgd-1024-RandomForest/clf.joblib\n_________________________________\n\nTraining: 1024 - df - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/df-1024-RandomForest/pipeline.joblib\nSaved scaler -> models/df-1024-RandomForest/scaler.joblib\nSaved classifier -> models/df-1024-RandomForest/clf.joblib\n_________________________________\n\nTraining: 1024 - cw - RandomForest \n\nUsing RandomForest as classifier\nFitting pipeline\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TRAIN Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[486, 0], [0, 486]]\nSaved pipeline -> models/cw-1024-RandomForest/pipeline.joblib\nSaved scaler -> models/cw-1024-RandomForest/scaler.joblib\nSaved classifier -> models/cw-1024-RandomForest/clf.joblib\n_________________________________\n\n==============================\n\n++++++++++++++++++++++++++++++++++\n\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"# Evaluate (Val Set)","metadata":{}},{"cell_type":"code","source":"IMG_SIZES = [32, 64, 128, 256, 512, 1024]\nATTACKS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\nclassifiers = ['LogisticRegression', 'RandomForest']\nfor IMG_SIZE in IMG_SIZES:\n    for ATTACK in ATTACKS:\n        print (f'Attack Method: {ATTACK}\\n')\n        for classifier in classifiers:\n            print (f'\\n Classifier: {classifier}: \\n')\n            val_res = eval_val_from_npy(\n                 val_npy_path = f\"/kaggle/input/detectlid/Dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/val_raw.npy\",\n                 val_label_path = f\"/kaggle/input/detectlid/Dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/val_labels.npy\",\n                 model_out_dir = f\"/kaggle/working/models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n                 return_predictions=True,\n                 use_mmap=False,\n                 csv_path=f\"./eval-VALSET/{ATTACK}-{DATASET}-{IMG_SIZE}-{classifier}_test_result.csv\"\n            )\n            print(\"val metrics:\", val_res[\"metrics\"])\n        print ('_____________________\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T14:41:51.976851Z","iopub.execute_input":"2025-10-19T14:41:51.977166Z","iopub.status.idle":"2025-10-19T14:41:56.539346Z","shell.execute_reply.started":"2025-10-19T14:41:51.977145Z","shell.execute_reply":"2025-10-19T14:41:56.538153Z"}},"outputs":[{"name":"stdout","text":"Attack Method: fgsm\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.5432  prec=0.5574  recall=0.4198  f1=0.4789\n  roc_auc=0.5856\n  confusion_matrix: [[54, 27], [47, 34]]\nPredictions saved to: eval-VALSET/fgsm-cw-32-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/fgsm-cw-32-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.5432098765432098, 'precision': 0.5573770491803278, 'recall': 0.41975308641975306, 'f1': 0.4788732394366197, 'roc_auc': 0.5855814662399025, 'confusion_matrix': [[54, 27], [47, 34]], 'classification_report': {'0': {'precision': 0.5346534653465347, 'recall': 0.6666666666666666, 'f1-score': 0.5934065934065934, 'support': 81}, '1': {'precision': 0.5573770491803278, 'recall': 0.41975308641975306, 'f1-score': 0.4788732394366197, 'support': 81}, 'accuracy': 0.5432098765432098, 'macro avg': {'precision': 0.5460152572634313, 'recall': 0.5432098765432098, 'f1-score': 0.5361399164216065, 'support': 162}, 'weighted avg': {'precision': 0.5460152572634313, 'recall': 0.5432098765432098, 'f1-score': 0.5361399164216065, 'support': 162}}}\n\n Classifier: RandomForest: \n\nVAL Eval results:\n  acc=0.4938  prec=0.4938  recall=0.4938  f1=0.4938\n  roc_auc=0.5066\n  confusion_matrix: [[40, 41], [41, 40]]\nPredictions saved to: eval-VALSET/fgsm-cw-32-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/fgsm-cw-32-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.49382716049382713, 'precision': 0.49382716049382713, 'recall': 0.49382716049382713, 'f1': 0.49382716049382713, 'roc_auc': 0.5066300868770004, 'confusion_matrix': [[40, 41], [41, 40]], 'classification_report': {'0': {'precision': 0.49382716049382713, 'recall': 0.49382716049382713, 'f1-score': 0.49382716049382713, 'support': 81}, '1': {'precision': 0.49382716049382713, 'recall': 0.49382716049382713, 'f1-score': 0.49382716049382713, 'support': 81}, 'accuracy': 0.49382716049382713, 'macro avg': {'precision': 0.49382716049382713, 'recall': 0.49382716049382713, 'f1-score': 0.49382716049382713, 'support': 162}, 'weighted avg': {'precision': 0.49382716049382713, 'recall': 0.49382716049382713, 'f1-score': 0.49382716049382713, 'support': 162}}}\n_____________________\n\nAttack Method: bim\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.7099  prec=0.7576  recall=0.6173  f1=0.6803\n  roc_auc=0.7785\n  confusion_matrix: [[65, 16], [31, 50]]\nPredictions saved to: eval-VALSET/bim-cw-32-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/bim-cw-32-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.7098765432098766, 'precision': 0.7575757575757576, 'recall': 0.6172839506172839, 'f1': 0.6802721088435375, 'roc_auc': 0.7785398567291572, 'confusion_matrix': [[65, 16], [31, 50]], 'classification_report': {'0': {'precision': 0.6770833333333334, 'recall': 0.8024691358024691, 'f1-score': 0.7344632768361582, 'support': 81}, '1': {'precision': 0.7575757575757576, 'recall': 0.6172839506172839, 'f1-score': 0.6802721088435375, 'support': 81}, 'accuracy': 0.7098765432098766, 'macro avg': {'precision': 0.7173295454545454, 'recall': 0.7098765432098766, 'f1-score': 0.7073676928398478, 'support': 162}, 'weighted avg': {'precision': 0.7173295454545454, 'recall': 0.7098765432098766, 'f1-score': 0.7073676928398479, 'support': 162}}}\n\n Classifier: RandomForest: \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"VAL Eval results:\n  acc=0.8457  prec=0.8333  recall=0.8642  f1=0.8485\n  roc_auc=0.9123\n  confusion_matrix: [[67, 14], [11, 70]]\nPredictions saved to: eval-VALSET/bim-cw-32-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/bim-cw-32-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.845679012345679, 'precision': 0.8333333333333334, 'recall': 0.8641975308641975, 'f1': 0.8484848484848484, 'roc_auc': 0.9122847126962352, 'confusion_matrix': [[67, 14], [11, 70]], 'classification_report': {'0': {'precision': 0.8589743589743589, 'recall': 0.8271604938271605, 'f1-score': 0.8427672955974842, 'support': 81}, '1': {'precision': 0.8333333333333334, 'recall': 0.8641975308641975, 'f1-score': 0.8484848484848484, 'support': 81}, 'accuracy': 0.845679012345679, 'macro avg': {'precision': 0.8461538461538461, 'recall': 0.845679012345679, 'f1-score': 0.8456260720411664, 'support': 162}, 'weighted avg': {'precision': 0.846153846153846, 'recall': 0.845679012345679, 'f1-score': 0.8456260720411664, 'support': 162}}}\n_____________________\n\nAttack Method: pgd\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.7099  prec=0.8148  recall=0.5432  f1=0.6519\n  roc_auc=0.8150\n  confusion_matrix: [[71, 10], [37, 44]]\nPredictions saved to: eval-VALSET/pgd-cw-32-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/pgd-cw-32-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.7098765432098766, 'precision': 0.8148148148148148, 'recall': 0.5432098765432098, 'f1': 0.6518518518518519, 'roc_auc': 0.8149672306050906, 'confusion_matrix': [[71, 10], [37, 44]], 'classification_report': {'0': {'precision': 0.6574074074074074, 'recall': 0.8765432098765432, 'f1-score': 0.7513227513227515, 'support': 81}, '1': {'precision': 0.8148148148148148, 'recall': 0.5432098765432098, 'f1-score': 0.6518518518518519, 'support': 81}, 'accuracy': 0.7098765432098766, 'macro avg': {'precision': 0.7361111111111112, 'recall': 0.7098765432098766, 'f1-score': 0.7015873015873018, 'support': 162}, 'weighted avg': {'precision': 0.7361111111111112, 'recall': 0.7098765432098766, 'f1-score': 0.7015873015873016, 'support': 162}}}\n\n Classifier: RandomForest: \n\nVAL Eval results:\n  acc=0.8272  prec=0.8118  recall=0.8519  f1=0.8313\n  roc_auc=0.8941\n  confusion_matrix: [[65, 16], [12, 69]]\nPredictions saved to: eval-VALSET/pgd-cw-32-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/pgd-cw-32-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.8271604938271605, 'precision': 0.8117647058823529, 'recall': 0.8518518518518519, 'f1': 0.8313253012048193, 'roc_auc': 0.8941472336534064, 'confusion_matrix': [[65, 16], [12, 69]], 'classification_report': {'0': {'precision': 0.8441558441558441, 'recall': 0.8024691358024691, 'f1-score': 0.8227848101265822, 'support': 81}, '1': {'precision': 0.8117647058823529, 'recall': 0.8518518518518519, 'f1-score': 0.8313253012048193, 'support': 81}, 'accuracy': 0.8271604938271605, 'macro avg': {'precision': 0.8279602750190985, 'recall': 0.8271604938271605, 'f1-score': 0.8270550556657008, 'support': 162}, 'weighted avg': {'precision': 0.8279602750190985, 'recall': 0.8271604938271605, 'f1-score': 0.8270550556657008, 'support': 162}}}\n_____________________\n\nAttack Method: df\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.5185  prec=0.5143  recall=0.6667  f1=0.5806\n  roc_auc=0.5356\n  confusion_matrix: [[30, 51], [27, 54]]\nPredictions saved to: eval-VALSET/df-cw-32-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/df-cw-32-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.5185185185185185, 'precision': 0.5142857142857142, 'recall': 0.6666666666666666, 'f1': 0.5806451612903226, 'roc_auc': 0.5355890870294162, 'confusion_matrix': [[30, 51], [27, 54]], 'classification_report': {'0': {'precision': 0.5263157894736842, 'recall': 0.37037037037037035, 'f1-score': 0.43478260869565216, 'support': 81}, '1': {'precision': 0.5142857142857142, 'recall': 0.6666666666666666, 'f1-score': 0.5806451612903226, 'support': 81}, 'accuracy': 0.5185185185185185, 'macro avg': {'precision': 0.5203007518796992, 'recall': 0.5185185185185185, 'f1-score': 0.5077138849929874, 'support': 162}, 'weighted avg': {'precision': 0.5203007518796992, 'recall': 0.5185185185185185, 'f1-score': 0.5077138849929874, 'support': 162}}}\n\n Classifier: RandomForest: \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"VAL Eval results:\n  acc=0.5247  prec=0.5270  recall=0.4815  f1=0.5032\n  roc_auc=0.5374\n  confusion_matrix: [[46, 35], [42, 39]]\nPredictions saved to: eval-VALSET/df-cw-32-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/df-cw-32-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.5246913580246914, 'precision': 0.527027027027027, 'recall': 0.48148148148148145, 'f1': 0.5032258064516129, 'roc_auc': 0.5374180765127267, 'confusion_matrix': [[46, 35], [42, 39]], 'classification_report': {'0': {'precision': 0.5227272727272727, 'recall': 0.5679012345679012, 'f1-score': 0.544378698224852, 'support': 81}, '1': {'precision': 0.527027027027027, 'recall': 0.48148148148148145, 'f1-score': 0.5032258064516129, 'support': 81}, 'accuracy': 0.5246913580246914, 'macro avg': {'precision': 0.5248771498771498, 'recall': 0.5246913580246914, 'f1-score': 0.5238022523382324, 'support': 162}, 'weighted avg': {'precision': 0.5248771498771498, 'recall': 0.5246913580246914, 'f1-score': 0.5238022523382324, 'support': 162}}}\n_____________________\n\nAttack Method: cw\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.5123  prec=0.5094  recall=0.6667  f1=0.5775\n  roc_auc=0.5202\n  confusion_matrix: [[29, 52], [27, 54]]\nPredictions saved to: eval-VALSET/cw-cw-32-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/cw-cw-32-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.5123456790123457, 'precision': 0.5094339622641509, 'recall': 0.6666666666666666, 'f1': 0.5775401069518716, 'roc_auc': 0.5201950922115531, 'confusion_matrix': [[29, 52], [27, 54]], 'classification_report': {'0': {'precision': 0.5178571428571429, 'recall': 0.35802469135802467, 'f1-score': 0.4233576642335767, 'support': 81}, '1': {'precision': 0.5094339622641509, 'recall': 0.6666666666666666, 'f1-score': 0.5775401069518716, 'support': 81}, 'accuracy': 0.5123456790123457, 'macro avg': {'precision': 0.5136455525606469, 'recall': 0.5123456790123456, 'f1-score': 0.5004488855927242, 'support': 162}, 'weighted avg': {'precision': 0.5136455525606469, 'recall': 0.5123456790123457, 'f1-score': 0.5004488855927242, 'support': 162}}}\n\n Classifier: RandomForest: \n\nVAL Eval results:\n  acc=0.4815  prec=0.4805  recall=0.4568  f1=0.4684\n  roc_auc=0.5235\n  confusion_matrix: [[41, 40], [44, 37]]\nPredictions saved to: eval-VALSET/cw-cw-32-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/cw-cw-32-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.48148148148148145, 'precision': 0.4805194805194805, 'recall': 0.4567901234567901, 'f1': 0.46835443037974683, 'roc_auc': 0.5234720317024844, 'confusion_matrix': [[41, 40], [44, 37]], 'classification_report': {'0': {'precision': 0.4823529411764706, 'recall': 0.5061728395061729, 'f1-score': 0.49397590361445787, 'support': 81}, '1': {'precision': 0.4805194805194805, 'recall': 0.4567901234567901, 'f1-score': 0.46835443037974683, 'support': 81}, 'accuracy': 0.48148148148148145, 'macro avg': {'precision': 0.48143621084797555, 'recall': 0.4814814814814815, 'f1-score': 0.4811651669971023, 'support': 162}, 'weighted avg': {'precision': 0.48143621084797555, 'recall': 0.48148148148148145, 'f1-score': 0.4811651669971024, 'support': 162}}}\n_____________________\n\nAttack Method: fgsm\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.5494  prec=0.5741  recall=0.3827  f1=0.4593\n  roc_auc=0.5935\n  confusion_matrix: [[58, 23], [50, 31]]\nPredictions saved to: eval-VALSET/fgsm-cw-64-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/fgsm-cw-64-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.5493827160493827, 'precision': 0.5740740740740741, 'recall': 0.38271604938271603, 'f1': 0.4592592592592592, 'roc_auc': 0.5935070873342478, 'confusion_matrix': [[58, 23], [50, 31]], 'classification_report': {'0': {'precision': 0.5370370370370371, 'recall': 0.7160493827160493, 'f1-score': 0.6137566137566137, 'support': 81}, '1': {'precision': 0.5740740740740741, 'recall': 0.38271604938271603, 'f1-score': 0.4592592592592592, 'support': 81}, 'accuracy': 0.5493827160493827, 'macro avg': {'precision': 0.5555555555555556, 'recall': 0.5493827160493827, 'f1-score': 0.5365079365079365, 'support': 162}, 'weighted avg': {'precision': 0.5555555555555556, 'recall': 0.5493827160493827, 'f1-score': 0.5365079365079365, 'support': 162}}}\n\n Classifier: RandomForest: \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"VAL Eval results:\n  acc=0.5988  prec=0.5930  recall=0.6296  f1=0.6108\n  roc_auc=0.6289\n  confusion_matrix: [[46, 35], [30, 51]]\nPredictions saved to: eval-VALSET/fgsm-cw-64-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/fgsm-cw-64-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.5987654320987654, 'precision': 0.5930232558139535, 'recall': 0.6296296296296297, 'f1': 0.6107784431137725, 'roc_auc': 0.6288675506782502, 'confusion_matrix': [[46, 35], [30, 51]], 'classification_report': {'0': {'precision': 0.6052631578947368, 'recall': 0.5679012345679012, 'f1-score': 0.5859872611464968, 'support': 81}, '1': {'precision': 0.5930232558139535, 'recall': 0.6296296296296297, 'f1-score': 0.6107784431137725, 'support': 81}, 'accuracy': 0.5987654320987654, 'macro avg': {'precision': 0.5991432068543452, 'recall': 0.5987654320987654, 'f1-score': 0.5983828521301346, 'support': 162}, 'weighted avg': {'precision': 0.5991432068543452, 'recall': 0.5987654320987654, 'f1-score': 0.5983828521301348, 'support': 162}}}\n_____________________\n\nAttack Method: bim\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.8210  prec=0.8939  recall=0.7284  f1=0.8027\n  roc_auc=0.8944\n  confusion_matrix: [[74, 7], [22, 59]]\nPredictions saved to: eval-VALSET/bim-cw-64-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/bim-cw-64-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.8209876543209876, 'precision': 0.8939393939393939, 'recall': 0.7283950617283951, 'f1': 0.8027210884353742, 'roc_auc': 0.8943758573388203, 'confusion_matrix': [[74, 7], [22, 59]], 'classification_report': {'0': {'precision': 0.7708333333333334, 'recall': 0.9135802469135802, 'f1-score': 0.8361581920903954, 'support': 81}, '1': {'precision': 0.8939393939393939, 'recall': 0.7283950617283951, 'f1-score': 0.8027210884353742, 'support': 81}, 'accuracy': 0.8209876543209876, 'macro avg': {'precision': 0.8323863636363636, 'recall': 0.8209876543209876, 'f1-score': 0.8194396402628847, 'support': 162}, 'weighted avg': {'precision': 0.8323863636363636, 'recall': 0.8209876543209876, 'f1-score': 0.8194396402628847, 'support': 162}}}\n\n Classifier: RandomForest: \n\nVAL Eval results:\n  acc=0.9383  prec=0.9080  recall=0.9753  f1=0.9405\n  roc_auc=0.9772\n  confusion_matrix: [[73, 8], [2, 79]]\nPredictions saved to: eval-VALSET/bim-cw-64-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/bim-cw-64-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.9382716049382716, 'precision': 0.9080459770114943, 'recall': 0.9753086419753086, 'f1': 0.9404761904761905, 'roc_auc': 0.977213839353757, 'confusion_matrix': [[73, 8], [2, 79]], 'classification_report': {'0': {'precision': 0.9733333333333334, 'recall': 0.9012345679012346, 'f1-score': 0.935897435897436, 'support': 81}, '1': {'precision': 0.9080459770114943, 'recall': 0.9753086419753086, 'f1-score': 0.9404761904761905, 'support': 81}, 'accuracy': 0.9382716049382716, 'macro avg': {'precision': 0.9406896551724138, 'recall': 0.9382716049382716, 'f1-score': 0.9381868131868132, 'support': 162}, 'weighted avg': {'precision': 0.9406896551724138, 'recall': 0.9382716049382716, 'f1-score': 0.9381868131868134, 'support': 162}}}\n_____________________\n\nAttack Method: pgd\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.8025  prec=0.9016  recall=0.6790  f1=0.7746\n  roc_auc=0.8861\n  confusion_matrix: [[75, 6], [26, 55]]\nPredictions saved to: eval-VALSET/pgd-cw-64-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/pgd-cw-64-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.8024691358024691, 'precision': 0.9016393442622951, 'recall': 0.6790123456790124, 'f1': 0.7746478873239437, 'roc_auc': 0.8861454046639232, 'confusion_matrix': [[75, 6], [26, 55]], 'classification_report': {'0': {'precision': 0.7425742574257426, 'recall': 0.9259259259259259, 'f1-score': 0.8241758241758241, 'support': 81}, '1': {'precision': 0.9016393442622951, 'recall': 0.6790123456790124, 'f1-score': 0.7746478873239437, 'support': 81}, 'accuracy': 0.8024691358024691, 'macro avg': {'precision': 0.8221068008440189, 'recall': 0.8024691358024691, 'f1-score': 0.7994118557498839, 'support': 162}, 'weighted avg': {'precision': 0.8221068008440187, 'recall': 0.8024691358024691, 'f1-score': 0.7994118557498838, 'support': 162}}}\n\n Classifier: RandomForest: \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"VAL Eval results:\n  acc=0.9259  prec=0.9157  recall=0.9383  f1=0.9268\n  roc_auc=0.9734\n  confusion_matrix: [[74, 7], [5, 76]]\nPredictions saved to: eval-VALSET/pgd-cw-64-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/pgd-cw-64-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.9259259259259259, 'precision': 0.9156626506024096, 'recall': 0.9382716049382716, 'f1': 0.9268292682926829, 'roc_auc': 0.9734034445968602, 'confusion_matrix': [[74, 7], [5, 76]], 'classification_report': {'0': {'precision': 0.9367088607594937, 'recall': 0.9135802469135802, 'f1-score': 0.9249999999999999, 'support': 81}, '1': {'precision': 0.9156626506024096, 'recall': 0.9382716049382716, 'f1-score': 0.9268292682926829, 'support': 81}, 'accuracy': 0.9259259259259259, 'macro avg': {'precision': 0.9261857556809516, 'recall': 0.9259259259259258, 'f1-score': 0.9259146341463413, 'support': 162}, 'weighted avg': {'precision': 0.9261857556809516, 'recall': 0.9259259259259259, 'f1-score': 0.9259146341463415, 'support': 162}}}\n_____________________\n\nAttack Method: df\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.5556  prec=0.5437  recall=0.6914  f1=0.6087\n  roc_auc=0.5658\n  confusion_matrix: [[34, 47], [25, 56]]\nPredictions saved to: eval-VALSET/df-cw-64-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/df-cw-64-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.5555555555555556, 'precision': 0.5436893203883495, 'recall': 0.691358024691358, 'f1': 0.6086956521739131, 'roc_auc': 0.565767413504039, 'confusion_matrix': [[34, 47], [25, 56]], 'classification_report': {'0': {'precision': 0.576271186440678, 'recall': 0.41975308641975306, 'f1-score': 0.4857142857142857, 'support': 81}, '1': {'precision': 0.5436893203883495, 'recall': 0.691358024691358, 'f1-score': 0.6086956521739131, 'support': 81}, 'accuracy': 0.5555555555555556, 'macro avg': {'precision': 0.5599802534145137, 'recall': 0.5555555555555556, 'f1-score': 0.5472049689440994, 'support': 162}, 'weighted avg': {'precision': 0.5599802534145136, 'recall': 0.5555555555555556, 'f1-score': 0.5472049689440993, 'support': 162}}}\n\n Classifier: RandomForest: \n\nVAL Eval results:\n  acc=0.5309  prec=0.5325  recall=0.5062  f1=0.5190\n  roc_auc=0.5697\n  confusion_matrix: [[45, 36], [40, 41]]\nPredictions saved to: eval-VALSET/df-cw-64-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/df-cw-64-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.5308641975308642, 'precision': 0.5324675324675324, 'recall': 0.5061728395061729, 'f1': 0.518987341772152, 'roc_auc': 0.5697302240512118, 'confusion_matrix': [[45, 36], [40, 41]], 'classification_report': {'0': {'precision': 0.5294117647058824, 'recall': 0.5555555555555556, 'f1-score': 0.5421686746987951, 'support': 81}, '1': {'precision': 0.5324675324675324, 'recall': 0.5061728395061729, 'f1-score': 0.518987341772152, 'support': 81}, 'accuracy': 0.5308641975308642, 'macro avg': {'precision': 0.5309396485867074, 'recall': 0.5308641975308642, 'f1-score': 0.5305780082354736, 'support': 162}, 'weighted avg': {'precision': 0.5309396485867074, 'recall': 0.5308641975308642, 'f1-score': 0.5305780082354736, 'support': 162}}}\n_____________________\n\nAttack Method: cw\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.5556  prec=0.5429  recall=0.7037  f1=0.6129\n  roc_auc=0.5621\n  confusion_matrix: [[33, 48], [24, 57]]\nPredictions saved to: eval-VALSET/cw-cw-64-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/cw-cw-64-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.5555555555555556, 'precision': 0.5428571428571428, 'recall': 0.7037037037037037, 'f1': 0.6129032258064516, 'roc_auc': 0.5621094345374181, 'confusion_matrix': [[33, 48], [24, 57]], 'classification_report': {'0': {'precision': 0.5789473684210527, 'recall': 0.4074074074074074, 'f1-score': 0.47826086956521735, 'support': 81}, '1': {'precision': 0.5428571428571428, 'recall': 0.7037037037037037, 'f1-score': 0.6129032258064516, 'support': 81}, 'accuracy': 0.5555555555555556, 'macro avg': {'precision': 0.5609022556390977, 'recall': 0.5555555555555556, 'f1-score': 0.5455820476858345, 'support': 162}, 'weighted avg': {'precision': 0.5609022556390978, 'recall': 0.5555555555555556, 'f1-score': 0.5455820476858345, 'support': 162}}}\n\n Classifier: RandomForest: \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"VAL Eval results:\n  acc=0.5432  prec=0.5412  recall=0.5679  f1=0.5542\n  roc_auc=0.5562\n  confusion_matrix: [[42, 39], [35, 46]]\nPredictions saved to: eval-VALSET/cw-cw-64-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/cw-cw-64-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.5432098765432098, 'precision': 0.5411764705882353, 'recall': 0.5679012345679012, 'f1': 0.5542168674698795, 'roc_auc': 0.556241426611797, 'confusion_matrix': [[42, 39], [35, 46]], 'classification_report': {'0': {'precision': 0.5454545454545454, 'recall': 0.5185185185185185, 'f1-score': 0.5316455696202531, 'support': 81}, '1': {'precision': 0.5411764705882353, 'recall': 0.5679012345679012, 'f1-score': 0.5542168674698795, 'support': 81}, 'accuracy': 0.5432098765432098, 'macro avg': {'precision': 0.5433155080213903, 'recall': 0.5432098765432098, 'f1-score': 0.5429312185450663, 'support': 162}, 'weighted avg': {'precision': 0.5433155080213904, 'recall': 0.5432098765432098, 'f1-score': 0.5429312185450664, 'support': 162}}}\n_____________________\n\nAttack Method: fgsm\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.6235  prec=0.6515  recall=0.5309  f1=0.5850\n  roc_auc=0.6671\n  confusion_matrix: [[58, 23], [38, 43]]\nPredictions saved to: eval-VALSET/fgsm-cw-128-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/fgsm-cw-128-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.6234567901234568, 'precision': 0.6515151515151515, 'recall': 0.5308641975308642, 'f1': 0.5850340136054422, 'roc_auc': 0.6671239140374943, 'confusion_matrix': [[58, 23], [38, 43]], 'classification_report': {'0': {'precision': 0.6041666666666666, 'recall': 0.7160493827160493, 'f1-score': 0.655367231638418, 'support': 81}, '1': {'precision': 0.6515151515151515, 'recall': 0.5308641975308642, 'f1-score': 0.5850340136054422, 'support': 81}, 'accuracy': 0.6234567901234568, 'macro avg': {'precision': 0.6278409090909091, 'recall': 0.6234567901234568, 'f1-score': 0.6202006226219301, 'support': 162}, 'weighted avg': {'precision': 0.6278409090909092, 'recall': 0.6234567901234568, 'f1-score': 0.6202006226219301, 'support': 162}}}\n\n Classifier: RandomForest: \n\nVAL Eval results:\n  acc=0.6667  prec=0.6627  recall=0.6790  f1=0.6707\n  roc_auc=0.7189\n  confusion_matrix: [[53, 28], [26, 55]]\nPredictions saved to: eval-VALSET/fgsm-cw-128-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/fgsm-cw-128-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.6666666666666666, 'precision': 0.6626506024096386, 'recall': 0.6790123456790124, 'f1': 0.6707317073170732, 'roc_auc': 0.7188690748361529, 'confusion_matrix': [[53, 28], [26, 55]], 'classification_report': {'0': {'precision': 0.6708860759493671, 'recall': 0.654320987654321, 'f1-score': 0.6625, 'support': 81}, '1': {'precision': 0.6626506024096386, 'recall': 0.6790123456790124, 'f1-score': 0.6707317073170732, 'support': 81}, 'accuracy': 0.6666666666666666, 'macro avg': {'precision': 0.6667683391795028, 'recall': 0.6666666666666667, 'f1-score': 0.6666158536585366, 'support': 162}, 'weighted avg': {'precision': 0.6667683391795028, 'recall': 0.6666666666666666, 'f1-score': 0.6666158536585366, 'support': 162}}}\n_____________________\n\nAttack Method: bim\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.8889  prec=0.9701  recall=0.8025  f1=0.8784\n  roc_auc=0.9465\n  confusion_matrix: [[79, 2], [16, 65]]\nPredictions saved to: eval-VALSET/bim-cw-128-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/bim-cw-128-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.8888888888888888, 'precision': 0.9701492537313433, 'recall': 0.8024691358024691, 'f1': 0.8783783783783784, 'roc_auc': 0.9465020576131686, 'confusion_matrix': [[79, 2], [16, 65]], 'classification_report': {'0': {'precision': 0.8315789473684211, 'recall': 0.9753086419753086, 'f1-score': 0.8977272727272727, 'support': 81}, '1': {'precision': 0.9701492537313433, 'recall': 0.8024691358024691, 'f1-score': 0.8783783783783784, 'support': 81}, 'accuracy': 0.8888888888888888, 'macro avg': {'precision': 0.9008641005498822, 'recall': 0.8888888888888888, 'f1-score': 0.8880528255528255, 'support': 162}, 'weighted avg': {'precision': 0.9008641005498823, 'recall': 0.8888888888888888, 'f1-score': 0.8880528255528255, 'support': 162}}}\n\n Classifier: RandomForest: \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"VAL Eval results:\n  acc=0.9691  prec=1.0000  recall=0.9383  f1=0.9682\n  roc_auc=0.9848\n  confusion_matrix: [[81, 0], [5, 76]]\nPredictions saved to: eval-VALSET/bim-cw-128-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/bim-cw-128-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.9691358024691358, 'precision': 1.0, 'recall': 0.9382716049382716, 'f1': 0.9681528662420382, 'roc_auc': 0.9848346288675507, 'confusion_matrix': [[81, 0], [5, 76]], 'classification_report': {'0': {'precision': 0.9418604651162791, 'recall': 1.0, 'f1-score': 0.970059880239521, 'support': 81}, '1': {'precision': 1.0, 'recall': 0.9382716049382716, 'f1-score': 0.9681528662420382, 'support': 81}, 'accuracy': 0.9691358024691358, 'macro avg': {'precision': 0.9709302325581395, 'recall': 0.9691358024691358, 'f1-score': 0.9691063732407796, 'support': 162}, 'weighted avg': {'precision': 0.9709302325581395, 'recall': 0.9691358024691358, 'f1-score': 0.9691063732407796, 'support': 162}}}\n_____________________\n\nAttack Method: pgd\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.8457  prec=0.9828  recall=0.7037  f1=0.8201\n  roc_auc=0.9535\n  confusion_matrix: [[80, 1], [24, 57]]\nPredictions saved to: eval-VALSET/pgd-cw-128-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/pgd-cw-128-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.845679012345679, 'precision': 0.9827586206896551, 'recall': 0.7037037037037037, 'f1': 0.8201438848920862, 'roc_auc': 0.9535131839658588, 'confusion_matrix': [[80, 1], [24, 57]], 'classification_report': {'0': {'precision': 0.7692307692307693, 'recall': 0.9876543209876543, 'f1-score': 0.864864864864865, 'support': 81}, '1': {'precision': 0.9827586206896551, 'recall': 0.7037037037037037, 'f1-score': 0.8201438848920862, 'support': 81}, 'accuracy': 0.845679012345679, 'macro avg': {'precision': 0.8759946949602122, 'recall': 0.845679012345679, 'f1-score': 0.8425043748784756, 'support': 162}, 'weighted avg': {'precision': 0.8759946949602122, 'recall': 0.845679012345679, 'f1-score': 0.8425043748784755, 'support': 162}}}\n\n Classifier: RandomForest: \n\nVAL Eval results:\n  acc=0.9815  prec=1.0000  recall=0.9630  f1=0.9811\n  roc_auc=0.9861\n  confusion_matrix: [[81, 0], [3, 78]]\nPredictions saved to: eval-VALSET/pgd-cw-128-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/pgd-cw-128-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.9814814814814815, 'precision': 1.0, 'recall': 0.9629629629629629, 'f1': 0.9811320754716981, 'roc_auc': 0.9860539551897575, 'confusion_matrix': [[81, 0], [3, 78]], 'classification_report': {'0': {'precision': 0.9642857142857143, 'recall': 1.0, 'f1-score': 0.9818181818181818, 'support': 81}, '1': {'precision': 1.0, 'recall': 0.9629629629629629, 'f1-score': 0.9811320754716981, 'support': 81}, 'accuracy': 0.9814814814814815, 'macro avg': {'precision': 0.9821428571428572, 'recall': 0.9814814814814814, 'f1-score': 0.9814751286449399, 'support': 162}, 'weighted avg': {'precision': 0.9821428571428572, 'recall': 0.9814814814814815, 'f1-score': 0.9814751286449401, 'support': 162}}}\n_____________________\n\nAttack Method: df\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.6173  prec=0.5812  recall=0.8395  f1=0.6869\n  roc_auc=0.7020\n  confusion_matrix: [[32, 49], [13, 68]]\nPredictions saved to: eval-VALSET/df-cw-128-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/df-cw-128-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.6172839506172839, 'precision': 0.5811965811965812, 'recall': 0.8395061728395061, 'f1': 0.686868686868687, 'roc_auc': 0.7020271300106692, 'confusion_matrix': [[32, 49], [13, 68]], 'classification_report': {'0': {'precision': 0.7111111111111111, 'recall': 0.3950617283950617, 'f1-score': 0.5079365079365079, 'support': 81}, '1': {'precision': 0.5811965811965812, 'recall': 0.8395061728395061, 'f1-score': 0.686868686868687, 'support': 81}, 'accuracy': 0.6172839506172839, 'macro avg': {'precision': 0.6461538461538462, 'recall': 0.6172839506172839, 'f1-score': 0.5974025974025974, 'support': 162}, 'weighted avg': {'precision': 0.6461538461538462, 'recall': 0.6172839506172839, 'f1-score': 0.5974025974025975, 'support': 162}}}\n\n Classifier: RandomForest: \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"VAL Eval results:\n  acc=0.6173  prec=0.5905  recall=0.7654  f1=0.6667\n  roc_auc=0.6874\n  confusion_matrix: [[38, 43], [19, 62]]\nPredictions saved to: eval-VALSET/df-cw-128-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/df-cw-128-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.6172839506172839, 'precision': 0.5904761904761905, 'recall': 0.7654320987654321, 'f1': 0.6666666666666666, 'roc_auc': 0.6873952141441854, 'confusion_matrix': [[38, 43], [19, 62]], 'classification_report': {'0': {'precision': 0.6666666666666666, 'recall': 0.4691358024691358, 'f1-score': 0.5507246376811594, 'support': 81}, '1': {'precision': 0.5904761904761905, 'recall': 0.7654320987654321, 'f1-score': 0.6666666666666666, 'support': 81}, 'accuracy': 0.6172839506172839, 'macro avg': {'precision': 0.6285714285714286, 'recall': 0.6172839506172839, 'f1-score': 0.6086956521739131, 'support': 162}, 'weighted avg': {'precision': 0.6285714285714286, 'recall': 0.6172839506172839, 'f1-score': 0.608695652173913, 'support': 162}}}\n_____________________\n\nAttack Method: cw\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.6049  prec=0.5726  recall=0.8272  f1=0.6768\n  roc_auc=0.6917\n  confusion_matrix: [[31, 50], [14, 67]]\nPredictions saved to: eval-VALSET/cw-cw-128-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/cw-cw-128-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.6049382716049383, 'precision': 0.5726495726495726, 'recall': 0.8271604938271605, 'f1': 0.6767676767676768, 'roc_auc': 0.6916628562719098, 'confusion_matrix': [[31, 50], [14, 67]], 'classification_report': {'0': {'precision': 0.6888888888888889, 'recall': 0.38271604938271603, 'f1-score': 0.49206349206349204, 'support': 81}, '1': {'precision': 0.5726495726495726, 'recall': 0.8271604938271605, 'f1-score': 0.6767676767676768, 'support': 81}, 'accuracy': 0.6049382716049383, 'macro avg': {'precision': 0.6307692307692307, 'recall': 0.6049382716049383, 'f1-score': 0.5844155844155844, 'support': 162}, 'weighted avg': {'precision': 0.6307692307692306, 'recall': 0.6049382716049383, 'f1-score': 0.5844155844155844, 'support': 162}}}\n\n Classifier: RandomForest: \n\nVAL Eval results:\n  acc=0.6235  prec=0.6136  recall=0.6667  f1=0.6391\n  roc_auc=0.6749\n  confusion_matrix: [[47, 34], [27, 54]]\nPredictions saved to: eval-VALSET/cw-cw-128-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/cw-cw-128-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.6234567901234568, 'precision': 0.6136363636363636, 'recall': 0.6666666666666666, 'f1': 0.6390532544378698, 'roc_auc': 0.6748971193415637, 'confusion_matrix': [[47, 34], [27, 54]], 'classification_report': {'0': {'precision': 0.6351351351351351, 'recall': 0.5802469135802469, 'f1-score': 0.6064516129032258, 'support': 81}, '1': {'precision': 0.6136363636363636, 'recall': 0.6666666666666666, 'f1-score': 0.6390532544378698, 'support': 81}, 'accuracy': 0.6234567901234568, 'macro avg': {'precision': 0.6243857493857494, 'recall': 0.6234567901234568, 'f1-score': 0.6227524336705478, 'support': 162}, 'weighted avg': {'precision': 0.6243857493857494, 'recall': 0.6234567901234568, 'f1-score': 0.6227524336705478, 'support': 162}}}\n_____________________\n\nAttack Method: fgsm\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.6111  prec=0.6286  recall=0.5432  f1=0.5828\n  roc_auc=0.6699\n  confusion_matrix: [[55, 26], [37, 44]]\nPredictions saved to: eval-VALSET/fgsm-cw-256-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/fgsm-cw-256-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.6111111111111112, 'precision': 0.6285714285714286, 'recall': 0.5432098765432098, 'f1': 0.5827814569536424, 'roc_auc': 0.66986739826246, 'confusion_matrix': [[55, 26], [37, 44]], 'classification_report': {'0': {'precision': 0.5978260869565217, 'recall': 0.6790123456790124, 'f1-score': 0.6358381502890174, 'support': 81}, '1': {'precision': 0.6285714285714286, 'recall': 0.5432098765432098, 'f1-score': 0.5827814569536424, 'support': 81}, 'accuracy': 0.6111111111111112, 'macro avg': {'precision': 0.6131987577639751, 'recall': 0.6111111111111112, 'f1-score': 0.6093098036213298, 'support': 162}, 'weighted avg': {'precision': 0.613198757763975, 'recall': 0.6111111111111112, 'f1-score': 0.6093098036213298, 'support': 162}}}\n\n Classifier: RandomForest: \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"VAL Eval results:\n  acc=0.6852  prec=0.6829  recall=0.6914  f1=0.6871\n  roc_auc=0.7823\n  confusion_matrix: [[55, 26], [25, 56]]\nPredictions saved to: eval-VALSET/fgsm-cw-256-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/fgsm-cw-256-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.6851851851851852, 'precision': 0.6829268292682927, 'recall': 0.691358024691358, 'f1': 0.6871165644171778, 'roc_auc': 0.782274043590916, 'confusion_matrix': [[55, 26], [25, 56]], 'classification_report': {'0': {'precision': 0.6875, 'recall': 0.6790123456790124, 'f1-score': 0.6832298136645963, 'support': 81}, '1': {'precision': 0.6829268292682927, 'recall': 0.691358024691358, 'f1-score': 0.6871165644171778, 'support': 81}, 'accuracy': 0.6851851851851852, 'macro avg': {'precision': 0.6852134146341464, 'recall': 0.6851851851851851, 'f1-score': 0.6851731890408871, 'support': 162}, 'weighted avg': {'precision': 0.6852134146341463, 'recall': 0.6851851851851852, 'f1-score': 0.6851731890408871, 'support': 162}}}\n_____________________\n\nAttack Method: bim\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.8889  prec=0.9200  recall=0.8519  f1=0.8846\n  roc_auc=0.9453\n  confusion_matrix: [[75, 6], [12, 69]]\nPredictions saved to: eval-VALSET/bim-cw-256-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/bim-cw-256-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.8888888888888888, 'precision': 0.92, 'recall': 0.8518518518518519, 'f1': 0.8846153846153846, 'roc_auc': 0.9452827312909617, 'confusion_matrix': [[75, 6], [12, 69]], 'classification_report': {'0': {'precision': 0.8620689655172413, 'recall': 0.9259259259259259, 'f1-score': 0.8928571428571429, 'support': 81}, '1': {'precision': 0.92, 'recall': 0.8518518518518519, 'f1-score': 0.8846153846153846, 'support': 81}, 'accuracy': 0.8888888888888888, 'macro avg': {'precision': 0.8910344827586207, 'recall': 0.8888888888888888, 'f1-score': 0.8887362637362637, 'support': 162}, 'weighted avg': {'precision': 0.8910344827586207, 'recall': 0.8888888888888888, 'f1-score': 0.8887362637362637, 'support': 162}}}\n\n Classifier: RandomForest: \n\nVAL Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[81, 0], [0, 81]]\nPredictions saved to: eval-VALSET/bim-cw-256-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/bim-cw-256-RandomForest_test_result.csv\nval metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'roc_auc': 1.0, 'confusion_matrix': [[81, 0], [0, 81]], 'classification_report': {'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162}}}\n_____________________\n\nAttack Method: pgd\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.8210  prec=0.8611  recall=0.7654  f1=0.8105\n  roc_auc=0.8800\n  confusion_matrix: [[71, 10], [19, 62]]\nPredictions saved to: eval-VALSET/pgd-cw-256-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/pgd-cw-256-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.8209876543209876, 'precision': 0.8611111111111112, 'recall': 0.7654320987654321, 'f1': 0.8104575163398693, 'roc_auc': 0.8800487730528883, 'confusion_matrix': [[71, 10], [19, 62]], 'classification_report': {'0': {'precision': 0.7888888888888889, 'recall': 0.8765432098765432, 'f1-score': 0.8304093567251462, 'support': 81}, '1': {'precision': 0.8611111111111112, 'recall': 0.7654320987654321, 'f1-score': 0.8104575163398693, 'support': 81}, 'accuracy': 0.8209876543209876, 'macro avg': {'precision': 0.825, 'recall': 0.8209876543209876, 'f1-score': 0.8204334365325077, 'support': 162}, 'weighted avg': {'precision': 0.8250000000000001, 'recall': 0.8209876543209876, 'f1-score': 0.8204334365325077, 'support': 162}}}\n\n Classifier: RandomForest: \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"VAL Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[81, 0], [0, 81]]\nPredictions saved to: eval-VALSET/pgd-cw-256-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/pgd-cw-256-RandomForest_test_result.csv\nval metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'roc_auc': 1.0, 'confusion_matrix': [[81, 0], [0, 81]], 'classification_report': {'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162}}}\n_____________________\n\nAttack Method: df\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.6296  prec=0.6129  recall=0.7037  f1=0.6552\n  roc_auc=0.6923\n  confusion_matrix: [[45, 36], [24, 57]]\nPredictions saved to: eval-VALSET/df-cw-256-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/df-cw-256-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.6296296296296297, 'precision': 0.6129032258064516, 'recall': 0.7037037037037037, 'f1': 0.6551724137931035, 'roc_auc': 0.6922725194330132, 'confusion_matrix': [[45, 36], [24, 57]], 'classification_report': {'0': {'precision': 0.6521739130434783, 'recall': 0.5555555555555556, 'f1-score': 0.6, 'support': 81}, '1': {'precision': 0.6129032258064516, 'recall': 0.7037037037037037, 'f1-score': 0.6551724137931035, 'support': 81}, 'accuracy': 0.6296296296296297, 'macro avg': {'precision': 0.632538569424965, 'recall': 0.6296296296296297, 'f1-score': 0.6275862068965518, 'support': 162}, 'weighted avg': {'precision': 0.632538569424965, 'recall': 0.6296296296296297, 'f1-score': 0.6275862068965518, 'support': 162}}}\n\n Classifier: RandomForest: \n\nVAL Eval results:\n  acc=0.6852  prec=0.6829  recall=0.6914  f1=0.6871\n  roc_auc=0.7421\n  confusion_matrix: [[55, 26], [25, 56]]\nPredictions saved to: eval-VALSET/df-cw-256-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/df-cw-256-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.6851851851851852, 'precision': 0.6829268292682927, 'recall': 0.691358024691358, 'f1': 0.6871165644171778, 'roc_auc': 0.7421124828532236, 'confusion_matrix': [[55, 26], [25, 56]], 'classification_report': {'0': {'precision': 0.6875, 'recall': 0.6790123456790124, 'f1-score': 0.6832298136645963, 'support': 81}, '1': {'precision': 0.6829268292682927, 'recall': 0.691358024691358, 'f1-score': 0.6871165644171778, 'support': 81}, 'accuracy': 0.6851851851851852, 'macro avg': {'precision': 0.6852134146341464, 'recall': 0.6851851851851851, 'f1-score': 0.6851731890408871, 'support': 162}, 'weighted avg': {'precision': 0.6852134146341463, 'recall': 0.6851851851851852, 'f1-score': 0.6851731890408871, 'support': 162}}}\n_____________________\n\nAttack Method: cw\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.6111  prec=0.5957  recall=0.6914  f1=0.6400\n  roc_auc=0.6609\n  confusion_matrix: [[43, 38], [25, 56]]\nPredictions saved to: eval-VALSET/cw-cw-256-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/cw-cw-256-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.6111111111111112, 'precision': 0.5957446808510638, 'recall': 0.691358024691358, 'f1': 0.64, 'roc_auc': 0.6608748666361833, 'confusion_matrix': [[43, 38], [25, 56]], 'classification_report': {'0': {'precision': 0.6323529411764706, 'recall': 0.5308641975308642, 'f1-score': 0.5771812080536912, 'support': 81}, '1': {'precision': 0.5957446808510638, 'recall': 0.691358024691358, 'f1-score': 0.64, 'support': 81}, 'accuracy': 0.6111111111111112, 'macro avg': {'precision': 0.6140488110137672, 'recall': 0.6111111111111112, 'f1-score': 0.6085906040268456, 'support': 162}, 'weighted avg': {'precision': 0.6140488110137672, 'recall': 0.6111111111111112, 'f1-score': 0.6085906040268456, 'support': 162}}}\n\n Classifier: RandomForest: \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"VAL Eval results:\n  acc=0.6420  prec=0.6386  recall=0.6543  f1=0.6463\n  roc_auc=0.6902\n  confusion_matrix: [[51, 30], [28, 53]]\nPredictions saved to: eval-VALSET/cw-cw-256-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/cw-cw-256-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.6419753086419753, 'precision': 0.6385542168674698, 'recall': 0.654320987654321, 'f1': 0.6463414634146342, 'roc_auc': 0.690214906264289, 'confusion_matrix': [[51, 30], [28, 53]], 'classification_report': {'0': {'precision': 0.6455696202531646, 'recall': 0.6296296296296297, 'f1-score': 0.6375, 'support': 81}, '1': {'precision': 0.6385542168674698, 'recall': 0.654320987654321, 'f1-score': 0.6463414634146342, 'support': 81}, 'accuracy': 0.6419753086419753, 'macro avg': {'precision': 0.6420619185603171, 'recall': 0.6419753086419753, 'f1-score': 0.641920731707317, 'support': 162}, 'weighted avg': {'precision': 0.6420619185603172, 'recall': 0.6419753086419753, 'f1-score': 0.641920731707317, 'support': 162}}}\n_____________________\n\nAttack Method: fgsm\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.6420  prec=0.6885  recall=0.5185  f1=0.5915\n  roc_auc=0.7615\n  confusion_matrix: [[62, 19], [39, 42]]\nPredictions saved to: eval-VALSET/fgsm-cw-512-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/fgsm-cw-512-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.6419753086419753, 'precision': 0.6885245901639344, 'recall': 0.5185185185185185, 'f1': 0.5915492957746479, 'roc_auc': 0.7614692882182594, 'confusion_matrix': [[62, 19], [39, 42]], 'classification_report': {'0': {'precision': 0.6138613861386139, 'recall': 0.7654320987654321, 'f1-score': 0.6813186813186813, 'support': 81}, '1': {'precision': 0.6885245901639344, 'recall': 0.5185185185185185, 'f1-score': 0.5915492957746479, 'support': 81}, 'accuracy': 0.6419753086419753, 'macro avg': {'precision': 0.6511929881512741, 'recall': 0.6419753086419753, 'f1-score': 0.6364339885466646, 'support': 162}, 'weighted avg': {'precision': 0.6511929881512741, 'recall': 0.6419753086419753, 'f1-score': 0.6364339885466646, 'support': 162}}}\n\n Classifier: RandomForest: \n\nVAL Eval results:\n  acc=0.7407  prec=0.7468  recall=0.7284  f1=0.7375\n  roc_auc=0.8078\n  confusion_matrix: [[61, 20], [22, 59]]\nPredictions saved to: eval-VALSET/fgsm-cw-512-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/fgsm-cw-512-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.7407407407407407, 'precision': 0.7468354430379747, 'recall': 0.7283950617283951, 'f1': 0.7374999999999999, 'roc_auc': 0.8078036884621247, 'confusion_matrix': [[61, 20], [22, 59]], 'classification_report': {'0': {'precision': 0.7349397590361446, 'recall': 0.7530864197530864, 'f1-score': 0.7439024390243902, 'support': 81}, '1': {'precision': 0.7468354430379747, 'recall': 0.7283950617283951, 'f1-score': 0.7374999999999999, 'support': 81}, 'accuracy': 0.7407407407407407, 'macro avg': {'precision': 0.7408876010370596, 'recall': 0.7407407407407407, 'f1-score': 0.7407012195121951, 'support': 162}, 'weighted avg': {'precision': 0.7408876010370596, 'recall': 0.7407407407407407, 'f1-score': 0.7407012195121951, 'support': 162}}}\n_____________________\n\nAttack Method: bim\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.9259  prec=0.9726  recall=0.8765  f1=0.9221\n  roc_auc=0.9726\n  confusion_matrix: [[79, 2], [10, 71]]\nPredictions saved to: eval-VALSET/bim-cw-512-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/bim-cw-512-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.9259259259259259, 'precision': 0.9726027397260274, 'recall': 0.8765432098765432, 'f1': 0.922077922077922, 'roc_auc': 0.9725651577503429, 'confusion_matrix': [[79, 2], [10, 71]], 'classification_report': {'0': {'precision': 0.8876404494382022, 'recall': 0.9753086419753086, 'f1-score': 0.9294117647058823, 'support': 81}, '1': {'precision': 0.9726027397260274, 'recall': 0.8765432098765432, 'f1-score': 0.922077922077922, 'support': 81}, 'accuracy': 0.9259259259259259, 'macro avg': {'precision': 0.9301215945821149, 'recall': 0.9259259259259259, 'f1-score': 0.9257448433919022, 'support': 162}, 'weighted avg': {'precision': 0.9301215945821149, 'recall': 0.9259259259259259, 'f1-score': 0.9257448433919023, 'support': 162}}}\n\n Classifier: RandomForest: \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"VAL Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[81, 0], [0, 81]]\nPredictions saved to: eval-VALSET/bim-cw-512-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/bim-cw-512-RandomForest_test_result.csv\nval metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'roc_auc': 1.0, 'confusion_matrix': [[81, 0], [0, 81]], 'classification_report': {'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162}}}\n_____________________\n\nAttack Method: pgd\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.9136  prec=0.9718  recall=0.8519  f1=0.9079\n  roc_auc=0.9534\n  confusion_matrix: [[79, 2], [12, 69]]\nPredictions saved to: eval-VALSET/pgd-cw-512-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/pgd-cw-512-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.9135802469135802, 'precision': 0.971830985915493, 'recall': 0.8518518518518519, 'f1': 0.9078947368421053, 'roc_auc': 0.9533607681755829, 'confusion_matrix': [[79, 2], [12, 69]], 'classification_report': {'0': {'precision': 0.8681318681318682, 'recall': 0.9753086419753086, 'f1-score': 0.9186046511627908, 'support': 81}, '1': {'precision': 0.971830985915493, 'recall': 0.8518518518518519, 'f1-score': 0.9078947368421053, 'support': 81}, 'accuracy': 0.9135802469135802, 'macro avg': {'precision': 0.9199814270236806, 'recall': 0.9135802469135803, 'f1-score': 0.913249694002448, 'support': 162}, 'weighted avg': {'precision': 0.9199814270236805, 'recall': 0.9135802469135802, 'f1-score': 0.913249694002448, 'support': 162}}}\n\n Classifier: RandomForest: \n\nVAL Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[81, 0], [0, 81]]\nPredictions saved to: eval-VALSET/pgd-cw-512-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/pgd-cw-512-RandomForest_test_result.csv\nval metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'roc_auc': 1.0, 'confusion_matrix': [[81, 0], [0, 81]], 'classification_report': {'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162}}}\n_____________________\n\nAttack Method: df\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.6296  prec=0.6000  recall=0.7778  f1=0.6774\n  roc_auc=0.6677\n  confusion_matrix: [[39, 42], [18, 63]]\nPredictions saved to: eval-VALSET/df-cw-512-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/df-cw-512-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.6296296296296297, 'precision': 0.6, 'recall': 0.7777777777777778, 'f1': 0.6774193548387097, 'roc_auc': 0.6677335771985978, 'confusion_matrix': [[39, 42], [18, 63]], 'classification_report': {'0': {'precision': 0.6842105263157895, 'recall': 0.48148148148148145, 'f1-score': 0.5652173913043478, 'support': 81}, '1': {'precision': 0.6, 'recall': 0.7777777777777778, 'f1-score': 0.6774193548387097, 'support': 81}, 'accuracy': 0.6296296296296297, 'macro avg': {'precision': 0.6421052631578947, 'recall': 0.6296296296296297, 'f1-score': 0.6213183730715288, 'support': 162}, 'weighted avg': {'precision': 0.6421052631578947, 'recall': 0.6296296296296297, 'f1-score': 0.6213183730715288, 'support': 162}}}\n\n Classifier: RandomForest: \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"VAL Eval results:\n  acc=0.6235  prec=0.6111  recall=0.6790  f1=0.6433\n  roc_auc=0.6616\n  confusion_matrix: [[46, 35], [26, 55]]\nPredictions saved to: eval-VALSET/df-cw-512-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/df-cw-512-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.6234567901234568, 'precision': 0.6111111111111112, 'recall': 0.6790123456790124, 'f1': 0.6432748538011697, 'roc_auc': 0.6616369455875628, 'confusion_matrix': [[46, 35], [26, 55]], 'classification_report': {'0': {'precision': 0.6388888888888888, 'recall': 0.5679012345679012, 'f1-score': 0.6013071895424836, 'support': 81}, '1': {'precision': 0.6111111111111112, 'recall': 0.6790123456790124, 'f1-score': 0.6432748538011697, 'support': 81}, 'accuracy': 0.6234567901234568, 'macro avg': {'precision': 0.625, 'recall': 0.6234567901234568, 'f1-score': 0.6222910216718267, 'support': 162}, 'weighted avg': {'precision': 0.625, 'recall': 0.6234567901234568, 'f1-score': 0.6222910216718266, 'support': 162}}}\n_____________________\n\nAttack Method: cw\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.6111  prec=0.5849  recall=0.7654  f1=0.6631\n  roc_auc=0.6315\n  confusion_matrix: [[37, 44], [19, 62]]\nPredictions saved to: eval-VALSET/cw-cw-512-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/cw-cw-512-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.6111111111111112, 'precision': 0.5849056603773585, 'recall': 0.7654320987654321, 'f1': 0.6631016042780749, 'roc_auc': 0.63145861911294, 'confusion_matrix': [[37, 44], [19, 62]], 'classification_report': {'0': {'precision': 0.6607142857142857, 'recall': 0.4567901234567901, 'f1-score': 0.5401459854014599, 'support': 81}, '1': {'precision': 0.5849056603773585, 'recall': 0.7654320987654321, 'f1-score': 0.6631016042780749, 'support': 81}, 'accuracy': 0.6111111111111112, 'macro avg': {'precision': 0.6228099730458221, 'recall': 0.611111111111111, 'f1-score': 0.6016237948397674, 'support': 162}, 'weighted avg': {'precision': 0.6228099730458221, 'recall': 0.6111111111111112, 'f1-score': 0.6016237948397674, 'support': 162}}}\n\n Classifier: RandomForest: \n\nVAL Eval results:\n  acc=0.5679  prec=0.5591  recall=0.6420  f1=0.5977\n  roc_auc=0.6038\n  confusion_matrix: [[40, 41], [29, 52]]\nPredictions saved to: eval-VALSET/cw-cw-512-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/cw-cw-512-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.5679012345679012, 'precision': 0.5591397849462365, 'recall': 0.6419753086419753, 'f1': 0.5977011494252873, 'roc_auc': 0.6037951531778691, 'confusion_matrix': [[40, 41], [29, 52]], 'classification_report': {'0': {'precision': 0.5797101449275363, 'recall': 0.49382716049382713, 'f1-score': 0.5333333333333333, 'support': 81}, '1': {'precision': 0.5591397849462365, 'recall': 0.6419753086419753, 'f1-score': 0.5977011494252873, 'support': 81}, 'accuracy': 0.5679012345679012, 'macro avg': {'precision': 0.5694249649368863, 'recall': 0.5679012345679012, 'f1-score': 0.5655172413793104, 'support': 162}, 'weighted avg': {'precision': 0.5694249649368863, 'recall': 0.5679012345679012, 'f1-score': 0.5655172413793104, 'support': 162}}}\n_____________________\n\nAttack Method: fgsm\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.7346  prec=0.7714  recall=0.6667  f1=0.7152\n  roc_auc=0.8375\n  confusion_matrix: [[65, 16], [27, 54]]\nPredictions saved to: eval-VALSET/fgsm-cw-1024-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/fgsm-cw-1024-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.7345679012345679, 'precision': 0.7714285714285715, 'recall': 0.6666666666666666, 'f1': 0.7152317880794701, 'roc_auc': 0.8375247675659198, 'confusion_matrix': [[65, 16], [27, 54]], 'classification_report': {'0': {'precision': 0.7065217391304348, 'recall': 0.8024691358024691, 'f1-score': 0.7514450867052024, 'support': 81}, '1': {'precision': 0.7714285714285715, 'recall': 0.6666666666666666, 'f1-score': 0.7152317880794701, 'support': 81}, 'accuracy': 0.7345679012345679, 'macro avg': {'precision': 0.7389751552795032, 'recall': 0.7345679012345678, 'f1-score': 0.7333384373923362, 'support': 162}, 'weighted avg': {'precision': 0.7389751552795032, 'recall': 0.7345679012345679, 'f1-score': 0.7333384373923362, 'support': 162}}}\n\n Classifier: RandomForest: \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"VAL Eval results:\n  acc=0.8272  prec=0.8630  recall=0.7778  f1=0.8182\n  roc_auc=0.9370\n  confusion_matrix: [[71, 10], [18, 63]]\nPredictions saved to: eval-VALSET/fgsm-cw-1024-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/fgsm-cw-1024-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.8271604938271605, 'precision': 0.863013698630137, 'recall': 0.7777777777777778, 'f1': 0.8181818181818182, 'roc_auc': 0.9369760707209267, 'confusion_matrix': [[71, 10], [18, 63]], 'classification_report': {'0': {'precision': 0.797752808988764, 'recall': 0.8765432098765432, 'f1-score': 0.8352941176470587, 'support': 81}, '1': {'precision': 0.863013698630137, 'recall': 0.7777777777777778, 'f1-score': 0.8181818181818182, 'support': 81}, 'accuracy': 0.8271604938271605, 'macro avg': {'precision': 0.8303832538094504, 'recall': 0.8271604938271605, 'f1-score': 0.8267379679144384, 'support': 162}, 'weighted avg': {'precision': 0.8303832538094504, 'recall': 0.8271604938271605, 'f1-score': 0.8267379679144385, 'support': 162}}}\n_____________________\n\nAttack Method: bim\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.9938  prec=1.0000  recall=0.9877  f1=0.9938\n  roc_auc=1.0000\n  confusion_matrix: [[81, 0], [1, 80]]\nPredictions saved to: eval-VALSET/bim-cw-1024-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/bim-cw-1024-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.9938271604938271, 'precision': 1.0, 'recall': 0.9876543209876543, 'f1': 0.9937888198757764, 'roc_auc': 1.0, 'confusion_matrix': [[81, 0], [1, 80]], 'classification_report': {'0': {'precision': 0.9878048780487805, 'recall': 1.0, 'f1-score': 0.9938650306748467, 'support': 81}, '1': {'precision': 1.0, 'recall': 0.9876543209876543, 'f1-score': 0.9937888198757764, 'support': 81}, 'accuracy': 0.9938271604938271, 'macro avg': {'precision': 0.9939024390243902, 'recall': 0.9938271604938271, 'f1-score': 0.9938269252753116, 'support': 162}, 'weighted avg': {'precision': 0.9939024390243901, 'recall': 0.9938271604938271, 'f1-score': 0.9938269252753115, 'support': 162}}}\n\n Classifier: RandomForest: \n\nVAL Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[81, 0], [0, 81]]\nPredictions saved to: eval-VALSET/bim-cw-1024-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/bim-cw-1024-RandomForest_test_result.csv\nval metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'roc_auc': 1.0, 'confusion_matrix': [[81, 0], [0, 81]], 'classification_report': {'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162}}}\n_____________________\n\nAttack Method: pgd\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.9877  prec=1.0000  recall=0.9753  f1=0.9875\n  roc_auc=1.0000\n  confusion_matrix: [[81, 0], [2, 79]]\nPredictions saved to: eval-VALSET/pgd-cw-1024-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/pgd-cw-1024-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.9876543209876543, 'precision': 1.0, 'recall': 0.9753086419753086, 'f1': 0.9875, 'roc_auc': 1.0, 'confusion_matrix': [[81, 0], [2, 79]], 'classification_report': {'0': {'precision': 0.9759036144578314, 'recall': 1.0, 'f1-score': 0.9878048780487805, 'support': 81}, '1': {'precision': 1.0, 'recall': 0.9753086419753086, 'f1-score': 0.9875, 'support': 81}, 'accuracy': 0.9876543209876543, 'macro avg': {'precision': 0.9879518072289157, 'recall': 0.9876543209876543, 'f1-score': 0.9876524390243903, 'support': 162}, 'weighted avg': {'precision': 0.9879518072289158, 'recall': 0.9876543209876543, 'f1-score': 0.9876524390243903, 'support': 162}}}\n\n Classifier: RandomForest: \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"VAL Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\n  confusion_matrix: [[81, 0], [0, 81]]\nPredictions saved to: eval-VALSET/pgd-cw-1024-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/pgd-cw-1024-RandomForest_test_result.csv\nval metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'roc_auc': 1.0, 'confusion_matrix': [[81, 0], [0, 81]], 'classification_report': {'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162}}}\n_____________________\n\nAttack Method: df\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.5617  prec=0.5490  recall=0.6914  f1=0.6120\n  roc_auc=0.5574\n  confusion_matrix: [[35, 46], [25, 56]]\nPredictions saved to: eval-VALSET/df-cw-1024-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/df-cw-1024-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.5617283950617284, 'precision': 0.5490196078431373, 'recall': 0.691358024691358, 'f1': 0.6120218579234973, 'roc_auc': 0.557384545038866, 'confusion_matrix': [[35, 46], [25, 56]], 'classification_report': {'0': {'precision': 0.5833333333333334, 'recall': 0.43209876543209874, 'f1-score': 0.4964539007092198, 'support': 81}, '1': {'precision': 0.5490196078431373, 'recall': 0.691358024691358, 'f1-score': 0.6120218579234973, 'support': 81}, 'accuracy': 0.5617283950617284, 'macro avg': {'precision': 0.5661764705882353, 'recall': 0.5617283950617283, 'f1-score': 0.5542378793163585, 'support': 162}, 'weighted avg': {'precision': 0.5661764705882353, 'recall': 0.5617283950617284, 'f1-score': 0.5542378793163586, 'support': 162}}}\n\n Classifier: RandomForest: \n\nVAL Eval results:\n  acc=0.5370  prec=0.5312  recall=0.6296  f1=0.5763\n  roc_auc=0.5655\n  confusion_matrix: [[36, 45], [30, 51]]\nPredictions saved to: eval-VALSET/df-cw-1024-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/df-cw-1024-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.5370370370370371, 'precision': 0.53125, 'recall': 0.6296296296296297, 'f1': 0.5762711864406779, 'roc_auc': 0.5654625819234873, 'confusion_matrix': [[36, 45], [30, 51]], 'classification_report': {'0': {'precision': 0.5454545454545454, 'recall': 0.4444444444444444, 'f1-score': 0.4897959183673469, 'support': 81}, '1': {'precision': 0.53125, 'recall': 0.6296296296296297, 'f1-score': 0.5762711864406779, 'support': 81}, 'accuracy': 0.5370370370370371, 'macro avg': {'precision': 0.5383522727272727, 'recall': 0.537037037037037, 'f1-score': 0.5330335524040124, 'support': 162}, 'weighted avg': {'precision': 0.5383522727272727, 'recall': 0.5370370370370371, 'f1-score': 0.5330335524040124, 'support': 162}}}\n_____________________\n\nAttack Method: cw\n\n\n Classifier: LogisticRegression: \n\nVAL Eval results:\n  acc=0.5247  prec=0.5192  recall=0.6667  f1=0.5838\n  roc_auc=0.5322\n  confusion_matrix: [[31, 50], [27, 54]]\nPredictions saved to: eval-VALSET/cw-cw-1024-LogisticRegression_test_result_predictions.csv\nMetrics saved to: eval-VALSET/cw-cw-1024-LogisticRegression_test_result.csv\nval metrics: {'accuracy': 0.5246913580246914, 'precision': 0.5192307692307693, 'recall': 0.6666666666666666, 'f1': 0.5837837837837838, 'roc_auc': 0.532235939643347, 'confusion_matrix': [[31, 50], [27, 54]], 'classification_report': {'0': {'precision': 0.5344827586206896, 'recall': 0.38271604938271603, 'f1-score': 0.44604316546762585, 'support': 81}, '1': {'precision': 0.5192307692307693, 'recall': 0.6666666666666666, 'f1-score': 0.5837837837837838, 'support': 81}, 'accuracy': 0.5246913580246914, 'macro avg': {'precision': 0.5268567639257294, 'recall': 0.5246913580246914, 'f1-score': 0.5149134746257048, 'support': 162}, 'weighted avg': {'precision': 0.5268567639257294, 'recall': 0.5246913580246914, 'f1-score': 0.5149134746257049, 'support': 162}}}\n\n Classifier: RandomForest: \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"VAL Eval results:\n  acc=0.4815  prec=0.4828  recall=0.5185  f1=0.5000\n  roc_auc=0.5002\n  confusion_matrix: [[36, 45], [39, 42]]\nPredictions saved to: eval-VALSET/cw-cw-1024-RandomForest_test_result_predictions.csv\nMetrics saved to: eval-VALSET/cw-cw-1024-RandomForest_test_result.csv\nval metrics: {'accuracy': 0.48148148148148145, 'precision': 0.4827586206896552, 'recall': 0.5185185185185185, 'f1': 0.5, 'roc_auc': 0.5001524157902759, 'confusion_matrix': [[36, 45], [39, 42]], 'classification_report': {'0': {'precision': 0.48, 'recall': 0.4444444444444444, 'f1-score': 0.4615384615384615, 'support': 81}, '1': {'precision': 0.4827586206896552, 'recall': 0.5185185185185185, 'f1-score': 0.5, 'support': 81}, 'accuracy': 0.48148148148148145, 'macro avg': {'precision': 0.4813793103448276, 'recall': 0.48148148148148145, 'f1-score': 0.4807692307692307, 'support': 162}, 'weighted avg': {'precision': 0.4813793103448275, 'recall': 0.48148148148148145, 'f1-score': 0.4807692307692308, 'support': 162}}}\n_____________________\n\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluate Dataset (Test Set)","metadata":{}},{"cell_type":"code","source":"classifier = 'LogisticRegression'\nIMG_SIZES = [32, 64, 128, 256, 512, 1024]\n\nATTACKS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\nDATASETS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n\nfor IMG_SIZE in IMG_SIZES:\n    for ATTACK in ATTACKS:\n        for DATASET in DATASETS:\n            print(f'Evaluate Against Test Set (Image Size: {IMG_SIZE}) \\n Method: {ATTACK} \\n Dataset: {DATASET} \\n')\n            eval_test_from_npy(\n                test_clean_npy_path=f'/kaggle/input/detectlid/Dataset/{IMG_SIZE}x{IMG_SIZE}/{DATASET}/test_clean_raw.npy',\n                test_adv_npy_path=f'/kaggle/input/detectlid/Dataset/{IMG_SIZE}x{IMG_SIZE}/{DATASET}/test_adv_raw.npy',\n                model_out_dir=f\"/kaggle/working/models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n                test_labels_npy_path=None,\n                return_predictions=False,\n                use_mmap=False,\n                csv_path=f\"./eval/{ATTACK}-{DATASET}-{IMG_SIZE}-{classifier}_test_result.csv\"\n            )\n            print ('_________________________\\n')\n    \n        print ('===============================\\n')\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T14:42:07.475400Z","iopub.execute_input":"2025-10-19T14:42:07.475779Z","iopub.status.idle":"2025-10-19T14:42:10.123242Z","shell.execute_reply.started":"2025-10-19T14:42:07.475753Z","shell.execute_reply":"2025-10-19T14:42:10.121916Z"}},"outputs":[{"name":"stdout","text":"Evaluate Against Test Set (Image Size: 32) \n Method: fgsm \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5610  prec=0.5658  recall=0.5244  f1=0.5443\n  roc_auc=0.5709\nMetrics saved to: eval/fgsm-fgsm-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: fgsm \n Dataset: bim \n\nTEST Eval results:\n  acc=0.4024  prec=0.3400  recall=0.2073  f1=0.2576\n  roc_auc=0.3055\nMetrics saved to: eval/fgsm-bim-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: fgsm \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.4085  prec=0.3529  recall=0.2195  f1=0.2707\n  roc_auc=0.3349\nMetrics saved to: eval/fgsm-pgd-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: fgsm \n Dataset: df \n\nTEST Eval results:\n  acc=0.5061  prec=0.5075  recall=0.4146  f1=0.4564\n  roc_auc=0.5070\nMetrics saved to: eval/fgsm-df-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: fgsm \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5061  prec=0.5075  recall=0.4146  f1=0.4564\n  roc_auc=0.5083\nMetrics saved to: eval/fgsm-cw-32-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 32) \n Method: bim \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5183  prec=0.5405  recall=0.2439  f1=0.3361\n  roc_auc=0.5379\nMetrics saved to: eval/bim-fgsm-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: bim \n Dataset: bim \n\nTEST Eval results:\n  acc=0.6646  prec=0.7213  recall=0.5366  f1=0.6154\n  roc_auc=0.7249\nMetrics saved to: eval/bim-bim-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: bim \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.6402  prec=0.7018  recall=0.4878  f1=0.5755\n  roc_auc=0.6548\nMetrics saved to: eval/bim-pgd-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: bim \n Dataset: df \n\nTEST Eval results:\n  acc=0.5061  prec=0.5143  recall=0.2195  f1=0.3077\n  roc_auc=0.4988\nMetrics saved to: eval/bim-df-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: bim \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.2073  f1=0.2931\n  roc_auc=0.5022\nMetrics saved to: eval/bim-cw-32-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 32) \n Method: pgd \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5122  prec=0.5500  recall=0.1341  f1=0.2157\n  roc_auc=0.5498\nMetrics saved to: eval/pgd-fgsm-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: pgd \n Dataset: bim \n\nTEST Eval results:\n  acc=0.7256  prec=0.8364  recall=0.5610  f1=0.6715\n  roc_auc=0.8169\nMetrics saved to: eval/pgd-bim-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: pgd \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.6829  prec=0.8125  recall=0.4756  f1=0.6000\n  roc_auc=0.7479\nMetrics saved to: eval/pgd-pgd-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: pgd \n Dataset: df \n\nTEST Eval results:\n  acc=0.5061  prec=0.5263  recall=0.1220  f1=0.1980\n  roc_auc=0.4941\nMetrics saved to: eval/pgd-df-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: pgd \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.1098  f1=0.1800\n  roc_auc=0.4997\nMetrics saved to: eval/pgd-cw-32-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 32) \n Method: df \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5244  prec=0.5169  recall=0.7439  f1=0.6100\n  roc_auc=0.5208\nMetrics saved to: eval/df-fgsm-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: df \n Dataset: bim \n\nTEST Eval results:\n  acc=0.2256  prec=0.1739  recall=0.1463  f1=0.1589\n  roc_auc=0.1222\nMetrics saved to: eval/df-bim-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: df \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.2439  prec=0.2083  recall=0.1829  f1=0.1948\n  roc_auc=0.1404\nMetrics saved to: eval/df-pgd-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: df \n Dataset: df \n\nTEST Eval results:\n  acc=0.5305  prec=0.5210  recall=0.7561  f1=0.6169\n  roc_auc=0.5431\nMetrics saved to: eval/df-df-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: df \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5244  prec=0.5169  recall=0.7439  f1=0.6100\n  roc_auc=0.5405\nMetrics saved to: eval/df-cw-32-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 32) \n Method: cw \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5183  prec=0.5126  recall=0.7439  f1=0.6070\n  roc_auc=0.5198\nMetrics saved to: eval/cw-fgsm-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: cw \n Dataset: bim \n\nTEST Eval results:\n  acc=0.2195  prec=0.1714  recall=0.1463  f1=0.1579\n  roc_auc=0.1179\nMetrics saved to: eval/cw-bim-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: cw \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.2439  prec=0.2162  recall=0.1951  f1=0.2051\n  roc_auc=0.1475\nMetrics saved to: eval/cw-pgd-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: cw \n Dataset: df \n\nTEST Eval results:\n  acc=0.5122  prec=0.5085  recall=0.7317  f1=0.6000\n  roc_auc=0.5409\nMetrics saved to: eval/cw-df-32-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: cw \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5122  prec=0.5085  recall=0.7317  f1=0.6000\n  roc_auc=0.5399\nMetrics saved to: eval/cw-cw-32-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 64) \n Method: fgsm \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5671  prec=0.5846  recall=0.4634  f1=0.5170\n  roc_auc=0.5784\nMetrics saved to: eval/fgsm-fgsm-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: fgsm \n Dataset: bim \n\nTEST Eval results:\n  acc=0.4756  prec=0.4600  recall=0.2805  f1=0.3485\n  roc_auc=0.3943\nMetrics saved to: eval/fgsm-bim-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: fgsm \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.4756  prec=0.4600  recall=0.2805  f1=0.3485\n  roc_auc=0.3864\nMetrics saved to: eval/fgsm-pgd-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: fgsm \n Dataset: df \n\nTEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.3293  f1=0.3971\n  roc_auc=0.5076\nMetrics saved to: eval/fgsm-df-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: fgsm \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5061  prec=0.5091  recall=0.3415  f1=0.4088\n  roc_auc=0.5067\nMetrics saved to: eval/fgsm-cw-64-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 64) \n Method: bim \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.4939  prec=0.4444  recall=0.0488  f1=0.0879\n  roc_auc=0.5217\nMetrics saved to: eval/bim-fgsm-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: bim \n Dataset: bim \n\nTEST Eval results:\n  acc=0.7988  prec=0.9153  recall=0.6585  f1=0.7660\n  roc_auc=0.9048\nMetrics saved to: eval/bim-bim-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: bim \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.7988  prec=0.9153  recall=0.6585  f1=0.7660\n  roc_auc=0.9076\nMetrics saved to: eval/bim-pgd-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: bim \n Dataset: df \n\nTEST Eval results:\n  acc=0.4939  prec=0.4444  recall=0.0488  f1=0.0879\n  roc_auc=0.4703\nMetrics saved to: eval/bim-df-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: bim \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.0610  f1=0.1087\n  roc_auc=0.4820\nMetrics saved to: eval/bim-cw-64-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 64) \n Method: pgd \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.4817  prec=0.2857  recall=0.0244  f1=0.0449\n  roc_auc=0.5241\nMetrics saved to: eval/pgd-fgsm-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: pgd \n Dataset: bim \n\nTEST Eval results:\n  acc=0.7927  prec=0.9138  recall=0.6463  f1=0.7571\n  roc_auc=0.9010\nMetrics saved to: eval/pgd-bim-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: pgd \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.7805  prec=0.9107  recall=0.6220  f1=0.7391\n  roc_auc=0.9035\nMetrics saved to: eval/pgd-pgd-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: pgd \n Dataset: df \n\nTEST Eval results:\n  acc=0.4939  prec=0.4444  recall=0.0488  f1=0.0879\n  roc_auc=0.4710\nMetrics saved to: eval/pgd-df-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: pgd \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.0610  f1=0.1087\n  roc_auc=0.4819\nMetrics saved to: eval/pgd-cw-64-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 64) \n Method: df \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5244  prec=0.5189  recall=0.6707  f1=0.5851\n  roc_auc=0.5144\nMetrics saved to: eval/df-fgsm-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: df \n Dataset: bim \n\nTEST Eval results:\n  acc=0.1890  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0165\nMetrics saved to: eval/df-bim-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: df \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.1890  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0147\nMetrics saved to: eval/df-pgd-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: df \n Dataset: df \n\nTEST Eval results:\n  acc=0.5915  prec=0.5641  recall=0.8049  f1=0.6633\n  roc_auc=0.5906\nMetrics saved to: eval/df-df-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: df \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5671  prec=0.5487  recall=0.7561  f1=0.6359\n  roc_auc=0.5738\nMetrics saved to: eval/df-cw-64-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 64) \n Method: cw \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5061  prec=0.5046  recall=0.6707  f1=0.5759\n  roc_auc=0.5155\nMetrics saved to: eval/cw-fgsm-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: cw \n Dataset: bim \n\nTEST Eval results:\n  acc=0.1707  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0165\nMetrics saved to: eval/cw-bim-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: cw \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.1707  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0149\nMetrics saved to: eval/cw-pgd-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: cw \n Dataset: df \n\nTEST Eval results:\n  acc=0.5854  prec=0.5574  recall=0.8293  f1=0.6667\n  roc_auc=0.5947\nMetrics saved to: eval/cw-df-64-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: cw \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5671  prec=0.5462  recall=0.7927  f1=0.6468\n  roc_auc=0.5741\nMetrics saved to: eval/cw-cw-64-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 128) \n Method: fgsm \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5976  prec=0.6000  recall=0.5854  f1=0.5926\n  roc_auc=0.6466\nMetrics saved to: eval/fgsm-fgsm-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: fgsm \n Dataset: bim \n\nTEST Eval results:\n  acc=0.3049  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0123\nMetrics saved to: eval/fgsm-bim-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: fgsm \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.3049  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0048\nMetrics saved to: eval/fgsm-pgd-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: fgsm \n Dataset: df \n\nTEST Eval results:\n  acc=0.5671  prec=0.5733  recall=0.5244  f1=0.5478\n  roc_auc=0.5758\nMetrics saved to: eval/fgsm-df-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: fgsm \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5549  prec=0.5616  recall=0.5000  f1=0.5290\n  roc_auc=0.5709\nMetrics saved to: eval/fgsm-cw-128-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 128) \n Method: bim \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.4817  prec=0.2857  recall=0.0244  f1=0.0449\n  roc_auc=0.5431\nMetrics saved to: eval/bim-fgsm-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: bim \n Dataset: bim \n\nTEST Eval results:\n  acc=0.8537  prec=0.9265  recall=0.7683  f1=0.8400\n  roc_auc=0.9383\nMetrics saved to: eval/bim-bim-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: bim \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.8659  prec=0.9286  recall=0.7927  f1=0.8553\n  roc_auc=0.9514\nMetrics saved to: eval/bim-pgd-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: bim \n Dataset: df \n\nTEST Eval results:\n  acc=0.4939  prec=0.4444  recall=0.0488  f1=0.0879\n  roc_auc=0.4707\nMetrics saved to: eval/bim-df-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: bim \n Dataset: cw \n\nTEST Eval results:\n  acc=0.4939  prec=0.4444  recall=0.0488  f1=0.0879\n  roc_auc=0.4775\nMetrics saved to: eval/bim-cw-128-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 128) \n Method: pgd \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.0244  f1=0.0465\n  roc_auc=0.5549\nMetrics saved to: eval/pgd-fgsm-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: pgd \n Dataset: bim \n\nTEST Eval results:\n  acc=0.8598  prec=0.9683  recall=0.7439  f1=0.8414\n  roc_auc=0.9421\nMetrics saved to: eval/pgd-bim-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: pgd \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.8720  prec=0.9692  recall=0.7683  f1=0.8571\n  roc_auc=0.9542\nMetrics saved to: eval/pgd-pgd-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: pgd \n Dataset: df \n\nTEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.0244  f1=0.0465\n  roc_auc=0.4667\nMetrics saved to: eval/pgd-df-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: pgd \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.0244  f1=0.0465\n  roc_auc=0.4707\nMetrics saved to: eval/pgd-cw-128-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 128) \n Method: df \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.6098  prec=0.5938  recall=0.6951  f1=0.6404\n  roc_auc=0.6463\nMetrics saved to: eval/df-fgsm-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: df \n Dataset: bim \n\nTEST Eval results:\n  acc=0.2622  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0004\nMetrics saved to: eval/df-bim-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: df \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.2622  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0000\nMetrics saved to: eval/df-pgd-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: df \n Dataset: df \n\nTEST Eval results:\n  acc=0.6585  prec=0.6250  recall=0.7927  f1=0.6989\n  roc_auc=0.7136\nMetrics saved to: eval/df-df-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: df \n Dataset: cw \n\nTEST Eval results:\n  acc=0.6402  prec=0.6139  recall=0.7561  f1=0.6776\n  roc_auc=0.6907\nMetrics saved to: eval/df-cw-128-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 128) \n Method: cw \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5976  prec=0.5800  recall=0.7073  f1=0.6374\n  roc_auc=0.6474\nMetrics saved to: eval/cw-fgsm-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: cw \n Dataset: bim \n\nTEST Eval results:\n  acc=0.2439  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0006\nMetrics saved to: eval/cw-bim-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: cw \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.2439  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0000\nMetrics saved to: eval/cw-pgd-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: cw \n Dataset: df \n\nTEST Eval results:\n  acc=0.6463  prec=0.6111  recall=0.8049  f1=0.6947\n  roc_auc=0.7112\nMetrics saved to: eval/cw-df-128-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: cw \n Dataset: cw \n\nTEST Eval results:\n  acc=0.6280  prec=0.6000  recall=0.7683  f1=0.6738\n  roc_auc=0.6883\nMetrics saved to: eval/cw-cw-128-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 256) \n Method: fgsm \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5976  prec=0.6081  recall=0.5488  f1=0.5769\n  roc_auc=0.6730\nMetrics saved to: eval/fgsm-fgsm-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: fgsm \n Dataset: bim \n\nTEST Eval results:\n  acc=0.3293  prec=0.0333  recall=0.0122  f1=0.0179\n  roc_auc=0.0128\nMetrics saved to: eval/fgsm-bim-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: fgsm \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.3293  prec=0.0333  recall=0.0122  f1=0.0179\n  roc_auc=0.0122\nMetrics saved to: eval/fgsm-pgd-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: fgsm \n Dataset: df \n\nTEST Eval results:\n  acc=0.5305  prec=0.5397  recall=0.4146  f1=0.4690\n  roc_auc=0.5458\nMetrics saved to: eval/fgsm-df-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: fgsm \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5122  prec=0.5167  recall=0.3780  f1=0.4366\n  roc_auc=0.5156\nMetrics saved to: eval/fgsm-cw-256-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 256) \n Method: bim \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.4878  prec=0.3750  recall=0.0366  f1=0.0667\n  roc_auc=0.5407\nMetrics saved to: eval/bim-fgsm-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: bim \n Dataset: bim \n\nTEST Eval results:\n  acc=0.9329  prec=0.9383  recall=0.9268  f1=0.9325\n  roc_auc=0.9695\nMetrics saved to: eval/bim-bim-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: bim \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.9451  prec=0.9398  recall=0.9512  f1=0.9455\n  roc_auc=0.9781\nMetrics saved to: eval/bim-pgd-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: bim \n Dataset: df \n\nTEST Eval results:\n  acc=0.4939  prec=0.4444  recall=0.0488  f1=0.0879\n  roc_auc=0.4872\nMetrics saved to: eval/bim-df-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: bim \n Dataset: cw \n\nTEST Eval results:\n  acc=0.4939  prec=0.4444  recall=0.0488  f1=0.0879\n  roc_auc=0.4891\nMetrics saved to: eval/bim-cw-256-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 256) \n Method: pgd \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.4939  prec=0.4800  recall=0.1463  f1=0.2243\n  roc_auc=0.5367\nMetrics saved to: eval/pgd-fgsm-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: pgd \n Dataset: bim \n\nTEST Eval results:\n  acc=0.8110  prec=0.8312  recall=0.7805  f1=0.8050\n  roc_auc=0.9057\nMetrics saved to: eval/pgd-bim-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: pgd \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.8537  prec=0.8452  recall=0.8659  f1=0.8554\n  roc_auc=0.9295\nMetrics saved to: eval/pgd-pgd-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: pgd \n Dataset: df \n\nTEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.1585  f1=0.2407\n  roc_auc=0.4899\nMetrics saved to: eval/pgd-df-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: pgd \n Dataset: cw \n\nTEST Eval results:\n  acc=0.4939  prec=0.4800  recall=0.1463  f1=0.2243\n  roc_auc=0.4927\nMetrics saved to: eval/pgd-cw-256-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 256) \n Method: df \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5793  prec=0.5730  recall=0.6220  f1=0.5965\n  roc_auc=0.5919\nMetrics saved to: eval/df-fgsm-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: df \n Dataset: bim \n\nTEST Eval results:\n  acc=0.2683  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0000\nMetrics saved to: eval/df-bim-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: df \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.2683  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0000\nMetrics saved to: eval/df-pgd-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: df \n Dataset: df \n\nTEST Eval results:\n  acc=0.6951  prec=0.6481  recall=0.8537  f1=0.7368\n  roc_auc=0.6795\nMetrics saved to: eval/df-df-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: df \n Dataset: cw \n\nTEST Eval results:\n  acc=0.6402  prec=0.6162  recall=0.7439  f1=0.6740\n  roc_auc=0.6359\nMetrics saved to: eval/df-cw-256-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 256) \n Method: cw \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5732  prec=0.5682  recall=0.6098  f1=0.5882\n  roc_auc=0.5641\nMetrics saved to: eval/cw-fgsm-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: cw \n Dataset: bim \n\nTEST Eval results:\n  acc=0.2683  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0000\nMetrics saved to: eval/cw-bim-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: cw \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.2683  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0000\nMetrics saved to: eval/cw-pgd-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: cw \n Dataset: df \n\nTEST Eval results:\n  acc=0.6829  prec=0.6415  recall=0.8293  f1=0.7234\n  roc_auc=0.6807\nMetrics saved to: eval/cw-df-256-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: cw \n Dataset: cw \n\nTEST Eval results:\n  acc=0.6402  prec=0.6162  recall=0.7439  f1=0.6740\n  roc_auc=0.6456\nMetrics saved to: eval/cw-cw-256-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 512) \n Method: fgsm \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.6890  prec=0.6914  recall=0.6829  f1=0.6871\n  roc_auc=0.7394\nMetrics saved to: eval/fgsm-fgsm-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: fgsm \n Dataset: bim \n\nTEST Eval results:\n  acc=0.8476  prec=0.7664  recall=1.0000  f1=0.8677\n  roc_auc=1.0000\nMetrics saved to: eval/fgsm-bim-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: fgsm \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.8476  prec=0.7664  recall=1.0000  f1=0.8677\n  roc_auc=1.0000\nMetrics saved to: eval/fgsm-pgd-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: fgsm \n Dataset: df \n\nTEST Eval results:\n  acc=0.4573  prec=0.4186  recall=0.2195  f1=0.2880\n  roc_auc=0.4325\nMetrics saved to: eval/fgsm-df-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: fgsm \n Dataset: cw \n\nTEST Eval results:\n  acc=0.4573  prec=0.4186  recall=0.2195  f1=0.2880\n  roc_auc=0.4355\nMetrics saved to: eval/fgsm-cw-512-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 512) \n Method: bim \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5061  prec=0.6000  recall=0.0366  f1=0.0690\n  roc_auc=0.5790\nMetrics saved to: eval/bim-fgsm-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: bim \n Dataset: bim \n\nTEST Eval results:\n  acc=0.9329  prec=0.9733  recall=0.8902  f1=0.9299\n  roc_auc=0.9856\nMetrics saved to: eval/bim-bim-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: bim \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.9451  prec=0.9740  recall=0.9146  f1=0.9434\n  roc_auc=0.9909\nMetrics saved to: eval/bim-pgd-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: bim \n Dataset: df \n\nTEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.0244  f1=0.0465\n  roc_auc=0.4903\nMetrics saved to: eval/bim-df-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: bim \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.0244  f1=0.0465\n  roc_auc=0.4970\nMetrics saved to: eval/bim-cw-512-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 512) \n Method: pgd \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5183  prec=0.7143  recall=0.0610  f1=0.1124\n  roc_auc=0.5797\nMetrics saved to: eval/pgd-fgsm-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: pgd \n Dataset: bim \n\nTEST Eval results:\n  acc=0.8963  prec=0.9710  recall=0.8171  f1=0.8874\n  roc_auc=0.9706\nMetrics saved to: eval/pgd-bim-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: pgd \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.9146  prec=0.9722  recall=0.8537  f1=0.9091\n  roc_auc=0.9789\nMetrics saved to: eval/pgd-pgd-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: pgd \n Dataset: df \n\nTEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.0244  f1=0.0465\n  roc_auc=0.4908\nMetrics saved to: eval/pgd-df-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: pgd \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.0244  f1=0.0465\n  roc_auc=0.4994\nMetrics saved to: eval/pgd-cw-512-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 512) \n Method: df \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.4146  prec=0.3793  recall=0.2683  f1=0.3143\n  roc_auc=0.3473\nMetrics saved to: eval/df-fgsm-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: df \n Dataset: bim \n\nTEST Eval results:\n  acc=0.2805  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0000\nMetrics saved to: eval/df-bim-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: df \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.2805  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0000\nMetrics saved to: eval/df-pgd-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: df \n Dataset: df \n\nTEST Eval results:\n  acc=0.6463  prec=0.6250  recall=0.7317  f1=0.6742\n  roc_auc=0.6471\nMetrics saved to: eval/df-df-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: df \n Dataset: cw \n\nTEST Eval results:\n  acc=0.6098  prec=0.6000  recall=0.6585  f1=0.6279\n  roc_auc=0.6129\nMetrics saved to: eval/df-cw-512-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 512) \n Method: cw \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.3720  prec=0.3385  recall=0.2683  f1=0.2993\n  roc_auc=0.3238\nMetrics saved to: eval/cw-fgsm-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: cw \n Dataset: bim \n\nTEST Eval results:\n  acc=0.2378  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0000\nMetrics saved to: eval/cw-bim-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: cw \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.2378  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0000\nMetrics saved to: eval/cw-pgd-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: cw \n Dataset: df \n\nTEST Eval results:\n  acc=0.6159  prec=0.5905  recall=0.7561  f1=0.6631\n  roc_auc=0.6420\nMetrics saved to: eval/cw-df-512-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: cw \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5793  prec=0.5657  recall=0.6829  f1=0.6188\n  roc_auc=0.6093\nMetrics saved to: eval/cw-cw-512-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: fgsm \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.7500  prec=0.7595  recall=0.7317  f1=0.7453\n  roc_auc=0.8370\nMetrics saved to: eval/fgsm-fgsm-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: fgsm \n Dataset: bim \n\nTEST Eval results:\n  acc=0.8841  prec=0.8119  recall=1.0000  f1=0.8962\n  roc_auc=1.0000\nMetrics saved to: eval/fgsm-bim-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: fgsm \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.8841  prec=0.8119  recall=1.0000  f1=0.8962\n  roc_auc=1.0000\nMetrics saved to: eval/fgsm-pgd-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: fgsm \n Dataset: df \n\nTEST Eval results:\n  acc=0.4756  prec=0.4412  recall=0.1829  f1=0.2586\n  roc_auc=0.4786\nMetrics saved to: eval/fgsm-df-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: fgsm \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.2317  f1=0.3167\n  roc_auc=0.4857\nMetrics saved to: eval/fgsm-cw-1024-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: bim \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.6336\nMetrics saved to: eval/bim-fgsm-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: bim \n Dataset: bim \n\nTEST Eval results:\n  acc=0.9817  prec=1.0000  recall=0.9634  f1=0.9814\n  roc_auc=0.9996\nMetrics saved to: eval/bim-bim-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: bim \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.9817  prec=1.0000  recall=0.9634  f1=0.9814\n  roc_auc=1.0000\nMetrics saved to: eval/bim-pgd-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: bim \n Dataset: df \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.4952\nMetrics saved to: eval/bim-df-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: bim \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.5024\nMetrics saved to: eval/bim-cw-1024-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: pgd \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.6686\nMetrics saved to: eval/pgd-fgsm-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: pgd \n Dataset: bim \n\nTEST Eval results:\n  acc=0.9756  prec=1.0000  recall=0.9512  f1=0.9750\n  roc_auc=1.0000\nMetrics saved to: eval/pgd-bim-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: pgd \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.9756  prec=1.0000  recall=0.9512  f1=0.9750\n  roc_auc=1.0000\nMetrics saved to: eval/pgd-pgd-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: pgd \n Dataset: df \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.4936\nMetrics saved to: eval/pgd-df-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: pgd \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.4997\nMetrics saved to: eval/pgd-cw-1024-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: df \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.2866  prec=0.1818  recall=0.1220  f1=0.1460\n  roc_auc=0.1747\nMetrics saved to: eval/df-fgsm-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: df \n Dataset: bim \n\nTEST Eval results:\n  acc=0.2256  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0000\nMetrics saved to: eval/df-bim-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: df \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.2256  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0000\nMetrics saved to: eval/df-pgd-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: df \n Dataset: df \n\nTEST Eval results:\n  acc=0.5488  prec=0.5408  recall=0.6463  f1=0.5889\n  roc_auc=0.5534\nMetrics saved to: eval/df-df-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: df \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5366  prec=0.5312  recall=0.6220  f1=0.5730\n  roc_auc=0.5287\nMetrics saved to: eval/df-cw-1024-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: cw \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.2927  prec=0.1731  recall=0.1098  f1=0.1343\n  roc_auc=0.1706\nMetrics saved to: eval/cw-fgsm-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: cw \n Dataset: bim \n\nTEST Eval results:\n  acc=0.2378  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0000\nMetrics saved to: eval/cw-bim-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: cw \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.2378  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0000\nMetrics saved to: eval/cw-pgd-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: cw \n Dataset: df \n\nTEST Eval results:\n  acc=0.5305  prec=0.5275  recall=0.5854  f1=0.5549\n  roc_auc=0.5448\nMetrics saved to: eval/cw-df-1024-LogisticRegression_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: cw \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5244  prec=0.5222  recall=0.5732  f1=0.5465\n  roc_auc=0.5286\nMetrics saved to: eval/cw-cw-1024-LogisticRegression_test_result.csv\n_________________________\n\n===============================\n\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"classifier = 'RandomForest'\nIMG_SIZES = [32, 64, 128, 256, 512, 1024]\n\nATTACKS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\nDATASETS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n\nfor IMG_SIZE in IMG_SIZES:\n    for ATTACK in ATTACKS:\n        for DATASET in DATASETS:\n            print(f'Evaluate Against Test Set (Image Size: {IMG_SIZE}) \\n Method: {ATTACK} \\n Dataset: {DATASET} \\n')\n            eval_test_from_npy(\n                test_clean_npy_path=f'/kaggle/input/detectlid/Dataset/{IMG_SIZE}x{IMG_SIZE}/{DATASET}/test_clean_raw.npy',\n                test_adv_npy_path=f'/kaggle/input/detectlid/Dataset/{IMG_SIZE}x{IMG_SIZE}/{DATASET}/test_adv_raw.npy',\n                model_out_dir=f\"/kaggle/working/models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n                test_labels_npy_path=None,\n                return_predictions=False,\n                use_mmap=False,\n                csv_path=f\"./eval/{ATTACK}-{DATASET}-{IMG_SIZE}-{classifier}_test_result.csv\"\n            )\n            print ('_________________________\\n')\n    \n        print ('===============================\\n')\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T13:56:51.482170Z","iopub.execute_input":"2025-10-19T13:56:51.482590Z","iopub.status.idle":"2025-10-19T13:57:11.272061Z","shell.execute_reply.started":"2025-10-19T13:56:51.482562Z","shell.execute_reply":"2025-10-19T13:57:11.269593Z"}},"outputs":[{"name":"stdout","text":"Evaluate Against Test Set (Image Size: 32) \n Method: fgsm \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5061  prec=0.5077  recall=0.4024  f1=0.4490\n  roc_auc=0.5318\nMetrics saved to: eval/fgsm-fgsm-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: fgsm \n Dataset: bim \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5305  prec=0.5362  recall=0.4512  f1=0.4901\n  roc_auc=0.5149\nMetrics saved to: eval/fgsm-bim-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: fgsm \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.5671  prec=0.5733  recall=0.5244  f1=0.5478\n  roc_auc=0.5456\nMetrics saved to: eval/fgsm-pgd-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: fgsm \n Dataset: df \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.4878  prec=0.4839  recall=0.3659  f1=0.4167\n  roc_auc=0.4894\nMetrics saved to: eval/fgsm-df-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: fgsm \n Dataset: cw \n\nTEST Eval results:\n  acc=0.4878  prec=0.4839  recall=0.3659  f1=0.4167\n  roc_auc=0.5008\nMetrics saved to: eval/fgsm-cw-32-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 32) \n Method: bim \n Dataset: fgsm \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.4878  prec=0.4583  recall=0.1341  f1=0.2075\n  roc_auc=0.4744\nMetrics saved to: eval/bim-fgsm-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: bim \n Dataset: bim \n\nTEST Eval results:\n  acc=0.8110  prec=0.8312  recall=0.7805  f1=0.8050\n  roc_auc=0.8887\nMetrics saved to: eval/bim-bim-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: bim \n Dataset: pgd \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.7744  prec=0.8169  recall=0.7073  f1=0.7582\n  roc_auc=0.8623\nMetrics saved to: eval/bim-pgd-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: bim \n Dataset: df \n\nTEST Eval results:\n  acc=0.4878  prec=0.4583  recall=0.1341  f1=0.2075\n  roc_auc=0.4861\nMetrics saved to: eval/bim-df-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: bim \n Dataset: cw \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.4878  prec=0.4583  recall=0.1341  f1=0.2075\n  roc_auc=0.4985\nMetrics saved to: eval/bim-cw-32-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 32) \n Method: pgd \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.4695  prec=0.4074  recall=0.1341  f1=0.2018\n  roc_auc=0.4606\nMetrics saved to: eval/pgd-fgsm-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: pgd \n Dataset: bim \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.7988  prec=0.8025  recall=0.7927  f1=0.7975\n  roc_auc=0.8919\nMetrics saved to: eval/pgd-bim-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: pgd \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.7683  prec=0.7895  recall=0.7317  f1=0.7595\n  roc_auc=0.8655\nMetrics saved to: eval/pgd-pgd-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: pgd \n Dataset: df \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.4817  prec=0.4483  recall=0.1585  f1=0.2342\n  roc_auc=0.4553\nMetrics saved to: eval/pgd-df-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: pgd \n Dataset: cw \n\nTEST Eval results:\n  acc=0.4817  prec=0.4483  recall=0.1585  f1=0.2342\n  roc_auc=0.4679\nMetrics saved to: eval/pgd-cw-32-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 32) \n Method: df \n Dataset: fgsm \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5549  prec=0.5556  recall=0.5488  f1=0.5521\n  roc_auc=0.5286\nMetrics saved to: eval/df-fgsm-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: df \n Dataset: bim \n\nTEST Eval results:\n  acc=0.3354  prec=0.2000  recall=0.1098  f1=0.1417\n  roc_auc=0.2037\nMetrics saved to: eval/df-bim-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: df \n Dataset: pgd \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.3659  prec=0.2800  recall=0.1707  f1=0.2121\n  roc_auc=0.2429\nMetrics saved to: eval/df-pgd-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: df \n Dataset: df \n\nTEST Eval results:\n  acc=0.4939  prec=0.4930  recall=0.4268  f1=0.4575\n  roc_auc=0.5066\nMetrics saved to: eval/df-df-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: df \n Dataset: cw \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5305  prec=0.5325  recall=0.5000  f1=0.5157\n  roc_auc=0.5127\nMetrics saved to: eval/df-cw-32-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 32) \n Method: cw \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.4939  prec=0.4940  recall=0.5000  f1=0.4970\n  roc_auc=0.4819\nMetrics saved to: eval/cw-fgsm-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: cw \n Dataset: bim \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.2927  prec=0.1600  recall=0.0976  f1=0.1212\n  roc_auc=0.1465\nMetrics saved to: eval/cw-bim-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: cw \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.3293  prec=0.2500  recall=0.1707  f1=0.2029\n  roc_auc=0.2107\nMetrics saved to: eval/cw-pgd-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: cw \n Dataset: df \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.4817  prec=0.4815  recall=0.4756  f1=0.4785\n  roc_auc=0.4852\nMetrics saved to: eval/cw-df-32-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 32) \n Method: cw \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.5122  f1=0.5060\n  roc_auc=0.5101\nMetrics saved to: eval/cw-cw-32-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 64) \n Method: fgsm \n Dataset: fgsm \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5549  prec=0.5517  recall=0.5854  f1=0.5680\n  roc_auc=0.5950\nMetrics saved to: eval/fgsm-fgsm-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: fgsm \n Dataset: bim \n\nTEST Eval results:\n  acc=0.4695  prec=0.4658  recall=0.4146  f1=0.4387\n  roc_auc=0.4628\nMetrics saved to: eval/fgsm-bim-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: fgsm \n Dataset: pgd \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.4573  prec=0.4507  recall=0.3902  f1=0.4183\n  roc_auc=0.4601\nMetrics saved to: eval/fgsm-pgd-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: fgsm \n Dataset: df \n\nTEST Eval results:\n  acc=0.5244  prec=0.5244  recall=0.5244  f1=0.5244\n  roc_auc=0.5143\nMetrics saved to: eval/fgsm-df-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: fgsm \n Dataset: cw \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.4756  prec=0.4730  recall=0.4268  f1=0.4487\n  roc_auc=0.4833\nMetrics saved to: eval/fgsm-cw-64-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 64) \n Method: bim \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.0854  f1=0.1458\n  roc_auc=0.5020\nMetrics saved to: eval/bim-fgsm-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: bim \n Dataset: bim \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.9390  prec=0.9186  recall=0.9634  f1=0.9405\n  roc_auc=0.9701\nMetrics saved to: eval/bim-bim-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: bim \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.9512  prec=0.9205  recall=0.9878  f1=0.9529\n  roc_auc=0.9728\nMetrics saved to: eval/bim-pgd-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: bim \n Dataset: df \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.4817  prec=0.3636  recall=0.0488  f1=0.0860\n  roc_auc=0.4448\nMetrics saved to: eval/bim-df-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: bim \n Dataset: cw \n\nTEST Eval results:\n  acc=0.4878  prec=0.4167  recall=0.0610  f1=0.1064\n  roc_auc=0.4617\nMetrics saved to: eval/bim-cw-64-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 64) \n Method: pgd \n Dataset: fgsm \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.0854  f1=0.1458\n  roc_auc=0.5071\nMetrics saved to: eval/pgd-fgsm-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: pgd \n Dataset: bim \n\nTEST Eval results:\n  acc=0.9329  prec=0.9176  recall=0.9512  f1=0.9341\n  roc_auc=0.9694\nMetrics saved to: eval/pgd-bim-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: pgd \n Dataset: pgd \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.9512  prec=0.9205  recall=0.9878  f1=0.9529\n  roc_auc=0.9735\nMetrics saved to: eval/pgd-pgd-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: pgd \n Dataset: df \n\nTEST Eval results:\n  acc=0.4756  prec=0.3000  recall=0.0366  f1=0.0652\n  roc_auc=0.4466\nMetrics saved to: eval/pgd-df-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: pgd \n Dataset: cw \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.4939  prec=0.4615  recall=0.0732  f1=0.1263\n  roc_auc=0.4627\nMetrics saved to: eval/pgd-cw-64-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 64) \n Method: df \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.4939  prec=0.4935  recall=0.4634  f1=0.4780\n  roc_auc=0.5135\nMetrics saved to: eval/df-fgsm-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: df \n Dataset: bim \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.2622  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.1064\nMetrics saved to: eval/df-bim-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: df \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.2683  prec=0.0250  recall=0.0122  f1=0.0164\n  roc_auc=0.1130\nMetrics saved to: eval/df-pgd-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: df \n Dataset: df \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5427  prec=0.5412  recall=0.5610  f1=0.5509\n  roc_auc=0.5692\nMetrics saved to: eval/df-df-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: df \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5244  prec=0.5244  recall=0.5244  f1=0.5244\n  roc_auc=0.5455\nMetrics saved to: eval/df-cw-64-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 64) \n Method: cw \n Dataset: fgsm \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5305  prec=0.5342  recall=0.4756  f1=0.5032\n  roc_auc=0.4960\nMetrics saved to: eval/cw-fgsm-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: cw \n Dataset: bim \n\nTEST Eval results:\n  acc=0.3049  prec=0.0556  recall=0.0244  f1=0.0339\n  roc_auc=0.1576\nMetrics saved to: eval/cw-bim-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: cw \n Dataset: pgd \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.3110  prec=0.0811  recall=0.0366  f1=0.0504\n  roc_auc=0.1661\nMetrics saved to: eval/cw-pgd-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: cw \n Dataset: df \n\nTEST Eval results:\n  acc=0.5366  prec=0.5405  recall=0.4878  f1=0.5128\n  roc_auc=0.5368\nMetrics saved to: eval/cw-df-64-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 64) \n Method: cw \n Dataset: cw \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5244  prec=0.5278  recall=0.4634  f1=0.4935\n  roc_auc=0.5257\nMetrics saved to: eval/cw-cw-64-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 128) \n Method: fgsm \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.6402  prec=0.6211  recall=0.7195  f1=0.6667\n  roc_auc=0.6776\nMetrics saved to: eval/fgsm-fgsm-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: fgsm \n Dataset: bim \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.3049  prec=0.1000  recall=0.0488  f1=0.0656\n  roc_auc=0.2823\nMetrics saved to: eval/fgsm-bim-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: fgsm \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.3232  prec=0.1628  recall=0.0854  f1=0.1120\n  roc_auc=0.2892\nMetrics saved to: eval/fgsm-pgd-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: fgsm \n Dataset: df \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5732  prec=0.5714  recall=0.5854  f1=0.5783\n  roc_auc=0.6101\nMetrics saved to: eval/fgsm-df-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: fgsm \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5854  prec=0.5814  recall=0.6098  f1=0.5952\n  roc_auc=0.5982\nMetrics saved to: eval/fgsm-cw-128-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 128) \n Method: bim \n Dataset: fgsm \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.4959\nMetrics saved to: eval/bim-fgsm-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: bim \n Dataset: bim \n\nTEST Eval results:\n  acc=0.9695  prec=1.0000  recall=0.9390  f1=0.9686\n  roc_auc=0.9998\nMetrics saved to: eval/bim-bim-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: bim \n Dataset: pgd \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\nMetrics saved to: eval/bim-pgd-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: bim \n Dataset: df \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.4308\nMetrics saved to: eval/bim-df-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: bim \n Dataset: cw \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.4457\nMetrics saved to: eval/bim-cw-128-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 128) \n Method: pgd \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.5100\nMetrics saved to: eval/pgd-fgsm-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: pgd \n Dataset: bim \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.9634  prec=1.0000  recall=0.9268  f1=0.9620\n  roc_auc=0.9984\nMetrics saved to: eval/pgd-bim-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: pgd \n Dataset: pgd \n\nTEST Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\nMetrics saved to: eval/pgd-pgd-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: pgd \n Dataset: df \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.4731\nMetrics saved to: eval/pgd-df-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: pgd \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.4830\nMetrics saved to: eval/pgd-cw-128-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 128) \n Method: df \n Dataset: fgsm \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.6037  prec=0.5934  recall=0.6585  f1=0.6243\n  roc_auc=0.6229\nMetrics saved to: eval/df-fgsm-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: df \n Dataset: bim \n\nTEST Eval results:\n  acc=0.2744  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.1449\nMetrics saved to: eval/df-bim-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: df \n Dataset: pgd \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.2744  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.1534\nMetrics saved to: eval/df-pgd-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: df \n Dataset: df \n\nTEST Eval results:\n  acc=0.6707  prec=0.6373  recall=0.7927  f1=0.7065\n  roc_auc=0.6806\nMetrics saved to: eval/df-df-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: df \n Dataset: cw \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.6280  prec=0.6105  recall=0.7073  f1=0.6554\n  roc_auc=0.6608\nMetrics saved to: eval/df-cw-128-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 128) \n Method: cw \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.6098  prec=0.5957  recall=0.6829  f1=0.6364\n  roc_auc=0.6135\nMetrics saved to: eval/cw-fgsm-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: cw \n Dataset: bim \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.2744  prec=0.0256  recall=0.0122  f1=0.0165\n  roc_auc=0.1363\nMetrics saved to: eval/cw-bim-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: cw \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.2805  prec=0.0500  recall=0.0244  f1=0.0328\n  roc_auc=0.1398\nMetrics saved to: eval/cw-pgd-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: cw \n Dataset: df \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.6341  prec=0.6122  recall=0.7317  f1=0.6667\n  roc_auc=0.6797\nMetrics saved to: eval/cw-df-128-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 128) \n Method: cw \n Dataset: cw \n\nTEST Eval results:\n  acc=0.6220  prec=0.6042  recall=0.7073  f1=0.6517\n  roc_auc=0.6538\nMetrics saved to: eval/cw-cw-128-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 256) \n Method: fgsm \n Dataset: fgsm \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.7073  prec=0.6635  recall=0.8415  f1=0.7419\n  roc_auc=0.7677\nMetrics saved to: eval/fgsm-fgsm-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: fgsm \n Dataset: bim \n\nTEST Eval results:\n  acc=0.4695  prec=0.4615  recall=0.3659  f1=0.4082\n  roc_auc=0.4534\nMetrics saved to: eval/fgsm-bim-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: fgsm \n Dataset: pgd \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.4756  prec=0.4697  recall=0.3780  f1=0.4189\n  roc_auc=0.4442\nMetrics saved to: eval/fgsm-pgd-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: fgsm \n Dataset: df \n\nTEST Eval results:\n  acc=0.5244  prec=0.5270  recall=0.4756  f1=0.5000\n  roc_auc=0.5319\nMetrics saved to: eval/fgsm-df-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: fgsm \n Dataset: cw \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.4878  prec=0.4853  recall=0.4024  f1=0.4400\n  roc_auc=0.5033\nMetrics saved to: eval/fgsm-cw-256-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 256) \n Method: bim \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.4941\nMetrics saved to: eval/bim-fgsm-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: bim \n Dataset: bim \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.9939  prec=1.0000  recall=0.9878  f1=0.9939\n  roc_auc=0.9994\nMetrics saved to: eval/bim-bim-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: bim \n Dataset: pgd \n\nTEST Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\nMetrics saved to: eval/bim-pgd-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: bim \n Dataset: df \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.4904\nMetrics saved to: eval/bim-df-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: bim \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.5007\nMetrics saved to: eval/bim-cw-256-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 256) \n Method: pgd \n Dataset: fgsm \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.5242\nMetrics saved to: eval/pgd-fgsm-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: pgd \n Dataset: bim \n\nTEST Eval results:\n  acc=0.9939  prec=1.0000  recall=0.9878  f1=0.9939\n  roc_auc=0.9994\nMetrics saved to: eval/pgd-bim-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: pgd \n Dataset: pgd \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\nMetrics saved to: eval/pgd-pgd-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: pgd \n Dataset: df \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.4856\nMetrics saved to: eval/pgd-df-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: pgd \n Dataset: cw \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.4986\nMetrics saved to: eval/pgd-cw-256-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 256) \n Method: df \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5915  prec=0.5843  recall=0.6341  f1=0.6082\n  roc_auc=0.6292\nMetrics saved to: eval/df-fgsm-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: df \n Dataset: bim \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.2744  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.2026\nMetrics saved to: eval/df-bim-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: df \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.2744  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.1987\nMetrics saved to: eval/df-pgd-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: df \n Dataset: df \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.6646  prec=0.6337  recall=0.7805  f1=0.6995\n  roc_auc=0.7213\nMetrics saved to: eval/df-df-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: df \n Dataset: cw \n\nTEST Eval results:\n  acc=0.6220  prec=0.6064  recall=0.6951  f1=0.6477\n  roc_auc=0.6568\nMetrics saved to: eval/df-cw-256-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 256) \n Method: cw \n Dataset: fgsm \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5427  prec=0.5493  recall=0.4756  f1=0.5098\n  roc_auc=0.5422\nMetrics saved to: eval/cw-fgsm-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: cw \n Dataset: bim \n\nTEST Eval results:\n  acc=0.3354  prec=0.1351  recall=0.0610  f1=0.0840\n  roc_auc=0.2578\nMetrics saved to: eval/cw-bim-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: cw \n Dataset: pgd \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.3293  prec=0.1111  recall=0.0488  f1=0.0678\n  roc_auc=0.2695\nMetrics saved to: eval/cw-pgd-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: cw \n Dataset: df \n\nTEST Eval results:\n  acc=0.6341  prec=0.6279  recall=0.6585  f1=0.6429\n  roc_auc=0.6762\nMetrics saved to: eval/cw-df-256-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 256) \n Method: cw \n Dataset: cw \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.6524  prec=0.6404  recall=0.6951  f1=0.6667\n  roc_auc=0.6672\nMetrics saved to: eval/cw-cw-256-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 512) \n Method: fgsm \n Dataset: fgsm \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.7073  prec=0.6771  recall=0.7927  f1=0.7303\n  roc_auc=0.8106\nMetrics saved to: eval/fgsm-fgsm-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: fgsm \n Dataset: bim \n\nTEST Eval results:\n  acc=0.6402  prec=0.6353  recall=0.6585  f1=0.6467\n  roc_auc=0.7087\nMetrics saved to: eval/fgsm-bim-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: fgsm \n Dataset: pgd \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.6280  prec=0.6265  recall=0.6341  f1=0.6303\n  roc_auc=0.6831\nMetrics saved to: eval/fgsm-pgd-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: fgsm \n Dataset: df \n\nTEST Eval results:\n  acc=0.4573  prec=0.4364  recall=0.2927  f1=0.3504\n  roc_auc=0.4419\nMetrics saved to: eval/fgsm-df-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: fgsm \n Dataset: cw \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.4329  prec=0.3922  recall=0.2439  f1=0.3008\n  roc_auc=0.4285\nMetrics saved to: eval/fgsm-cw-512-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 512) \n Method: bim \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.5528\nMetrics saved to: eval/bim-fgsm-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: bim \n Dataset: bim \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\nMetrics saved to: eval/bim-bim-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: bim \n Dataset: pgd \n\nTEST Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\nMetrics saved to: eval/bim-pgd-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: bim \n Dataset: df \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.5039\nMetrics saved to: eval/bim-df-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: bim \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.4974\nMetrics saved to: eval/bim-cw-512-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 512) \n Method: pgd \n Dataset: fgsm \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.5587\nMetrics saved to: eval/pgd-fgsm-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: pgd \n Dataset: bim \n\nTEST Eval results:\n  acc=0.9939  prec=1.0000  recall=0.9878  f1=0.9939\n  roc_auc=1.0000\nMetrics saved to: eval/pgd-bim-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: pgd \n Dataset: pgd \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\nMetrics saved to: eval/pgd-pgd-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: pgd \n Dataset: df \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.5068\nMetrics saved to: eval/pgd-df-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: pgd \n Dataset: cw \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.5097\nMetrics saved to: eval/pgd-cw-512-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 512) \n Method: df \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.3841  prec=0.3273  recall=0.2195  f1=0.2628\n  roc_auc=0.3317\nMetrics saved to: eval/df-fgsm-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: df \n Dataset: bim \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.2744  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0701\nMetrics saved to: eval/df-bim-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: df \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.2744  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0650\nMetrics saved to: eval/df-pgd-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: df \n Dataset: df \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.6463  prec=0.6224  recall=0.7439  f1=0.6778\n  roc_auc=0.6765\nMetrics saved to: eval/df-df-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: df \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5915  prec=0.5843  recall=0.6341  f1=0.6082\n  roc_auc=0.6341\nMetrics saved to: eval/df-cw-512-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 512) \n Method: cw \n Dataset: fgsm \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.4329  prec=0.4035  recall=0.2805  f1=0.3309\n  roc_auc=0.3418\nMetrics saved to: eval/cw-fgsm-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: cw \n Dataset: bim \n\nTEST Eval results:\n  acc=0.3293  prec=0.1500  recall=0.0732  f1=0.0984\n  roc_auc=0.2746\nMetrics saved to: eval/cw-bim-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: cw \n Dataset: pgd \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.3415  prec=0.1905  recall=0.0976  f1=0.1290\n  roc_auc=0.2971\nMetrics saved to: eval/cw-pgd-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: cw \n Dataset: df \n\nTEST Eval results:\n  acc=0.6220  prec=0.6136  recall=0.6585  f1=0.6353\n  roc_auc=0.6512\nMetrics saved to: eval/cw-df-512-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 512) \n Method: cw \n Dataset: cw \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5976  prec=0.5952  recall=0.6098  f1=0.6024\n  roc_auc=0.6275\nMetrics saved to: eval/cw-cw-512-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: fgsm \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.8171  prec=0.8095  recall=0.8293  f1=0.8193\n  roc_auc=0.9065\nMetrics saved to: eval/fgsm-fgsm-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: fgsm \n Dataset: bim \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.8354  prec=0.8161  recall=0.8659  f1=0.8402\n  roc_auc=0.8810\nMetrics saved to: eval/fgsm-bim-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: fgsm \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.8171  prec=0.8095  recall=0.8293  f1=0.8193\n  roc_auc=0.8723\nMetrics saved to: eval/fgsm-pgd-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: fgsm \n Dataset: df \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.4634  prec=0.3846  recall=0.1220  f1=0.1852\n  roc_auc=0.4536\nMetrics saved to: eval/fgsm-df-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: fgsm \n Dataset: cw \n\nTEST Eval results:\n  acc=0.4756  prec=0.4286  recall=0.1463  f1=0.2182\n  roc_auc=0.4648\nMetrics saved to: eval/fgsm-cw-1024-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: bim \n Dataset: fgsm \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.5370\nMetrics saved to: eval/bim-fgsm-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: bim \n Dataset: bim \n\nTEST Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\nMetrics saved to: eval/bim-bim-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: bim \n Dataset: pgd \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\nMetrics saved to: eval/bim-pgd-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: bim \n Dataset: df \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.5000\nMetrics saved to: eval/bim-df-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: bim \n Dataset: cw \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.5061\nMetrics saved to: eval/bim-cw-1024-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: pgd \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.5564\nMetrics saved to: eval/pgd-fgsm-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: pgd \n Dataset: bim \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\nMetrics saved to: eval/pgd-bim-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: pgd \n Dataset: pgd \n\nTEST Eval results:\n  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n  roc_auc=1.0000\nMetrics saved to: eval/pgd-pgd-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: pgd \n Dataset: df \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.5000\nMetrics saved to: eval/pgd-df-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: pgd \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.4939\nMetrics saved to: eval/pgd-cw-1024-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: df \n Dataset: fgsm \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.3598  prec=0.3333  recall=0.2805  f1=0.3046\n  roc_auc=0.2789\nMetrics saved to: eval/df-fgsm-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: df \n Dataset: bim \n\nTEST Eval results:\n  acc=0.2195  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0625\nMetrics saved to: eval/df-bim-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: df \n Dataset: pgd \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.2195  prec=0.0000  recall=0.0000  f1=0.0000\n  roc_auc=0.0622\nMetrics saved to: eval/df-pgd-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: df \n Dataset: df \n\nTEST Eval results:\n  acc=0.5244  prec=0.5208  recall=0.6098  f1=0.5618\n  roc_auc=0.5486\nMetrics saved to: eval/df-df-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: df \n Dataset: cw \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5122  prec=0.5106  recall=0.5854  f1=0.5455\n  roc_auc=0.5352\nMetrics saved to: eval/df-cw-1024-RandomForest_test_result.csv\n_________________________\n\n===============================\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: cw \n Dataset: fgsm \n\nTEST Eval results:\n  acc=0.3841  prec=0.3061  recall=0.1829  f1=0.2290\n  roc_auc=0.2826\nMetrics saved to: eval/cw-fgsm-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: cw \n Dataset: bim \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.7134  prec=0.6699  recall=0.8415  f1=0.7459\n  roc_auc=0.8028\nMetrics saved to: eval/cw-bim-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: cw \n Dataset: pgd \n\nTEST Eval results:\n  acc=0.7439  prec=0.6852  recall=0.9024  f1=0.7789\n  roc_auc=0.8020\nMetrics saved to: eval/cw-pgd-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: cw \n Dataset: df \n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"TEST Eval results:\n  acc=0.5488  prec=0.5526  recall=0.5122  f1=0.5316\n  roc_auc=0.5296\nMetrics saved to: eval/cw-df-1024-RandomForest_test_result.csv\n_________________________\n\nEvaluate Against Test Set (Image Size: 1024) \n Method: cw \n Dataset: cw \n\nTEST Eval results:\n  acc=0.5000  prec=0.5000  recall=0.4146  f1=0.4533\n  roc_auc=0.4965\nMetrics saved to: eval/cw-cw-1024-RandomForest_test_result.csv\n_________________________\n\n===============================\n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import hashlib\nimport os\nfrom pathlib import Path\nimport zipfile\nfrom datetime import datetime\n\n# -------------------------------\n# Config\n# -------------------------------\ninput_dir = Path(\"/kaggle/working/eval\")\noutput_zip = Path(\"/kaggle/working/evals-TEST.zip\")\nmanifest_path = Path(\"/kaggle/working/manifest-evals-TEST-sha256.txt\")\nchunk_size = 8 * 1024 * 1024  # 8 MB\nskip_files = {output_zip.name, manifest_path.name}\n\n# -------------------------------\n# Helper: compute SHA256\n# -------------------------------\ndef sha256_of_file(path: Path) -> str:\n    h = hashlib.sha256()\n    with path.open(\"rb\") as f:\n        while True:\n            chunk = f.read(chunk_size)\n            if not chunk:\n                break\n            h.update(chunk)\n    return h.hexdigest()\n\n# -------------------------------\n# Collect files to zip\n# -------------------------------\nfiles_to_add = []\nfor root, dirs, files in os.walk(input_dir):\n    for fname in files:\n        full = Path(root) / fname\n        rel = full.relative_to(input_dir)\n        rel_str = str(rel).replace(os.sep, \"/\")\n        if rel.name in skip_files:\n            continue\n        files_to_add.append((full, rel))\n\nif not files_to_add:\n    print(f\"No files found in {input_dir} to archive.\")\nelse:\n    # -------------------------------\n    # Create zip\n    # -------------------------------\n    print(f\"Creating zip: {output_zip}\")\n    with zipfile.ZipFile(output_zip, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n        for full, rel in files_to_add:\n            arcname = str(rel).replace(os.sep, \"/\")\n            print(f\"  adding: {arcname}\")\n            zf.write(full, arcname=arcname)\n\n    # -------------------------------\n    # Create manifest\n    # -------------------------------\n    print(f\"Computing per-file SHA-256 and writing manifest: {manifest_path}\")\n    with manifest_path.open(\"w\", encoding=\"utf-8\") as mf:\n        mf.write(f\"# manifest generated: {datetime.utcnow().isoformat()}Z\\n\")\n        mf.write(f\"# input_dir: {input_dir}\\n\")\n        mf.write(\"# format: <sha256>  <relative/path>\\n\")\n        for full, rel in files_to_add:\n            rel_unix = str(rel).replace(os.sep, \"/\")\n            h = sha256_of_file(full)\n            size = full.stat().st_size\n            mf.write(f\"{h}  {rel_unix}  # {size} bytes\\n\")\n\n    # -------------------------------\n    # Compute zip SHA256\n    # -------------------------------\n    zip_hash = sha256_of_file(output_zip)\n    ziphash_path = output_zip.with_suffix(output_zip.suffix + \".sha256\")\n    with ziphash_path.open(\"w\", encoding=\"utf-8\") as zh:\n        zh.write(f\"{zip_hash}  {output_zip.name}\\n\")\n\n    print(\"Done.\")\n    print(f\"Created: {output_zip}\")\n    print(f\"Created: {manifest_path}\")\n    print(f\"Created: {ziphash_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T14:42:41.343933Z","iopub.execute_input":"2025-10-19T14:42:41.344273Z","iopub.status.idle":"2025-10-19T14:42:41.421771Z","shell.execute_reply.started":"2025-10-19T14:42:41.344243Z","shell.execute_reply":"2025-10-19T14:42:41.420635Z"}},"outputs":[{"name":"stdout","text":"Creating zip: /kaggle/working/evals-TEST.zip\n  adding: pgd-cw-128-RandomForest_test_result.csv\n  adding: pgd-df-512-LogisticRegression_test_result.csv\n  adding: df-bim-32-LogisticRegression_test_result.csv\n  adding: pgd-cw-512-LogisticRegression_test_result.csv\n  adding: df-cw-64-RandomForest_test_result.csv\n  adding: df-pgd-128-LogisticRegression_test_result.csv\n  adding: pgd-df-64-RandomForest_test_result.csv\n  adding: df-pgd-1024-RandomForest_test_result.csv\n  adding: fgsm-cw-1024-LogisticRegression_test_result.csv\n  adding: df-df-256-LogisticRegression_test_result.csv\n  adding: bim-fgsm-1024-LogisticRegression_test_result.csv\n  adding: bim-fgsm-64-RandomForest_test_result.csv\n  adding: df-df-512-LogisticRegression_test_result.csv\n  adding: bim-df-256-LogisticRegression_test_result.csv\n  adding: fgsm-df-64-LogisticRegression_test_result.csv\n  adding: pgd-df-256-RandomForest_test_result.csv\n  adding: pgd-fgsm-1024-RandomForest_test_result.csv\n  adding: bim-df-64-RandomForest_test_result.csv\n  adding: df-cw-512-LogisticRegression_test_result.csv\n  adding: cw-fgsm-256-LogisticRegression_test_result.csv\n  adding: fgsm-fgsm-64-LogisticRegression_test_result.csv\n  adding: df-pgd-128-RandomForest_test_result.csv\n  adding: pgd-fgsm-128-LogisticRegression_test_result.csv\n  adding: df-df-1024-RandomForest_test_result.csv\n  adding: pgd-pgd-64-RandomForest_test_result.csv\n  adding: pgd-pgd-128-LogisticRegression_test_result.csv\n  adding: bim-pgd-128-LogisticRegression_test_result.csv\n  adding: pgd-bim-1024-LogisticRegression_test_result.csv\n  adding: df-bim-256-RandomForest_test_result.csv\n  adding: pgd-pgd-256-LogisticRegression_test_result.csv\n  adding: bim-bim-512-LogisticRegression_test_result.csv\n  adding: fgsm-pgd-512-LogisticRegression_test_result.csv\n  adding: fgsm-pgd-256-RandomForest_test_result.csv\n  adding: cw-pgd-256-RandomForest_test_result.csv\n  adding: cw-df-1024-LogisticRegression_test_result.csv\n  adding: df-pgd-1024-LogisticRegression_test_result.csv\n  adding: bim-fgsm-256-LogisticRegression_test_result.csv\n  adding: fgsm-cw-512-LogisticRegression_test_result.csv\n  adding: bim-cw-128-LogisticRegression_test_result.csv\n  adding: cw-df-512-LogisticRegression_test_result.csv\n  adding: fgsm-cw-512-RandomForest_test_result.csv\n  adding: bim-cw-32-LogisticRegression_test_result.csv\n  adding: cw-fgsm-64-RandomForest_test_result.csv\n  adding: fgsm-fgsm-256-RandomForest_test_result.csv\n  adding: df-fgsm-512-LogisticRegression_test_result.csv\n  adding: pgd-cw-64-LogisticRegression_test_result.csv\n  adding: pgd-cw-512-RandomForest_test_result.csv\n  adding: fgsm-df-512-RandomForest_test_result.csv\n  adding: df-df-32-LogisticRegression_test_result.csv\n  adding: fgsm-pgd-32-LogisticRegression_test_result.csv\n  adding: bim-pgd-1024-LogisticRegression_test_result.csv\n  adding: fgsm-fgsm-512-LogisticRegression_test_result.csv\n  adding: df-bim-512-RandomForest_test_result.csv\n  adding: pgd-df-1024-LogisticRegression_test_result.csv\n  adding: bim-df-128-LogisticRegression_test_result.csv\n  adding: pgd-bim-128-LogisticRegression_test_result.csv\n  adding: cw-cw-128-LogisticRegression_test_result.csv\n  adding: bim-fgsm-512-LogisticRegression_test_result.csv\n  adding: bim-fgsm-512-RandomForest_test_result.csv\n  adding: df-pgd-256-RandomForest_test_result.csv\n  adding: pgd-cw-256-LogisticRegression_test_result.csv\n  adding: pgd-cw-256-RandomForest_test_result.csv\n  adding: fgsm-df-32-LogisticRegression_test_result.csv\n  adding: fgsm-cw-32-LogisticRegression_test_result.csv\n  adding: cw-fgsm-64-LogisticRegression_test_result.csv\n  adding: df-df-64-RandomForest_test_result.csv\n  adding: pgd-fgsm-256-LogisticRegression_test_result.csv\n  adding: df-df-64-LogisticRegression_test_result.csv\n  adding: bim-cw-512-RandomForest_test_result.csv\n  adding: cw-pgd-128-LogisticRegression_test_result.csv\n  adding: cw-cw-64-LogisticRegression_test_result.csv\n  adding: cw-bim-64-LogisticRegression_test_result.csv\n  adding: df-fgsm-1024-RandomForest_test_result.csv\n  adding: pgd-bim-256-RandomForest_test_result.csv\n  adding: bim-df-32-RandomForest_test_result.csv\n  adding: pgd-fgsm-64-LogisticRegression_test_result.csv\n  adding: fgsm-pgd-128-LogisticRegression_test_result.csv\n  adding: fgsm-pgd-1024-RandomForest_test_result.csv\n  adding: df-bim-1024-LogisticRegression_test_result.csv\n  adding: cw-bim-1024-RandomForest_test_result.csv\n  adding: pgd-pgd-1024-RandomForest_test_result.csv\n  adding: fgsm-fgsm-512-RandomForest_test_result.csv\n  adding: df-pgd-64-RandomForest_test_result.csv\n  adding: df-bim-128-LogisticRegression_test_result.csv\n  adding: df-df-128-RandomForest_test_result.csv\n  adding: bim-fgsm-128-LogisticRegression_test_result.csv\n  adding: cw-cw-1024-LogisticRegression_test_result.csv\n  adding: df-cw-32-RandomForest_test_result.csv\n  adding: cw-cw-256-LogisticRegression_test_result.csv\n  adding: pgd-bim-512-RandomForest_test_result.csv\n  adding: pgd-fgsm-128-RandomForest_test_result.csv\n  adding: df-pgd-32-RandomForest_test_result.csv\n  adding: bim-fgsm-64-LogisticRegression_test_result.csv\n  adding: bim-df-32-LogisticRegression_test_result.csv\n  adding: fgsm-pgd-256-LogisticRegression_test_result.csv\n  adding: df-df-256-RandomForest_test_result.csv\n  adding: fgsm-bim-1024-LogisticRegression_test_result.csv\n  adding: fgsm-df-512-LogisticRegression_test_result.csv\n  adding: bim-df-1024-RandomForest_test_result.csv\n  adding: cw-df-512-RandomForest_test_result.csv\n  adding: fgsm-df-128-LogisticRegression_test_result.csv\n  adding: cw-df-32-LogisticRegression_test_result.csv\n  adding: df-cw-256-LogisticRegression_test_result.csv\n  adding: cw-cw-256-RandomForest_test_result.csv\n  adding: fgsm-pgd-32-RandomForest_test_result.csv\n  adding: pgd-df-128-LogisticRegression_test_result.csv\n  adding: bim-fgsm-32-RandomForest_test_result.csv\n  adding: bim-cw-256-RandomForest_test_result.csv\n  adding: cw-pgd-512-RandomForest_test_result.csv\n  adding: cw-cw-512-LogisticRegression_test_result.csv\n  adding: fgsm-cw-64-LogisticRegression_test_result.csv\n  adding: pgd-fgsm-512-LogisticRegression_test_result.csv\n  adding: fgsm-bim-32-RandomForest_test_result.csv\n  adding: bim-bim-512-RandomForest_test_result.csv\n  adding: cw-df-128-RandomForest_test_result.csv\n  adding: cw-cw-32-LogisticRegression_test_result.csv\n  adding: cw-bim-1024-LogisticRegression_test_result.csv\n  adding: cw-pgd-1024-LogisticRegression_test_result.csv\n  adding: bim-df-128-RandomForest_test_result.csv\n  adding: fgsm-cw-32-RandomForest_test_result.csv\n  adding: fgsm-pgd-512-RandomForest_test_result.csv\n  adding: bim-pgd-128-RandomForest_test_result.csv\n  adding: fgsm-bim-512-LogisticRegression_test_result.csv\n  adding: df-pgd-64-LogisticRegression_test_result.csv\n  adding: bim-bim-256-RandomForest_test_result.csv\n  adding: cw-bim-32-LogisticRegression_test_result.csv\n  adding: df-fgsm-64-RandomForest_test_result.csv\n  adding: fgsm-fgsm-32-RandomForest_test_result.csv\n  adding: bim-pgd-512-RandomForest_test_result.csv\n  adding: cw-fgsm-128-RandomForest_test_result.csv\n  adding: pgd-df-1024-RandomForest_test_result.csv\n  adding: pgd-cw-1024-LogisticRegression_test_result.csv\n  adding: pgd-fgsm-256-RandomForest_test_result.csv\n  adding: pgd-bim-32-RandomForest_test_result.csv\n  adding: cw-df-256-LogisticRegression_test_result.csv\n  adding: df-pgd-512-RandomForest_test_result.csv\n  adding: fgsm-df-256-LogisticRegression_test_result.csv\n  adding: bim-bim-1024-RandomForest_test_result.csv\n  adding: bim-cw-1024-LogisticRegression_test_result.csv\n  adding: pgd-bim-32-LogisticRegression_test_result.csv\n  adding: pgd-cw-128-LogisticRegression_test_result.csv\n  adding: df-cw-1024-LogisticRegression_test_result.csv\n  adding: fgsm-df-1024-RandomForest_test_result.csv\n  adding: cw-pgd-256-LogisticRegression_test_result.csv\n  adding: cw-df-64-LogisticRegression_test_result.csv\n  adding: df-pgd-256-LogisticRegression_test_result.csv\n  adding: pgd-fgsm-1024-LogisticRegression_test_result.csv\n  adding: fgsm-fgsm-64-RandomForest_test_result.csv\n  adding: pgd-pgd-64-LogisticRegression_test_result.csv\n  adding: cw-bim-256-RandomForest_test_result.csv\n  adding: pgd-pgd-128-RandomForest_test_result.csv\n  adding: fgsm-bim-256-LogisticRegression_test_result.csv\n  adding: fgsm-bim-128-RandomForest_test_result.csv\n  adding: pgd-df-512-RandomForest_test_result.csv\n  adding: df-bim-1024-RandomForest_test_result.csv\n  adding: cw-fgsm-128-LogisticRegression_test_result.csv\n  adding: df-df-32-RandomForest_test_result.csv\n  adding: df-fgsm-128-RandomForest_test_result.csv\n  adding: bim-bim-128-LogisticRegression_test_result.csv\n  adding: fgsm-bim-32-LogisticRegression_test_result.csv\n  adding: cw-bim-64-RandomForest_test_result.csv\n  adding: cw-pgd-64-RandomForest_test_result.csv\n  adding: df-cw-256-RandomForest_test_result.csv\n  adding: bim-bim-256-LogisticRegression_test_result.csv\n  adding: fgsm-df-256-RandomForest_test_result.csv\n  adding: cw-fgsm-512-RandomForest_test_result.csv\n  adding: bim-cw-64-LogisticRegression_test_result.csv\n  adding: bim-pgd-256-LogisticRegression_test_result.csv\n  adding: df-fgsm-128-LogisticRegression_test_result.csv\n  adding: pgd-bim-128-RandomForest_test_result.csv\n  adding: df-cw-512-RandomForest_test_result.csv\n  adding: bim-bim-64-LogisticRegression_test_result.csv\n  adding: df-pgd-512-LogisticRegression_test_result.csv\n  adding: fgsm-fgsm-256-LogisticRegression_test_result.csv\n  adding: pgd-fgsm-32-LogisticRegression_test_result.csv\n  adding: pgd-df-128-RandomForest_test_result.csv\n  adding: fgsm-cw-256-LogisticRegression_test_result.csv\n  adding: fgsm-pgd-1024-LogisticRegression_test_result.csv\n  adding: fgsm-pgd-64-LogisticRegression_test_result.csv\n  adding: pgd-cw-32-LogisticRegression_test_result.csv\n  adding: pgd-df-256-LogisticRegression_test_result.csv\n  adding: cw-fgsm-1024-LogisticRegression_test_result.csv\n  adding: df-fgsm-1024-LogisticRegression_test_result.csv\n  adding: fgsm-bim-64-RandomForest_test_result.csv\n  adding: bim-cw-512-LogisticRegression_test_result.csv\n  adding: cw-pgd-1024-RandomForest_test_result.csv\n  adding: fgsm-fgsm-1024-LogisticRegression_test_result.csv\n  adding: pgd-pgd-32-RandomForest_test_result.csv\n  adding: cw-pgd-128-RandomForest_test_result.csv\n  adding: cw-fgsm-1024-RandomForest_test_result.csv\n  adding: bim-cw-64-RandomForest_test_result.csv\n  adding: pgd-pgd-256-RandomForest_test_result.csv\n  adding: fgsm-cw-128-RandomForest_test_result.csv\n  adding: pgd-pgd-512-LogisticRegression_test_result.csv\n  adding: bim-df-256-RandomForest_test_result.csv\n  adding: pgd-bim-256-LogisticRegression_test_result.csv\n  adding: pgd-fgsm-32-RandomForest_test_result.csv\n  adding: bim-cw-1024-RandomForest_test_result.csv\n  adding: df-bim-32-RandomForest_test_result.csv\n  adding: bim-df-1024-LogisticRegression_test_result.csv\n  adding: bim-bim-32-LogisticRegression_test_result.csv\n  adding: pgd-fgsm-512-RandomForest_test_result.csv\n  adding: cw-pgd-64-LogisticRegression_test_result.csv\n  adding: fgsm-fgsm-32-LogisticRegression_test_result.csv\n  adding: df-df-512-RandomForest_test_result.csv\n  adding: fgsm-pgd-128-RandomForest_test_result.csv\n  adding: cw-cw-64-RandomForest_test_result.csv\n  adding: pgd-pgd-32-LogisticRegression_test_result.csv\n  adding: fgsm-bim-256-RandomForest_test_result.csv\n  adding: bim-df-64-LogisticRegression_test_result.csv\n  adding: bim-pgd-32-RandomForest_test_result.csv\n  adding: fgsm-cw-1024-RandomForest_test_result.csv\n  adding: bim-df-512-LogisticRegression_test_result.csv\n  adding: bim-bim-1024-LogisticRegression_test_result.csv\n  adding: bim-fgsm-1024-RandomForest_test_result.csv\n  adding: fgsm-bim-128-LogisticRegression_test_result.csv\n  adding: fgsm-cw-128-LogisticRegression_test_result.csv\n  adding: cw-bim-128-LogisticRegression_test_result.csv\n  adding: pgd-bim-64-RandomForest_test_result.csv\n  adding: bim-pgd-1024-RandomForest_test_result.csv\n  adding: bim-cw-128-RandomForest_test_result.csv\n  adding: cw-fgsm-256-RandomForest_test_result.csv\n  adding: cw-df-64-RandomForest_test_result.csv\n  adding: cw-pgd-32-LogisticRegression_test_result.csv\n  adding: df-bim-256-LogisticRegression_test_result.csv\n  adding: df-bim-512-LogisticRegression_test_result.csv\n  adding: bim-pgd-256-RandomForest_test_result.csv\n  adding: fgsm-bim-1024-RandomForest_test_result.csv\n  adding: cw-cw-128-RandomForest_test_result.csv\n  adding: bim-cw-256-LogisticRegression_test_result.csv\n  adding: fgsm-pgd-64-RandomForest_test_result.csv\n  adding: cw-cw-1024-RandomForest_test_result.csv\n  adding: cw-df-256-RandomForest_test_result.csv\n  adding: fgsm-cw-256-RandomForest_test_result.csv\n  adding: df-cw-128-LogisticRegression_test_result.csv\n  adding: df-fgsm-32-RandomForest_test_result.csv\n  adding: df-fgsm-512-RandomForest_test_result.csv\n  adding: bim-cw-32-RandomForest_test_result.csv\n  adding: df-bim-64-RandomForest_test_result.csv\n  adding: fgsm-fgsm-1024-RandomForest_test_result.csv\n  adding: fgsm-df-64-RandomForest_test_result.csv\n  adding: bim-pgd-32-LogisticRegression_test_result.csv\n  adding: fgsm-df-1024-LogisticRegression_test_result.csv\n  adding: cw-bim-256-LogisticRegression_test_result.csv\n  adding: df-cw-128-RandomForest_test_result.csv\n  adding: df-df-1024-LogisticRegression_test_result.csv\n  adding: fgsm-df-32-RandomForest_test_result.csv\n  adding: cw-fgsm-32-RandomForest_test_result.csv\n  adding: fgsm-cw-64-RandomForest_test_result.csv\n  adding: bim-pgd-512-LogisticRegression_test_result.csv\n  adding: df-pgd-32-LogisticRegression_test_result.csv\n  adding: cw-df-128-LogisticRegression_test_result.csv\n  adding: fgsm-bim-64-LogisticRegression_test_result.csv\n  adding: fgsm-bim-512-RandomForest_test_result.csv\n  adding: cw-df-32-RandomForest_test_result.csv\n  adding: fgsm-df-128-RandomForest_test_result.csv\n  adding: pgd-cw-1024-RandomForest_test_result.csv\n  adding: bim-bim-128-RandomForest_test_result.csv\n  adding: fgsm-fgsm-128-RandomForest_test_result.csv\n  adding: cw-fgsm-512-LogisticRegression_test_result.csv\n  adding: cw-cw-512-RandomForest_test_result.csv\n  adding: cw-cw-32-RandomForest_test_result.csv\n  adding: cw-df-1024-RandomForest_test_result.csv\n  adding: bim-df-512-RandomForest_test_result.csv\n  adding: bim-fgsm-128-RandomForest_test_result.csv\n  adding: pgd-bim-1024-RandomForest_test_result.csv\n  adding: df-cw-1024-RandomForest_test_result.csv\n  adding: df-cw-64-LogisticRegression_test_result.csv\n  adding: cw-fgsm-32-LogisticRegression_test_result.csv\n  adding: df-fgsm-256-RandomForest_test_result.csv\n  adding: pgd-df-32-RandomForest_test_result.csv\n  adding: pgd-df-32-LogisticRegression_test_result.csv\n  adding: pgd-df-64-LogisticRegression_test_result.csv\n  adding: cw-pgd-32-RandomForest_test_result.csv\n  adding: cw-bim-512-LogisticRegression_test_result.csv\n  adding: pgd-pgd-1024-LogisticRegression_test_result.csv\n  adding: bim-pgd-64-LogisticRegression_test_result.csv\n  adding: pgd-cw-64-RandomForest_test_result.csv\n  adding: bim-bim-64-RandomForest_test_result.csv\n  adding: df-bim-128-RandomForest_test_result.csv\n  adding: bim-fgsm-32-LogisticRegression_test_result.csv\n  adding: df-df-128-LogisticRegression_test_result.csv\n  adding: fgsm-fgsm-128-LogisticRegression_test_result.csv\n  adding: pgd-pgd-512-RandomForest_test_result.csv\n  adding: bim-bim-32-RandomForest_test_result.csv\n  adding: pgd-bim-512-LogisticRegression_test_result.csv\n  adding: df-fgsm-32-LogisticRegression_test_result.csv\n  adding: df-fgsm-64-LogisticRegression_test_result.csv\n  adding: bim-pgd-64-RandomForest_test_result.csv\n  adding: cw-pgd-512-LogisticRegression_test_result.csv\n  adding: cw-bim-128-RandomForest_test_result.csv\n  adding: bim-fgsm-256-RandomForest_test_result.csv\n  adding: pgd-bim-64-LogisticRegression_test_result.csv\n  adding: df-bim-64-LogisticRegression_test_result.csv\n  adding: pgd-fgsm-64-RandomForest_test_result.csv\n  adding: cw-bim-32-RandomForest_test_result.csv\n  adding: df-cw-32-LogisticRegression_test_result.csv\n  adding: df-fgsm-256-LogisticRegression_test_result.csv\n  adding: cw-bim-512-RandomForest_test_result.csv\n  adding: pgd-cw-32-RandomForest_test_result.csv\nComputing per-file SHA-256 and writing manifest: /kaggle/working/manifest-evals-TEST-sha256.txt\nDone.\nCreated: /kaggle/working/evals-TEST.zip\nCreated: /kaggle/working/manifest-evals-TEST-sha256.txt\nCreated: /kaggle/working/evals-TEST.zip.sha256\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import hashlib\nimport os\nfrom pathlib import Path\nimport zipfile\nfrom datetime import datetime\n\n# -------------------------------\n# Config\n# -------------------------------\ninput_dir = Path(\"/kaggle/working/models\")\noutput_zip = Path(\"/kaggle/working/models.zip\")\nmanifest_path = Path(\"/kaggle/working/manifest-sha256.txt\")\nchunk_size = 8 * 1024 * 1024  # 8 MB\nskip_files = {output_zip.name, manifest_path.name}\n\n# -------------------------------\n# Helper: compute SHA256\n# -------------------------------\ndef sha256_of_file(path: Path) -> str:\n    h = hashlib.sha256()\n    with path.open(\"rb\") as f:\n        while True:\n            chunk = f.read(chunk_size)\n            if not chunk:\n                break\n            h.update(chunk)\n    return h.hexdigest()\n\n# -------------------------------\n# Collect files to zip\n# -------------------------------\nfiles_to_add = []\nfor root, dirs, files in os.walk(input_dir):\n    for fname in files:\n        full = Path(root) / fname\n        rel = full.relative_to(input_dir)\n        rel_str = str(rel).replace(os.sep, \"/\")\n        if rel.name in skip_files:\n            continue\n        files_to_add.append((full, rel))\n\nif not files_to_add:\n    print(f\"No files found in {input_dir} to archive.\")\nelse:\n    # -------------------------------\n    # Create zip\n    # -------------------------------\n    print(f\"Creating zip: {output_zip}\")\n    with zipfile.ZipFile(output_zip, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n        for full, rel in files_to_add:\n            arcname = str(rel).replace(os.sep, \"/\")\n            print(f\"  adding: {arcname}\")\n            zf.write(full, arcname=arcname)\n\n    # -------------------------------\n    # Create manifest\n    # -------------------------------\n    print(f\"Computing per-file SHA-256 and writing manifest: {manifest_path}\")\n    with manifest_path.open(\"w\", encoding=\"utf-8\") as mf:\n        mf.write(f\"# manifest generated: {datetime.utcnow().isoformat()}Z\\n\")\n        mf.write(f\"# input_dir: {input_dir}\\n\")\n        mf.write(\"# format: <sha256>  <relative/path>\\n\")\n        for full, rel in files_to_add:\n            rel_unix = str(rel).replace(os.sep, \"/\")\n            h = sha256_of_file(full)\n            size = full.stat().st_size\n            mf.write(f\"{h}  {rel_unix}  # {size} bytes\\n\")\n\n    # -------------------------------\n    # Compute zip SHA256\n    # -------------------------------\n    zip_hash = sha256_of_file(output_zip)\n    ziphash_path = output_zip.with_suffix(output_zip.suffix + \".sha256\")\n    with ziphash_path.open(\"w\", encoding=\"utf-8\") as zh:\n        zh.write(f\"{zip_hash}  {output_zip.name}\\n\")\n\n    print(\"Done.\")\n    print(f\"Created: {output_zip}\")\n    print(f\"Created: {manifest_path}\")\n    print(f\"Created: {ziphash_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T14:42:52.695086Z","iopub.execute_input":"2025-10-19T14:42:52.695409Z","iopub.status.idle":"2025-10-19T14:42:58.196863Z","shell.execute_reply.started":"2025-10-19T14:42:52.695384Z","shell.execute_reply":"2025-10-19T14:42:58.195545Z"}},"outputs":[{"name":"stdout","text":"Creating zip: /kaggle/working/models.zip\n  adding: fgsm-1024-RandomForest/scaler.joblib\n  adding: fgsm-1024-RandomForest/train_meta.json\n  adding: fgsm-1024-RandomForest/pipeline.joblib\n  adding: fgsm-1024-RandomForest/clf.joblib\n  adding: fgsm-256-LogisticRegression/scaler.joblib\n  adding: fgsm-256-LogisticRegression/train_meta.json\n  adding: fgsm-256-LogisticRegression/pipeline.joblib\n  adding: fgsm-256-LogisticRegression/clf.joblib\n  adding: df-512-RandomForest/scaler.joblib\n  adding: df-512-RandomForest/train_meta.json\n  adding: df-512-RandomForest/pipeline.joblib\n  adding: df-512-RandomForest/clf.joblib\n  adding: cw-256-RandomForest/scaler.joblib\n  adding: cw-256-RandomForest/train_meta.json\n  adding: cw-256-RandomForest/pipeline.joblib\n  adding: cw-256-RandomForest/clf.joblib\n  adding: pgd-64-RandomForest/scaler.joblib\n  adding: pgd-64-RandomForest/train_meta.json\n  adding: pgd-64-RandomForest/pipeline.joblib\n  adding: pgd-64-RandomForest/clf.joblib\n  adding: pgd-512-LogisticRegression/scaler.joblib\n  adding: pgd-512-LogisticRegression/train_meta.json\n  adding: pgd-512-LogisticRegression/pipeline.joblib\n  adding: pgd-512-LogisticRegression/clf.joblib\n  adding: bim-128-LogisticRegression/scaler.joblib\n  adding: bim-128-LogisticRegression/train_meta.json\n  adding: bim-128-LogisticRegression/pipeline.joblib\n  adding: bim-128-LogisticRegression/clf.joblib\n  adding: bim-256-RandomForest/scaler.joblib\n  adding: bim-256-RandomForest/train_meta.json\n  adding: bim-256-RandomForest/pipeline.joblib\n  adding: bim-256-RandomForest/clf.joblib\n  adding: df-1024-LogisticRegression/scaler.joblib\n  adding: df-1024-LogisticRegression/train_meta.json\n  adding: df-1024-LogisticRegression/pipeline.joblib\n  adding: df-1024-LogisticRegression/clf.joblib\n  adding: cw-32-RandomForest/scaler.joblib\n  adding: cw-32-RandomForest/train_meta.json\n  adding: cw-32-RandomForest/pipeline.joblib\n  adding: cw-32-RandomForest/clf.joblib\n  adding: df-32-LogisticRegression/scaler.joblib\n  adding: df-32-LogisticRegression/train_meta.json\n  adding: df-32-LogisticRegression/pipeline.joblib\n  adding: df-32-LogisticRegression/clf.joblib\n  adding: cw-32-LogisticRegression/scaler.joblib\n  adding: cw-32-LogisticRegression/train_meta.json\n  adding: cw-32-LogisticRegression/pipeline.joblib\n  adding: cw-32-LogisticRegression/clf.joblib\n  adding: bim-64-RandomForest/scaler.joblib\n  adding: bim-64-RandomForest/train_meta.json\n  adding: bim-64-RandomForest/pipeline.joblib\n  adding: bim-64-RandomForest/clf.joblib\n  adding: fgsm-512-LogisticRegression/scaler.joblib\n  adding: fgsm-512-LogisticRegression/train_meta.json\n  adding: fgsm-512-LogisticRegression/pipeline.joblib\n  adding: fgsm-512-LogisticRegression/clf.joblib\n  adding: df-256-LogisticRegression/scaler.joblib\n  adding: df-256-LogisticRegression/train_meta.json\n  adding: df-256-LogisticRegression/pipeline.joblib\n  adding: df-256-LogisticRegression/clf.joblib\n  adding: pgd-128-RandomForest/scaler.joblib\n  adding: pgd-128-RandomForest/train_meta.json\n  adding: pgd-128-RandomForest/pipeline.joblib\n  adding: pgd-128-RandomForest/clf.joblib\n  adding: pgd-1024-LogisticRegression/scaler.joblib\n  adding: pgd-1024-LogisticRegression/train_meta.json\n  adding: pgd-1024-LogisticRegression/pipeline.joblib\n  adding: pgd-1024-LogisticRegression/clf.joblib\n  adding: bim-32-LogisticRegression/scaler.joblib\n  adding: bim-32-LogisticRegression/train_meta.json\n  adding: bim-32-LogisticRegression/pipeline.joblib\n  adding: bim-32-LogisticRegression/clf.joblib\n  adding: df-256-RandomForest/scaler.joblib\n  adding: df-256-RandomForest/train_meta.json\n  adding: df-256-RandomForest/pipeline.joblib\n  adding: df-256-RandomForest/clf.joblib\n  adding: cw-128-LogisticRegression/scaler.joblib\n  adding: cw-128-LogisticRegression/train_meta.json\n  adding: cw-128-LogisticRegression/pipeline.joblib\n  adding: cw-128-LogisticRegression/clf.joblib\n  adding: df-32-RandomForest/scaler.joblib\n  adding: df-32-RandomForest/train_meta.json\n  adding: df-32-RandomForest/pipeline.joblib\n  adding: df-32-RandomForest/clf.joblib\n  adding: pgd-1024-RandomForest/scaler.joblib\n  adding: pgd-1024-RandomForest/train_meta.json\n  adding: pgd-1024-RandomForest/pipeline.joblib\n  adding: pgd-1024-RandomForest/clf.joblib\n  adding: df-64-RandomForest/scaler.joblib\n  adding: df-64-RandomForest/train_meta.json\n  adding: df-64-RandomForest/pipeline.joblib\n  adding: df-64-RandomForest/clf.joblib\n  adding: pgd-128-LogisticRegression/scaler.joblib\n  adding: pgd-128-LogisticRegression/train_meta.json\n  adding: pgd-128-LogisticRegression/pipeline.joblib\n  adding: pgd-128-LogisticRegression/clf.joblib\n  adding: pgd-512-RandomForest/scaler.joblib\n  adding: pgd-512-RandomForest/train_meta.json\n  adding: pgd-512-RandomForest/pipeline.joblib\n  adding: pgd-512-RandomForest/clf.joblib\n  adding: df-64-LogisticRegression/scaler.joblib\n  adding: df-64-LogisticRegression/train_meta.json\n  adding: df-64-LogisticRegression/pipeline.joblib\n  adding: df-64-LogisticRegression/clf.joblib\n  adding: cw-512-RandomForest/scaler.joblib\n  adding: cw-512-RandomForest/train_meta.json\n  adding: cw-512-RandomForest/pipeline.joblib\n  adding: cw-512-RandomForest/clf.joblib\n  adding: cw-64-LogisticRegression/scaler.joblib\n  adding: cw-64-LogisticRegression/train_meta.json\n  adding: cw-64-LogisticRegression/pipeline.joblib\n  adding: cw-64-LogisticRegression/clf.joblib\n  adding: pgd-32-LogisticRegression/scaler.joblib\n  adding: pgd-32-LogisticRegression/train_meta.json\n  adding: pgd-32-LogisticRegression/pipeline.joblib\n  adding: pgd-32-LogisticRegression/clf.joblib\n  adding: cw-128-RandomForest/scaler.joblib\n  adding: cw-128-RandomForest/train_meta.json\n  adding: cw-128-RandomForest/pipeline.joblib\n  adding: cw-128-RandomForest/clf.joblib\n  adding: df-128-LogisticRegression/scaler.joblib\n  adding: df-128-LogisticRegression/train_meta.json\n  adding: df-128-LogisticRegression/pipeline.joblib\n  adding: df-128-LogisticRegression/clf.joblib\n  adding: df-512-LogisticRegression/scaler.joblib\n  adding: df-512-LogisticRegression/train_meta.json\n  adding: df-512-LogisticRegression/pipeline.joblib\n  adding: df-512-LogisticRegression/clf.joblib\n  adding: df-1024-RandomForest/scaler.joblib\n  adding: df-1024-RandomForest/train_meta.json\n  adding: df-1024-RandomForest/pipeline.joblib\n  adding: df-1024-RandomForest/clf.joblib\n  adding: cw-1024-RandomForest/scaler.joblib\n  adding: cw-1024-RandomForest/train_meta.json\n  adding: cw-1024-RandomForest/pipeline.joblib\n  adding: cw-1024-RandomForest/clf.joblib\n  adding: fgsm-128-LogisticRegression/scaler.joblib\n  adding: fgsm-128-LogisticRegression/train_meta.json\n  adding: fgsm-128-LogisticRegression/pipeline.joblib\n  adding: fgsm-128-LogisticRegression/clf.joblib\n  adding: fgsm-512-RandomForest/scaler.joblib\n  adding: fgsm-512-RandomForest/train_meta.json\n  adding: fgsm-512-RandomForest/pipeline.joblib\n  adding: fgsm-512-RandomForest/clf.joblib\n  adding: df-128-RandomForest/scaler.joblib\n  adding: df-128-RandomForest/train_meta.json\n  adding: df-128-RandomForest/pipeline.joblib\n  adding: df-128-RandomForest/clf.joblib\n  adding: cw-1024-LogisticRegression/scaler.joblib\n  adding: cw-1024-LogisticRegression/train_meta.json\n  adding: cw-1024-LogisticRegression/pipeline.joblib\n  adding: cw-1024-LogisticRegression/clf.joblib\n  adding: pgd-32-RandomForest/scaler.joblib\n  adding: pgd-32-RandomForest/train_meta.json\n  adding: pgd-32-RandomForest/pipeline.joblib\n  adding: pgd-32-RandomForest/clf.joblib\n  adding: bim-1024-LogisticRegression/scaler.joblib\n  adding: bim-1024-LogisticRegression/train_meta.json\n  adding: bim-1024-LogisticRegression/pipeline.joblib\n  adding: bim-1024-LogisticRegression/clf.joblib\n  adding: pgd-64-LogisticRegression/scaler.joblib\n  adding: pgd-64-LogisticRegression/train_meta.json\n  adding: pgd-64-LogisticRegression/pipeline.joblib\n  adding: pgd-64-LogisticRegression/clf.joblib\n  adding: pgd-256-RandomForest/scaler.joblib\n  adding: pgd-256-RandomForest/train_meta.json\n  adding: pgd-256-RandomForest/pipeline.joblib\n  adding: pgd-256-RandomForest/clf.joblib\n  adding: fgsm-256-RandomForest/scaler.joblib\n  adding: fgsm-256-RandomForest/train_meta.json\n  adding: fgsm-256-RandomForest/pipeline.joblib\n  adding: fgsm-256-RandomForest/clf.joblib\n  adding: bim-512-RandomForest/scaler.joblib\n  adding: bim-512-RandomForest/train_meta.json\n  adding: bim-512-RandomForest/pipeline.joblib\n  adding: bim-512-RandomForest/clf.joblib\n  adding: bim-256-LogisticRegression/scaler.joblib\n  adding: bim-256-LogisticRegression/train_meta.json\n  adding: bim-256-LogisticRegression/pipeline.joblib\n  adding: bim-256-LogisticRegression/clf.joblib\n  adding: bim-512-LogisticRegression/scaler.joblib\n  adding: bim-512-LogisticRegression/train_meta.json\n  adding: bim-512-LogisticRegression/pipeline.joblib\n  adding: bim-512-LogisticRegression/clf.joblib\n  adding: fgsm-64-LogisticRegression/scaler.joblib\n  adding: fgsm-64-LogisticRegression/train_meta.json\n  adding: fgsm-64-LogisticRegression/pipeline.joblib\n  adding: fgsm-64-LogisticRegression/clf.joblib\n  adding: fgsm-1024-LogisticRegression/scaler.joblib\n  adding: fgsm-1024-LogisticRegression/train_meta.json\n  adding: fgsm-1024-LogisticRegression/pipeline.joblib\n  adding: fgsm-1024-LogisticRegression/clf.joblib\n  adding: bim-64-LogisticRegression/scaler.joblib\n  adding: bim-64-LogisticRegression/train_meta.json\n  adding: bim-64-LogisticRegression/pipeline.joblib\n  adding: bim-64-LogisticRegression/clf.joblib\n  adding: fgsm-32-RandomForest/scaler.joblib\n  adding: fgsm-32-RandomForest/train_meta.json\n  adding: fgsm-32-RandomForest/pipeline.joblib\n  adding: fgsm-32-RandomForest/clf.joblib\n  adding: bim-1024-RandomForest/scaler.joblib\n  adding: bim-1024-RandomForest/train_meta.json\n  adding: bim-1024-RandomForest/pipeline.joblib\n  adding: bim-1024-RandomForest/clf.joblib\n  adding: cw-64-RandomForest/scaler.joblib\n  adding: cw-64-RandomForest/train_meta.json\n  adding: cw-64-RandomForest/pipeline.joblib\n  adding: cw-64-RandomForest/clf.joblib\n  adding: pgd-256-LogisticRegression/scaler.joblib\n  adding: pgd-256-LogisticRegression/train_meta.json\n  adding: pgd-256-LogisticRegression/pipeline.joblib\n  adding: pgd-256-LogisticRegression/clf.joblib\n  adding: fgsm-64-RandomForest/scaler.joblib\n  adding: fgsm-64-RandomForest/train_meta.json\n  adding: fgsm-64-RandomForest/pipeline.joblib\n  adding: fgsm-64-RandomForest/clf.joblib\n  adding: bim-32-RandomForest/scaler.joblib\n  adding: bim-32-RandomForest/train_meta.json\n  adding: bim-32-RandomForest/pipeline.joblib\n  adding: bim-32-RandomForest/clf.joblib\n  adding: cw-512-LogisticRegression/scaler.joblib\n  adding: cw-512-LogisticRegression/train_meta.json\n  adding: cw-512-LogisticRegression/pipeline.joblib\n  adding: cw-512-LogisticRegression/clf.joblib\n  adding: fgsm-128-RandomForest/scaler.joblib\n  adding: fgsm-128-RandomForest/train_meta.json\n  adding: fgsm-128-RandomForest/pipeline.joblib\n  adding: fgsm-128-RandomForest/clf.joblib\n  adding: bim-128-RandomForest/scaler.joblib\n  adding: bim-128-RandomForest/train_meta.json\n  adding: bim-128-RandomForest/pipeline.joblib\n  adding: bim-128-RandomForest/clf.joblib\n  adding: cw-256-LogisticRegression/scaler.joblib\n  adding: cw-256-LogisticRegression/train_meta.json\n  adding: cw-256-LogisticRegression/pipeline.joblib\n  adding: cw-256-LogisticRegression/clf.joblib\n  adding: fgsm-32-LogisticRegression/scaler.joblib\n  adding: fgsm-32-LogisticRegression/train_meta.json\n  adding: fgsm-32-LogisticRegression/pipeline.joblib\n  adding: fgsm-32-LogisticRegression/clf.joblib\nComputing per-file SHA-256 and writing manifest: /kaggle/working/manifest-sha256.txt\nDone.\nCreated: /kaggle/working/models.zip\nCreated: /kaggle/working/manifest-sha256.txt\nCreated: /kaggle/working/models.zip.sha256\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"import hashlib\nimport os\nfrom pathlib import Path\nimport zipfile\nfrom datetime import datetime\n\n# -------------------------------\n# Config\n# -------------------------------\ninput_dir = Path(\"/kaggle/working/eval-VALSET\")\noutput_zip = Path(\"/kaggle/working/evals-VALSET.zip\")\nmanifest_path = Path(\"/kaggle/working/manifest-evals-VALSET-sha256.txt\")\nchunk_size = 8 * 1024 * 1024  # 8 MB\nskip_files = {output_zip.name, manifest_path.name}\n\n# -------------------------------\n# Helper: compute SHA256\n# -------------------------------\ndef sha256_of_file(path: Path) -> str:\n    h = hashlib.sha256()\n    with path.open(\"rb\") as f:\n        while True:\n            chunk = f.read(chunk_size)\n            if not chunk:\n                break\n            h.update(chunk)\n    return h.hexdigest()\n\n# -------------------------------\n# Collect files to zip\n# -------------------------------\nfiles_to_add = []\nfor root, dirs, files in os.walk(input_dir):\n    for fname in files:\n        full = Path(root) / fname\n        rel = full.relative_to(input_dir)\n        rel_str = str(rel).replace(os.sep, \"/\")\n        if rel.name in skip_files:\n            continue\n        files_to_add.append((full, rel))\n\nif not files_to_add:\n    print(f\"No files found in {input_dir} to archive.\")\nelse:\n    # -------------------------------\n    # Create zip\n    # -------------------------------\n    print(f\"Creating zip: {output_zip}\")\n    with zipfile.ZipFile(output_zip, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n        for full, rel in files_to_add:\n            arcname = str(rel).replace(os.sep, \"/\")\n            print(f\"  adding: {arcname}\")\n            zf.write(full, arcname=arcname)\n\n    # -------------------------------\n    # Create manifest\n    # -------------------------------\n    print(f\"Computing per-file SHA-256 and writing manifest: {manifest_path}\")\n    with manifest_path.open(\"w\", encoding=\"utf-8\") as mf:\n        mf.write(f\"# manifest generated: {datetime.utcnow().isoformat()}Z\\n\")\n        mf.write(f\"# input_dir: {input_dir}\\n\")\n        mf.write(\"# format: <sha256>  <relative/path>\\n\")\n        for full, rel in files_to_add:\n            rel_unix = str(rel).replace(os.sep, \"/\")\n            h = sha256_of_file(full)\n            size = full.stat().st_size\n            mf.write(f\"{h}  {rel_unix}  # {size} bytes\\n\")\n\n    # -------------------------------\n    # Compute zip SHA256\n    # -------------------------------\n    zip_hash = sha256_of_file(output_zip)\n    ziphash_path = output_zip.with_suffix(output_zip.suffix + \".sha256\")\n    with ziphash_path.open(\"w\", encoding=\"utf-8\") as zh:\n        zh.write(f\"{zip_hash}  {output_zip.name}\\n\")\n\n    print(\"Done.\")\n    print(f\"Created: {output_zip}\")\n    print(f\"Created: {manifest_path}\")\n    print(f\"Created: {ziphash_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T14:43:28.765341Z","iopub.execute_input":"2025-10-19T14:43:28.765705Z","iopub.status.idle":"2025-10-19T14:43:28.812826Z","shell.execute_reply.started":"2025-10-19T14:43:28.765679Z","shell.execute_reply":"2025-10-19T14:43:28.811837Z"}},"outputs":[{"name":"stdout","text":"Creating zip: /kaggle/working/evals-VALSET.zip\n  adding: pgd-cw-128-RandomForest_test_result.csv\n  adding: pgd-cw-512-LogisticRegression_test_result.csv\n  adding: df-cw-64-RandomForest_test_result.csv\n  adding: fgsm-cw-1024-LogisticRegression_test_result.csv\n  adding: pgd-cw-512-LogisticRegression_test_result_predictions.csv\n  adding: df-cw-128-LogisticRegression_test_result_predictions.csv\n  adding: cw-cw-256-LogisticRegression_test_result_predictions.csv\n  adding: fgsm-cw-64-RandomForest_test_result_predictions.csv\n  adding: df-cw-512-LogisticRegression_test_result.csv\n  adding: fgsm-cw-1024-RandomForest_test_result_predictions.csv\n  adding: fgsm-cw-512-LogisticRegression_test_result.csv\n  adding: bim-cw-128-LogisticRegression_test_result.csv\n  adding: fgsm-cw-512-RandomForest_test_result.csv\n  adding: bim-cw-32-LogisticRegression_test_result.csv\n  adding: pgd-cw-64-LogisticRegression_test_result.csv\n  adding: pgd-cw-512-RandomForest_test_result.csv\n  adding: pgd-cw-32-RandomForest_test_result_predictions.csv\n  adding: bim-cw-64-RandomForest_test_result_predictions.csv\n  adding: cw-cw-128-LogisticRegression_test_result.csv\n  adding: pgd-cw-256-LogisticRegression_test_result.csv\n  adding: fgsm-cw-512-LogisticRegression_test_result_predictions.csv\n  adding: fgsm-cw-32-RandomForest_test_result_predictions.csv\n  adding: pgd-cw-256-RandomForest_test_result.csv\n  adding: fgsm-cw-32-LogisticRegression_test_result.csv\n  adding: bim-cw-512-RandomForest_test_result.csv\n  adding: cw-cw-1024-RandomForest_test_result_predictions.csv\n  adding: cw-cw-64-LogisticRegression_test_result.csv\n  adding: pgd-cw-128-LogisticRegression_test_result_predictions.csv\n  adding: cw-cw-256-RandomForest_test_result_predictions.csv\n  adding: df-cw-1024-RandomForest_test_result_predictions.csv\n  adding: pgd-cw-64-RandomForest_test_result_predictions.csv\n  adding: cw-cw-128-LogisticRegression_test_result_predictions.csv\n  adding: bim-cw-32-LogisticRegression_test_result_predictions.csv\n  adding: fgsm-cw-256-RandomForest_test_result_predictions.csv\n  adding: fgsm-cw-64-LogisticRegression_test_result_predictions.csv\n  adding: cw-cw-1024-LogisticRegression_test_result.csv\n  adding: df-cw-32-RandomForest_test_result.csv\n  adding: cw-cw-256-LogisticRegression_test_result.csv\n  adding: df-cw-256-LogisticRegression_test_result.csv\n  adding: cw-cw-256-RandomForest_test_result.csv\n  adding: bim-cw-256-RandomForest_test_result.csv\n  adding: cw-cw-512-LogisticRegression_test_result.csv\n  adding: fgsm-cw-64-LogisticRegression_test_result.csv\n  adding: bim-cw-256-RandomForest_test_result_predictions.csv\n  adding: bim-cw-32-RandomForest_test_result_predictions.csv\n  adding: fgsm-cw-512-RandomForest_test_result_predictions.csv\n  adding: cw-cw-32-LogisticRegression_test_result.csv\n  adding: cw-cw-64-RandomForest_test_result_predictions.csv\n  adding: fgsm-cw-32-RandomForest_test_result.csv\n  adding: bim-cw-1024-RandomForest_test_result_predictions.csv\n  adding: cw-cw-128-RandomForest_test_result_predictions.csv\n  adding: pgd-cw-1024-LogisticRegression_test_result.csv\n  adding: bim-cw-1024-LogisticRegression_test_result.csv\n  adding: pgd-cw-128-LogisticRegression_test_result.csv\n  adding: df-cw-512-LogisticRegression_test_result_predictions.csv\n  adding: df-cw-1024-LogisticRegression_test_result.csv\n  adding: fgsm-cw-128-LogisticRegression_test_result_predictions.csv\n  adding: pgd-cw-32-LogisticRegression_test_result_predictions.csv\n  adding: fgsm-cw-256-LogisticRegression_test_result_predictions.csv\n  adding: fgsm-cw-32-LogisticRegression_test_result_predictions.csv\n  adding: bim-cw-1024-LogisticRegression_test_result_predictions.csv\n  adding: df-cw-256-RandomForest_test_result.csv\n  adding: cw-cw-64-LogisticRegression_test_result_predictions.csv\n  adding: bim-cw-64-LogisticRegression_test_result.csv\n  adding: cw-cw-512-LogisticRegression_test_result_predictions.csv\n  adding: df-cw-512-RandomForest_test_result.csv\n  adding: fgsm-cw-256-LogisticRegression_test_result.csv\n  adding: df-cw-32-LogisticRegression_test_result_predictions.csv\n  adding: pgd-cw-32-LogisticRegression_test_result.csv\n  adding: df-cw-64-RandomForest_test_result_predictions.csv\n  adding: cw-cw-1024-LogisticRegression_test_result_predictions.csv\n  adding: bim-cw-512-LogisticRegression_test_result.csv\n  adding: fgsm-cw-1024-LogisticRegression_test_result_predictions.csv\n  adding: pgd-cw-256-RandomForest_test_result_predictions.csv\n  adding: bim-cw-64-RandomForest_test_result.csv\n  adding: fgsm-cw-128-RandomForest_test_result.csv\n  adding: df-cw-256-RandomForest_test_result_predictions.csv\n  adding: bim-cw-1024-RandomForest_test_result.csv\n  adding: df-cw-512-RandomForest_test_result_predictions.csv\n  adding: pgd-cw-256-LogisticRegression_test_result_predictions.csv\n  adding: cw-cw-64-RandomForest_test_result.csv\n  adding: fgsm-cw-1024-RandomForest_test_result.csv\n  adding: fgsm-cw-128-LogisticRegression_test_result.csv\n  adding: pgd-cw-1024-LogisticRegression_test_result_predictions.csv\n  adding: df-cw-32-RandomForest_test_result_predictions.csv\n  adding: bim-cw-128-RandomForest_test_result.csv\n  adding: df-cw-64-LogisticRegression_test_result_predictions.csv\n  adding: cw-cw-32-LogisticRegression_test_result_predictions.csv\n  adding: cw-cw-128-RandomForest_test_result.csv\n  adding: cw-cw-512-RandomForest_test_result_predictions.csv\n  adding: bim-cw-256-LogisticRegression_test_result.csv\n  adding: cw-cw-1024-RandomForest_test_result.csv\n  adding: fgsm-cw-256-RandomForest_test_result.csv\n  adding: df-cw-128-LogisticRegression_test_result.csv\n  adding: bim-cw-256-LogisticRegression_test_result_predictions.csv\n  adding: bim-cw-64-LogisticRegression_test_result_predictions.csv\n  adding: bim-cw-32-RandomForest_test_result.csv\n  adding: bim-cw-512-RandomForest_test_result_predictions.csv\n  adding: df-cw-128-RandomForest_test_result.csv\n  adding: bim-cw-128-RandomForest_test_result_predictions.csv\n  adding: df-cw-256-LogisticRegression_test_result_predictions.csv\n  adding: fgsm-cw-64-RandomForest_test_result.csv\n  adding: pgd-cw-128-RandomForest_test_result_predictions.csv\n  adding: pgd-cw-1024-RandomForest_test_result.csv\n  adding: pgd-cw-1024-RandomForest_test_result_predictions.csv\n  adding: cw-cw-512-RandomForest_test_result.csv\n  adding: cw-cw-32-RandomForest_test_result.csv\n  adding: bim-cw-128-LogisticRegression_test_result_predictions.csv\n  adding: pgd-cw-64-LogisticRegression_test_result_predictions.csv\n  adding: fgsm-cw-128-RandomForest_test_result_predictions.csv\n  adding: df-cw-128-RandomForest_test_result_predictions.csv\n  adding: df-cw-1024-RandomForest_test_result.csv\n  adding: df-cw-64-LogisticRegression_test_result.csv\n  adding: pgd-cw-64-RandomForest_test_result.csv\n  adding: bim-cw-512-LogisticRegression_test_result_predictions.csv\n  adding: df-cw-1024-LogisticRegression_test_result_predictions.csv\n  adding: pgd-cw-512-RandomForest_test_result_predictions.csv\n  adding: df-cw-32-LogisticRegression_test_result.csv\n  adding: cw-cw-32-RandomForest_test_result_predictions.csv\n  adding: pgd-cw-32-RandomForest_test_result.csv\nComputing per-file SHA-256 and writing manifest: /kaggle/working/manifest-evals-VALSET-sha256.txt\nDone.\nCreated: /kaggle/working/evals-VALSET.zip\nCreated: /kaggle/working/manifest-evals-VALSET-sha256.txt\nCreated: /kaggle/working/evals-VALSET.zip.sha256\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}