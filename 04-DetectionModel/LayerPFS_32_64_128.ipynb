{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-20T18:43:50.528998Z",
     "iopub.status.busy": "2025-10-20T18:43:50.528780Z",
     "iopub.status.idle": "2025-10-20T18:43:52.335474Z",
     "shell.execute_reply": "2025-10-20T18:43:52.334608Z",
     "shell.execute_reply.started": "2025-10-20T18:43:50.528982Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "\n",
    "def _save_json(p, obj):\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(p, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "\n",
    "def train_from_npy(\n",
    "    train_npy_path,\n",
    "    model_out_dir,\n",
    "    train_labels_npy_path,\n",
    "    random_seed=42,\n",
    "    mem_limit_bytes=100_000_000_000,\n",
    "    use_mmap=False,\n",
    "    classifier='LogisticRegression'\n",
    "):\n",
    "    train_npy_path = Path(train_npy_path)\n",
    "    if not train_npy_path.exists():\n",
    "        raise FileNotFoundError(f\"Train npy not found: {train_npy_path}\")\n",
    "\n",
    "    model_out_dir = Path(model_out_dir)\n",
    "    model_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    X_train = np.load(str(train_npy_path), mmap_mode=\"r\" if use_mmap else None)\n",
    "    if X_train.ndim != 2:\n",
    "        raise RuntimeError(f\"train array must be 2D. got shape={X_train.shape}\")\n",
    "\n",
    "    labels_path = Path(train_labels_npy_path)\n",
    "    if not labels_path.exists():\n",
    "        raise FileNotFoundError(f\"Provided train_labels_npy_path does not exist: {labels_path}\")\n",
    "    y_train = np.load(str(labels_path), mmap_mode=\"r\" if use_mmap else None)\n",
    "    if y_train.shape[0] != X_train.shape[0]:\n",
    "        raise RuntimeError(f\"train labels length ({y_train.shape[0]}) != train rows ({X_train.shape[0]})\")\n",
    "\n",
    "    y_train = y_train.astype(np.int64)\n",
    "    unique = np.unique(y_train)\n",
    "    if unique.size != 2 or not np.array_equal(np.sort(unique), np.array([0, 1])):\n",
    "        raise RuntimeError(f\"train labels must contain exactly two classes 0 and 1. found: {unique}\")\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "\n",
    "    estimated_bytes = getattr(X_train, \"nbytes\", X_train.size * X_train.itemsize)\n",
    "    if estimated_bytes > mem_limit_bytes:\n",
    "        raise MemoryError(\n",
    "            f\"Estimated train bytes {estimated_bytes} > mem_limit_bytes {mem_limit_bytes}. \"\n",
    "            \"Either increase mem_limit_bytes, reduce dataset size, or use use_mmap=True and implement chunked/out-of-core training.\"\n",
    "        )\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    if classifier == 'LogisticRegression':\n",
    "        print ('Using LogisticRegression as classifier')\n",
    "        clf = LogisticRegression(random_state=random_seed, n_jobs=-1, verbose=1)\n",
    "    elif classifier == 'RandomForest':\n",
    "        print ('Using RandomForest as classifier')\n",
    "        clf = RandomForestClassifier(random_state=random_seed, n_jobs=-1, verbose=1)\n",
    "    else:\n",
    "        print ('Using SVC as classifier')\n",
    "        clf = SVC(random_state=random_seed, verbose=0)\n",
    "\n",
    "    pipeline = Pipeline([(\"scaler\", scaler), (\"clf\", clf)])\n",
    "\n",
    "    print(f\"Fitting pipeline\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    try:\n",
    "        y_pred_train, y_score_train = _predict_and_score(pipeline, None, None, X_train)\n",
    "        train_metrics = _compute_metrics(y_train, y_pred_train, y_score_train)\n",
    "\n",
    "        print(\"TRAIN Eval results:\")\n",
    "        print(f\"  acc={train_metrics['accuracy']:.4f}  prec={train_metrics['precision']:.4f}  \"\n",
    "              f\"recall={train_metrics['recall']:.4f}  f1={train_metrics['f1']:.4f}\")\n",
    "        if train_metrics.get(\"roc_auc\") is not None:\n",
    "            print(f\"  roc_auc={train_metrics['roc_auc']:.4f}\")\n",
    "        print(\"  confusion_matrix:\", train_metrics[\"confusion_matrix\"])\n",
    "    except Exception as e:\n",
    "\n",
    "        print(\"Warning: failed to compute train metrics:\", e)\n",
    "        train_metrics = None\n",
    "\n",
    "    pipeline_path = model_out_dir / \"pipeline.joblib\"\n",
    "    scaler_path = model_out_dir / \"scaler.joblib\"\n",
    "    clf_path = model_out_dir / \"clf.joblib\"\n",
    "    meta_out = model_out_dir / \"train_meta.json\"\n",
    "\n",
    "    joblib.dump(pipeline, pipeline_path)\n",
    "    joblib.dump(pipeline.named_steps[\"scaler\"], scaler_path)\n",
    "    joblib.dump(pipeline.named_steps[\"clf\"], clf_path)\n",
    "\n",
    "    meta_obj = {\n",
    "        \"train_npy\": str(train_npy_path),\n",
    "        \"train_labels_npy\": str(train_labels_npy_path),\n",
    "        \"train_rows\": int(X_train.shape[0]),\n",
    "        \"C\": None,\n",
    "        \"random_seed\": int(random_seed),\n",
    "        \"use_mmap\": bool(use_mmap),\n",
    "        # store train metrics (or null) so you have a record\n",
    "        \"train_metrics\": train_metrics,\n",
    "    }\n",
    "    _save_json(meta_out, meta_obj)\n",
    "\n",
    "    print(\"Saved pipeline ->\", pipeline_path)\n",
    "    print(\"Saved scaler ->\", scaler_path)\n",
    "    print(\"Saved classifier ->\", clf_path)\n",
    "    return str(model_out_dir)\n",
    "\n",
    "def _load_model(model_out_dir):\n",
    "    \"\"\"Load pipeline if present, else scaler+clf. Returns (pipeline, scaler, clf).\"\"\"\n",
    "    model_out_dir = Path(model_out_dir)\n",
    "    pipeline_path = model_out_dir / \"pipeline.joblib\"\n",
    "    scaler_path = model_out_dir / \"scaler.joblib\"\n",
    "    clf_path = model_out_dir / \"clf.joblib\"\n",
    "\n",
    "    pipeline = None\n",
    "    scaler = None\n",
    "    clf = None\n",
    "\n",
    "    if pipeline_path.exists():\n",
    "        pipeline = joblib.load(pipeline_path)\n",
    "    else:\n",
    "        if scaler_path.exists():\n",
    "            scaler = joblib.load(scaler_path)\n",
    "        if clf_path.exists():\n",
    "            clf = joblib.load(clf_path)\n",
    "        if scaler is None or clf is None:\n",
    "            raise FileNotFoundError(\"Could not find pipeline or scaler+clf in model_out_dir.\")\n",
    "    return pipeline, scaler, clf\n",
    "\n",
    "\n",
    "def _compute_metrics(y_true, y_pred, y_score):\n",
    "    metrics = {}\n",
    "    metrics[\"accuracy\"] = float(accuracy_score(y_true, y_pred))\n",
    "    metrics[\"precision\"] = float(precision_score(y_true, y_pred, zero_division=0))\n",
    "    metrics[\"recall\"] = float(recall_score(y_true, y_pred, zero_division=0))\n",
    "    metrics[\"f1\"] = float(f1_score(y_true, y_pred, zero_division=0))\n",
    "    try:\n",
    "        if y_score is not None and len(np.unique(y_true)) == 2:\n",
    "            metrics[\"roc_auc\"] = float(roc_auc_score(y_true, y_score))\n",
    "        else:\n",
    "            metrics[\"roc_auc\"] = None\n",
    "    except Exception:\n",
    "        metrics[\"roc_auc\"] = None\n",
    "    metrics[\"confusion_matrix\"] = confusion_matrix(y_true, y_pred).tolist()\n",
    "    metrics[\"classification_report\"] = classification_report(y_true, y_pred, zero_division=0, output_dict=True)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def _predict_and_score(pipeline, scaler, clf, X_test):\n",
    "    y_score = None\n",
    "    if pipeline is not None:\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        if hasattr(pipeline, \"predict_proba\"):\n",
    "            try:\n",
    "                y_score = pipeline.predict_proba(X_test)[:, 1]\n",
    "            except Exception:\n",
    "                y_score = None\n",
    "        else:\n",
    "            try:\n",
    "                clf_ = pipeline.named_steps[\"clf\"]\n",
    "                scaler_ = pipeline.named_steps[\"scaler\"]\n",
    "                if hasattr(clf_, \"decision_function\"):\n",
    "                    y_score = clf_.decision_function(scaler_.transform(X_test))\n",
    "            except Exception:\n",
    "                y_score = None\n",
    "    else:\n",
    "        X_t = scaler.transform(X_test)\n",
    "        y_pred = clf.predict(X_t)\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            y_score = clf.predict_proba(X_t)[:, 1]\n",
    "        elif hasattr(clf, \"decision_function\"):\n",
    "            y_score = clf.decision_function(X_t)\n",
    "    return y_pred, y_score\n",
    "\n",
    "\n",
    "def eval_val_from_npy(\n",
    "    val_npy_path,\n",
    "    val_label_path,\n",
    "    model_out_dir=\"./models\",\n",
    "    return_predictions=False,\n",
    "    use_mmap=False,\n",
    "    csv_path=None,  \n",
    "):\n",
    "    val_npy_path = Path(val_npy_path)\n",
    "    val_label_path = Path(val_label_path)\n",
    "    if not val_npy_path.exists():\n",
    "        raise FileNotFoundError(f\"val_npy not found: {val_npy_path}\")\n",
    "\n",
    "    X_test = np.load(str(val_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n",
    "    y_test = np.load(str(val_label_path), mmap_mode=\"r\" if use_mmap else None).astype(np.uint8)\n",
    "    \n",
    "    if X_test.shape[0] != y_test.shape[0]:\n",
    "        raise RuntimeError(f\"val X rows ({X_test.shape[0]}) != val labels length ({y_test.shape[0]})\")\n",
    "\n",
    "    pipeline, scaler, clf = _load_model(model_out_dir)\n",
    "\n",
    "    y_pred, y_score = _predict_and_score(pipeline, scaler, clf, X_test)\n",
    "\n",
    "    metrics = _compute_metrics(y_test, y_pred, y_score)\n",
    "\n",
    "    print(\"VAL Eval results:\")\n",
    "    print(f\"  acc={metrics['accuracy']:.4f}  prec={metrics['precision']:.4f}  recall={metrics['recall']:.4f}  f1={metrics['f1']:.4f}\")\n",
    "    if metrics[\"roc_auc\"] is not None:\n",
    "        print(f\"  roc_auc={metrics['roc_auc']:.4f}\")\n",
    "    print(\"  confusion_matrix:\", metrics[\"confusion_matrix\"])\n",
    "\n",
    "    if csv_path is not None:\n",
    "        csv_path = Path(csv_path)\n",
    "        csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        metrics_df = pd.DataFrame([metrics])\n",
    "        metrics_df.to_csv(csv_path, index=False)\n",
    "\n",
    "        if return_predictions:\n",
    "            preds_path = csv_path.with_name(csv_path.stem + \"_predictions.csv\")\n",
    "            preds_df = pd.DataFrame({\n",
    "                \"y_true\": y_test,\n",
    "                \"y_pred\": y_pred,\n",
    "                \"y_score\": y_score\n",
    "            })\n",
    "            preds_df.to_csv(preds_path, index=False)\n",
    "            print(f\"Predictions saved to: {preds_path}\")\n",
    "\n",
    "        print(f\"Metrics saved to: {csv_path}\")\n",
    "\n",
    "    return {\n",
    "        \"metrics\": metrics,\n",
    "        \"y_true\": y_test if return_predictions else None,\n",
    "        \"y_pred\": y_pred if return_predictions else None,\n",
    "        \"y_score\": y_score if return_predictions else None,\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_test_from_npy(\n",
    "    test_clean_npy_path,\n",
    "    test_adv_npy_path=None,\n",
    "    model_out_dir=\"./models\",\n",
    "    test_labels_npy_path=None,\n",
    "    return_predictions=False,\n",
    "    use_mmap=False,\n",
    "    csv_path=None,  \n",
    "):\n",
    "    test_clean_npy_path = Path(test_clean_npy_path)\n",
    "    if not test_clean_npy_path.exists():\n",
    "        raise FileNotFoundError(f\"test_clean npy not found: {test_clean_npy_path}\")\n",
    "\n",
    "    if test_adv_npy_path is None:\n",
    "        if test_labels_npy_path is None:\n",
    "            raise ValueError(\"Single-file mode requires test_labels_npy_path.\")\n",
    "        X_test = np.load(str(test_clean_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n",
    "        y_test = np.load(str(test_labels_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.uint8)\n",
    "        if X_test.shape[0] != y_test.shape[0]:\n",
    "            raise RuntimeError(f\"test X rows ({X_test.shape[0]}) != test labels length ({y_test.shape[0]})\")\n",
    "    else:\n",
    "        test_adv_npy_path = Path(test_adv_npy_path)\n",
    "        if not test_adv_npy_path.exists():\n",
    "            raise FileNotFoundError(f\"test_adv npy not found: {test_adv_npy_path}\")\n",
    "        X_clean = np.load(str(test_clean_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n",
    "        X_adv = np.load(str(test_adv_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n",
    "        X_test = np.vstack([X_clean, X_adv])\n",
    "        if test_labels_npy_path is not None:\n",
    "            y_test = np.load(str(test_labels_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.uint8)\n",
    "            if y_test.shape[0] != X_test.shape[0]:\n",
    "                raise RuntimeError(f\"test labels length ({y_test.shape[0]}) != stacked test rows ({X_test.shape[0]})\")\n",
    "        else:\n",
    "            y_test = np.concatenate([\n",
    "                np.zeros(X_clean.shape[0], dtype=np.uint8),\n",
    "                np.ones(X_adv.shape[0], dtype=np.uint8)\n",
    "            ])\n",
    "\n",
    "    pipeline, scaler, clf = _load_model(model_out_dir)\n",
    "    y_pred, y_score = _predict_and_score(pipeline, scaler, clf, X_test)\n",
    "    metrics = _compute_metrics(y_test, y_pred, y_score)\n",
    "\n",
    "    print(\"TEST Eval results:\")\n",
    "    print(f\"  acc={metrics['accuracy']:.4f}  prec={metrics['precision']:.4f}  recall={metrics['recall']:.4f}  f1={metrics['f1']:.4f}\")\n",
    "    if metrics[\"roc_auc\"] is not None:\n",
    "        print(f\"  roc_auc={metrics['roc_auc']:.4f}\")\n",
    "\n",
    "    if csv_path is not None:\n",
    "        csv_path = Path(csv_path)\n",
    "        csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        metrics_df = pd.DataFrame([metrics])\n",
    "        metrics_df.to_csv(csv_path, index=False)\n",
    "\n",
    "        if return_predictions:\n",
    "            preds_path = csv_path.with_name(csv_path.stem + \"_predictions.csv\")\n",
    "            preds_df = pd.DataFrame({\n",
    "                \"y_true\": y_test,\n",
    "                \"y_pred\": y_pred,\n",
    "                \"y_score\": y_score\n",
    "            })\n",
    "            preds_df.to_csv(preds_path, index=False)\n",
    "            print(f\"Predictions saved to: {preds_path}\")\n",
    "\n",
    "        print(f\"Metrics saved to: {csv_path}\")\n",
    "\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T19:57:55.926030Z",
     "iopub.status.busy": "2025-10-18T19:57:55.925718Z",
     "iopub.status.idle": "2025-10-18T19:58:30.159058Z",
     "shell.execute_reply": "2025-10-18T19:58:30.157850Z",
     "shell.execute_reply.started": "2025-10-18T19:57:55.926012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 32 - fgsm - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/fgsm-32-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/fgsm-32-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/fgsm-32-LogisticRegression/clf.joblib\n",
      "Training: 32 - bim - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/bim-32-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/bim-32-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/bim-32-LogisticRegression/clf.joblib\n",
      "Training: 32 - pgd - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/pgd-32-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/pgd-32-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/pgd-32-LogisticRegression/clf.joblib\n",
      "Training: 32 - df - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=0.9959  prec=1.0000  recall=0.9918  f1=0.9959\n",
      "  roc_auc=0.9999\n",
      "  confusion_matrix: [[486, 0], [4, 482]]\n",
      "Saved pipeline -> models/df-32-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/df-32-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/df-32-LogisticRegression/clf.joblib\n",
      "Training: 32 - cw - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=0.9938  prec=0.9959  recall=0.9918  f1=0.9938\n",
      "  roc_auc=0.9999\n",
      "  confusion_matrix: [[484, 2], [4, 482]]\n",
      "Saved pipeline -> models/cw-32-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/cw-32-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/cw-32-LogisticRegression/clf.joblib\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 32\n",
    "ATTACKS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n",
    "classifier = 'LogisticRegression'\n",
    "for ATTACK in ATTACKS:\n",
    "    print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "    train_from_npy( train_npy_path = f\"/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_raw.npy\",\n",
    "                    model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                    train_labels_npy_path=f\"/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_labels.npy\",\n",
    "                    random_seed=42,\n",
    "                    mem_limit_bytes=100_000_000_000,\n",
    "                    use_mmap=False,\n",
    "                    classifier = classifier)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T19:58:30.159949Z",
     "iopub.status.busy": "2025-10-18T19:58:30.159755Z",
     "iopub.status.idle": "2025-10-18T19:58:36.154283Z",
     "shell.execute_reply": "2025-10-18T19:58:36.153202Z",
     "shell.execute_reply.started": "2025-10-18T19:58:30.159932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 32 - fgsm - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    0.2s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/fgsm-32-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/fgsm-32-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/fgsm-32-RandomForest/clf.joblib\n",
      "Training: 32 - bim - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    0.2s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/bim-32-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/bim-32-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/bim-32-RandomForest/clf.joblib\n",
      "Training: 32 - pgd - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    0.2s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.1s remaining:    0.7s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/pgd-32-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/pgd-32-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/pgd-32-RandomForest/clf.joblib\n",
      "Training: 32 - df - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    0.3s remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/df-32-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/df-32-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/df-32-RandomForest/clf.joblib\n",
      "Training: 32 - cw - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    0.2s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/cw-32-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/cw-32-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/cw-32-RandomForest/clf.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 32\n",
    "ATTACKS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n",
    "classifier = 'RandomForest'\n",
    "for ATTACK in ATTACKS:\n",
    "    print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "    train_from_npy( train_npy_path = f\"/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_raw.npy\",\n",
    "                    model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                    train_labels_npy_path=f\"/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_labels.npy\",\n",
    "                    random_seed=42,\n",
    "                    mem_limit_bytes=100_000_000_000,\n",
    "                    use_mmap=False,\n",
    "                    classifier = classifier)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T19:58:36.155263Z",
     "iopub.status.busy": "2025-10-18T19:58:36.155074Z",
     "iopub.status.idle": "2025-10-18T20:00:22.742946Z",
     "shell.execute_reply": "2025-10-18T20:00:22.742161Z",
     "shell.execute_reply.started": "2025-10-18T19:58:36.155247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 64 - fgsm - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/fgsm-64-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/fgsm-64-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/fgsm-64-LogisticRegression/clf.joblib\n",
      "Training: 64 - bim - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/bim-64-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/bim-64-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/bim-64-LogisticRegression/clf.joblib\n",
      "Training: 64 - pgd - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/pgd-64-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/pgd-64-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/pgd-64-LogisticRegression/clf.joblib\n",
      "Training: 64 - df - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=0.9979  prec=0.9979  recall=0.9979  f1=0.9979\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[485, 1], [1, 485]]\n",
      "Saved pipeline -> models/df-64-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/df-64-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/df-64-LogisticRegression/clf.joblib\n",
      "Training: 64 - cw - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/cw-64-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/cw-64-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/cw-64-LogisticRegression/clf.joblib\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 64\n",
    "ATTACKS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n",
    "classifier = 'LogisticRegression'\n",
    "for ATTACK in ATTACKS:\n",
    "    print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "    train_from_npy( train_npy_path = f\"/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_raw.npy\",\n",
    "                    model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                    train_labels_npy_path=f\"/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_labels.npy\",\n",
    "                    random_seed=42,\n",
    "                    mem_limit_bytes=100_000_000_000,\n",
    "                    use_mmap=False,\n",
    "                    classifier = classifier)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T20:00:22.743628Z",
     "iopub.status.busy": "2025-10-18T20:00:22.743455Z",
     "iopub.status.idle": "2025-10-18T20:00:37.236620Z",
     "shell.execute_reply": "2025-10-18T20:00:37.235608Z",
     "shell.execute_reply.started": "2025-10-18T20:00:22.743613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 64 - fgsm - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    0.5s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/fgsm-64-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/fgsm-64-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/fgsm-64-RandomForest/clf.joblib\n",
      "Training: 64 - bim - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    0.5s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/bim-64-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/bim-64-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/bim-64-RandomForest/clf.joblib\n",
      "Training: 64 - pgd - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    0.5s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/pgd-64-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/pgd-64-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/pgd-64-RandomForest/clf.joblib\n",
      "Training: 64 - df - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    0.5s remaining:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/df-64-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/df-64-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/df-64-RandomForest/clf.joblib\n",
      "Training: 64 - cw - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    0.6s remaining:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/cw-64-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/cw-64-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/cw-64-RandomForest/clf.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 64\n",
    "ATTACKS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n",
    "classifier = 'RandomForest'\n",
    "for ATTACK in ATTACKS:\n",
    "    print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "    train_from_npy( train_npy_path = f\"/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_raw.npy\",\n",
    "                    model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                    train_labels_npy_path=f\"/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_labels.npy\",\n",
    "                    random_seed=42,\n",
    "                    mem_limit_bytes=100_000_000_000,\n",
    "                    use_mmap=False,\n",
    "                    classifier = classifier)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T20:00:37.237349Z",
     "iopub.status.busy": "2025-10-18T20:00:37.237168Z",
     "iopub.status.idle": "2025-10-18T20:03:25.343637Z",
     "shell.execute_reply": "2025-10-18T20:03:25.342438Z",
     "shell.execute_reply.started": "2025-10-18T20:00:37.237332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 128 - fgsm - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    1.0s remaining:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/fgsm-128-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/fgsm-128-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/fgsm-128-RandomForest/clf.joblib\n",
      "__________________________\n",
      "\n",
      "Training: 128 - bim - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    0.8s remaining:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/bim-128-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/bim-128-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/bim-128-RandomForest/clf.joblib\n",
      "__________________________\n",
      "\n",
      "Training: 128 - pgd - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    0.8s remaining:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/pgd-128-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/pgd-128-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/pgd-128-RandomForest/clf.joblib\n",
      "__________________________\n",
      "\n",
      "Training: 128 - df - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    1.3s remaining:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/df-128-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/df-128-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/df-128-RandomForest/clf.joblib\n",
      "__________________________\n",
      "\n",
      "Training: 128 - cw - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    1.4s remaining:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/cw-128-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/cw-128-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/cw-128-RandomForest/clf.joblib\n",
      "__________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 128\n",
    "ATTACKS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n",
    "classifier = 'RandomForest'\n",
    "for ATTACK in ATTACKS:\n",
    "    print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "    train_from_npy( train_npy_path = f\"/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_raw.npy\",\n",
    "                    model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                    train_labels_npy_path=f\"/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_labels.npy\",\n",
    "                    random_seed=42,\n",
    "                    mem_limit_bytes=100_000_000_000,\n",
    "                    use_mmap=False,\n",
    "                    classifier = classifier)\n",
    "    print ('__________________________\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T20:03:25.344502Z",
     "iopub.status.busy": "2025-10-18T20:03:25.344283Z",
     "iopub.status.idle": "2025-10-18T20:07:51.593291Z",
     "shell.execute_reply": "2025-10-18T20:07:51.592251Z",
     "shell.execute_reply.started": "2025-10-18T20:03:25.344485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 128 - fgsm - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/fgsm-128-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/fgsm-128-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/fgsm-128-LogisticRegression/clf.joblib\n",
      "__________________________\n",
      "\n",
      "Training: 128 - bim - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/bim-128-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/bim-128-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/bim-128-LogisticRegression/clf.joblib\n",
      "__________________________\n",
      "\n",
      "Training: 128 - pgd - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/pgd-128-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/pgd-128-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/pgd-128-LogisticRegression/clf.joblib\n",
      "__________________________\n",
      "\n",
      "Training: 128 - df - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=0.9990  prec=0.9979  recall=1.0000  f1=0.9990\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[485, 1], [0, 486]]\n",
      "Saved pipeline -> models/df-128-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/df-128-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/df-128-LogisticRegression/clf.joblib\n",
      "__________________________\n",
      "\n",
      "Training: 128 - cw - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=0.9990  prec=1.0000  recall=0.9979  f1=0.9990\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [1, 485]]\n",
      "Saved pipeline -> models/cw-128-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/cw-128-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/cw-128-LogisticRegression/clf.joblib\n",
      "__________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 128\n",
    "ATTACKS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n",
    "classifier = 'LogisticRegression'\n",
    "for ATTACK in ATTACKS:\n",
    "    print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "    train_from_npy( train_npy_path = f\"/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_raw.npy\",\n",
    "                    model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                    train_labels_npy_path=f\"/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_labels.npy\",\n",
    "                    random_seed=42,\n",
    "                    mem_limit_bytes=100_000_000_000,\n",
    "                    use_mmap=False,\n",
    "                    classifier = classifier)\n",
    "    print ('__________________________\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Dataset (LR vs RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T18:43:58.992151Z",
     "iopub.status.busy": "2025-10-20T18:43:58.991813Z",
     "iopub.status.idle": "2025-10-20T18:44:57.657482Z",
     "shell.execute_reply": "2025-10-20T18:44:57.656248Z",
     "shell.execute_reply.started": "2025-10-20T18:43:58.992135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Method: fgsm\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.8272  prec=0.8046  recall=0.8642  f1=0.8333\n",
      "  roc_auc=0.8999\n",
      "  confusion_matrix: [[64, 17], [11, 70]]\n",
      "Predictions saved to: eval-VALSET/fgsm-fgsm-32-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/fgsm-fgsm-32-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.8271604938271605, 'precision': 0.8045977011494253, 'recall': 0.8641975308641975, 'f1': 0.8333333333333334, 'roc_auc': 0.8998628257887518, 'confusion_matrix': [[64, 17], [11, 70]], 'classification_report': {'0': {'precision': 0.8533333333333334, 'recall': 0.7901234567901234, 'f1-score': 0.8205128205128205, 'support': 81.0}, '1': {'precision': 0.8045977011494253, 'recall': 0.8641975308641975, 'f1-score': 0.8333333333333334, 'support': 81.0}, 'accuracy': 0.8271604938271605, 'macro avg': {'precision': 0.8289655172413793, 'recall': 0.8271604938271604, 'f1-score': 0.8269230769230769, 'support': 162.0}, 'weighted avg': {'precision': 0.8289655172413792, 'recall': 0.8271604938271605, 'f1-score': 0.8269230769230769, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.7284  prec=0.7126  recall=0.7654  f1=0.7381\n",
      "  roc_auc=0.7688\n",
      "  confusion_matrix: [[56, 25], [19, 62]]\n",
      "Predictions saved to: eval-VALSET/fgsm-fgsm-32-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/fgsm-fgsm-32-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.7283950617283951, 'precision': 0.7126436781609196, 'recall': 0.7654320987654321, 'f1': 0.7380952380952381, 'roc_auc': 0.7687852461515011, 'confusion_matrix': [[56, 25], [19, 62]], 'classification_report': {'0': {'precision': 0.7466666666666667, 'recall': 0.691358024691358, 'f1-score': 0.717948717948718, 'support': 81.0}, '1': {'precision': 0.7126436781609196, 'recall': 0.7654320987654321, 'f1-score': 0.7380952380952381, 'support': 81.0}, 'accuracy': 0.7283950617283951, 'macro avg': {'precision': 0.7296551724137932, 'recall': 0.728395061728395, 'f1-score': 0.7280219780219781, 'support': 162.0}, 'weighted avg': {'precision': 0.7296551724137932, 'recall': 0.7283950617283951, 'f1-score': 0.728021978021978, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: bim\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.8210  prec=0.7826  recall=0.8889  f1=0.8324\n",
      "  roc_auc=0.9116\n",
      "  confusion_matrix: [[61, 20], [9, 72]]\n",
      "Predictions saved to: eval-VALSET/bim-bim-32-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/bim-bim-32-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.8209876543209876, 'precision': 0.782608695652174, 'recall': 0.8888888888888888, 'f1': 0.8323699421965318, 'roc_auc': 0.9115988416399938, 'confusion_matrix': [[61, 20], [9, 72]], 'classification_report': {'0': {'precision': 0.8714285714285714, 'recall': 0.7530864197530864, 'f1-score': 0.8079470198675497, 'support': 81.0}, '1': {'precision': 0.782608695652174, 'recall': 0.8888888888888888, 'f1-score': 0.8323699421965318, 'support': 81.0}, 'accuracy': 0.8209876543209876, 'macro avg': {'precision': 0.8270186335403726, 'recall': 0.8209876543209876, 'f1-score': 0.8201584810320408, 'support': 162.0}, 'weighted avg': {'precision': 0.8270186335403727, 'recall': 0.8209876543209876, 'f1-score': 0.8201584810320407, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.7099  prec=0.7073  recall=0.7160  f1=0.7117\n",
      "  roc_auc=0.7907\n",
      "  confusion_matrix: [[57, 24], [23, 58]]\n",
      "Predictions saved to: eval-VALSET/bim-bim-32-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/bim-bim-32-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.7098765432098766, 'precision': 0.7073170731707317, 'recall': 0.7160493827160493, 'f1': 0.7116564417177914, 'roc_auc': 0.7907331199512269, 'confusion_matrix': [[57, 24], [23, 58]], 'classification_report': {'0': {'precision': 0.7125, 'recall': 0.7037037037037037, 'f1-score': 0.7080745341614907, 'support': 81.0}, '1': {'precision': 0.7073170731707317, 'recall': 0.7160493827160493, 'f1-score': 0.7116564417177914, 'support': 81.0}, 'accuracy': 0.7098765432098766, 'macro avg': {'precision': 0.7099085365853659, 'recall': 0.7098765432098766, 'f1-score': 0.7098654879396411, 'support': 162.0}, 'weighted avg': {'precision': 0.7099085365853658, 'recall': 0.7098765432098766, 'f1-score': 0.7098654879396411, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: pgd\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.8210  prec=0.7955  recall=0.8642  f1=0.8284\n",
      "  roc_auc=0.8938\n",
      "  confusion_matrix: [[63, 18], [11, 70]]\n",
      "Predictions saved to: eval-VALSET/pgd-pgd-32-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/pgd-pgd-32-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.8209876543209876, 'precision': 0.7954545454545454, 'recall': 0.8641975308641975, 'f1': 0.8284023668639053, 'roc_auc': 0.8937661941777167, 'confusion_matrix': [[63, 18], [11, 70]], 'classification_report': {'0': {'precision': 0.8513513513513513, 'recall': 0.7777777777777778, 'f1-score': 0.8129032258064516, 'support': 81.0}, '1': {'precision': 0.7954545454545454, 'recall': 0.8641975308641975, 'f1-score': 0.8284023668639053, 'support': 81.0}, 'accuracy': 0.8209876543209876, 'macro avg': {'precision': 0.8234029484029484, 'recall': 0.8209876543209876, 'f1-score': 0.8206527963351784, 'support': 162.0}, 'weighted avg': {'precision': 0.8234029484029483, 'recall': 0.8209876543209876, 'f1-score': 0.8206527963351784, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.6975  prec=0.7000  recall=0.6914  f1=0.6957\n",
      "  roc_auc=0.7661\n",
      "  confusion_matrix: [[57, 24], [25, 56]]\n",
      "Predictions saved to: eval-VALSET/pgd-pgd-32-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/pgd-pgd-32-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.6975308641975309, 'precision': 0.7, 'recall': 0.691358024691358, 'f1': 0.6956521739130435, 'roc_auc': 0.7661179698216736, 'confusion_matrix': [[57, 24], [25, 56]], 'classification_report': {'0': {'precision': 0.6951219512195121, 'recall': 0.7037037037037037, 'f1-score': 0.6993865030674846, 'support': 81.0}, '1': {'precision': 0.7, 'recall': 0.691358024691358, 'f1-score': 0.6956521739130435, 'support': 81.0}, 'accuracy': 0.6975308641975309, 'macro avg': {'precision': 0.697560975609756, 'recall': 0.6975308641975309, 'f1-score': 0.697519338490264, 'support': 162.0}, 'weighted avg': {'precision': 0.697560975609756, 'recall': 0.6975308641975309, 'f1-score': 0.697519338490264, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: df\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.5432  prec=0.5385  recall=0.6049  f1=0.5698\n",
      "  roc_auc=0.5348\n",
      "  confusion_matrix: [[39, 42], [32, 49]]\n",
      "Predictions saved to: eval-VALSET/df-df-32-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/df-df-32-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.5432098765432098, 'precision': 0.5384615384615384, 'recall': 0.6049382716049383, 'f1': 0.5697674418604651, 'roc_auc': 0.5348270080780368, 'confusion_matrix': [[39, 42], [32, 49]], 'classification_report': {'0': {'precision': 0.5492957746478874, 'recall': 0.48148148148148145, 'f1-score': 0.5131578947368421, 'support': 81.0}, '1': {'precision': 0.5384615384615384, 'recall': 0.6049382716049383, 'f1-score': 0.5697674418604651, 'support': 81.0}, 'accuracy': 0.5432098765432098, 'macro avg': {'precision': 0.5438786565547129, 'recall': 0.5432098765432098, 'f1-score': 0.5414626682986536, 'support': 162.0}, 'weighted avg': {'precision': 0.5438786565547129, 'recall': 0.5432098765432098, 'f1-score': 0.5414626682986536, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.4444  f1=0.4706\n",
      "  roc_auc=0.5407\n",
      "  confusion_matrix: [[45, 36], [45, 36]]\n",
      "Predictions saved to: eval-VALSET/df-df-32-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/df-df-32-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.5, 'precision': 0.5, 'recall': 0.4444444444444444, 'f1': 0.47058823529411764, 'roc_auc': 0.540695016003658, 'confusion_matrix': [[45, 36], [45, 36]], 'classification_report': {'0': {'precision': 0.5, 'recall': 0.5555555555555556, 'f1-score': 0.5263157894736842, 'support': 81.0}, '1': {'precision': 0.5, 'recall': 0.4444444444444444, 'f1-score': 0.47058823529411764, 'support': 81.0}, 'accuracy': 0.5, 'macro avg': {'precision': 0.5, 'recall': 0.5, 'f1-score': 0.4984520123839009, 'support': 162.0}, 'weighted avg': {'precision': 0.5, 'recall': 0.5, 'f1-score': 0.4984520123839009, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: cw\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.5247  prec=0.5213  recall=0.6049  f1=0.5600\n",
      "  roc_auc=0.5330\n",
      "  confusion_matrix: [[36, 45], [32, 49]]\n",
      "Predictions saved to: eval-VALSET/cw-cw-32-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/cw-cw-32-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.5246913580246914, 'precision': 0.5212765957446809, 'recall': 0.6049382716049383, 'f1': 0.56, 'roc_auc': 0.5329980185947265, 'confusion_matrix': [[36, 45], [32, 49]], 'classification_report': {'0': {'precision': 0.5294117647058824, 'recall': 0.4444444444444444, 'f1-score': 0.48322147651006714, 'support': 81.0}, '1': {'precision': 0.5212765957446809, 'recall': 0.6049382716049383, 'f1-score': 0.56, 'support': 81.0}, 'accuracy': 0.5246913580246914, 'macro avg': {'precision': 0.5253441802252816, 'recall': 0.5246913580246914, 'f1-score': 0.5216107382550336, 'support': 162.0}, 'weighted avg': {'precision': 0.5253441802252816, 'recall': 0.5246913580246914, 'f1-score': 0.5216107382550336, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.1s remaining:    0.7s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.5185  prec=0.5211  recall=0.4568  f1=0.4868\n",
      "  roc_auc=0.5448\n",
      "  confusion_matrix: [[47, 34], [44, 37]]\n",
      "Predictions saved to: eval-VALSET/cw-cw-32-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/cw-cw-32-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.5185185185185185, 'precision': 0.5211267605633803, 'recall': 0.4567901234567901, 'f1': 0.4868421052631579, 'roc_auc': 0.5448102423411065, 'confusion_matrix': [[47, 34], [44, 37]], 'classification_report': {'0': {'precision': 0.5164835164835165, 'recall': 0.5802469135802469, 'f1-score': 0.5465116279069767, 'support': 81.0}, '1': {'precision': 0.5211267605633803, 'recall': 0.4567901234567901, 'f1-score': 0.4868421052631579, 'support': 81.0}, 'accuracy': 0.5185185185185185, 'macro avg': {'precision': 0.5188051385234485, 'recall': 0.5185185185185185, 'f1-score': 0.5166768665850673, 'support': 162.0}, 'weighted avg': {'precision': 0.5188051385234483, 'recall': 0.5185185185185185, 'f1-score': 0.5166768665850673, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: fgsm\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.8333  prec=0.8649  recall=0.7901  f1=0.8258\n",
      "  roc_auc=0.9267\n",
      "  confusion_matrix: [[71, 10], [17, 64]]\n",
      "Predictions saved to: eval-VALSET/fgsm-fgsm-64-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/fgsm-fgsm-64-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.8333333333333334, 'precision': 0.8648648648648649, 'recall': 0.7901234567901234, 'f1': 0.8258064516129032, 'roc_auc': 0.9266880048773054, 'confusion_matrix': [[71, 10], [17, 64]], 'classification_report': {'0': {'precision': 0.8068181818181818, 'recall': 0.8765432098765432, 'f1-score': 0.8402366863905325, 'support': 81.0}, '1': {'precision': 0.8648648648648649, 'recall': 0.7901234567901234, 'f1-score': 0.8258064516129032, 'support': 81.0}, 'accuracy': 0.8333333333333334, 'macro avg': {'precision': 0.8358415233415233, 'recall': 0.8333333333333333, 'f1-score': 0.8330215690017179, 'support': 162.0}, 'weighted avg': {'precision': 0.8358415233415234, 'recall': 0.8333333333333334, 'f1-score': 0.833021569001718, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.7407  prec=0.7671  recall=0.6914  f1=0.7273\n",
      "  roc_auc=0.8522\n",
      "  confusion_matrix: [[64, 17], [25, 56]]\n",
      "Predictions saved to: eval-VALSET/fgsm-fgsm-64-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/fgsm-fgsm-64-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.7407407407407407, 'precision': 0.7671232876712328, 'recall': 0.691358024691358, 'f1': 0.7272727272727273, 'roc_auc': 0.8521566834324036, 'confusion_matrix': [[64, 17], [25, 56]], 'classification_report': {'0': {'precision': 0.7191011235955056, 'recall': 0.7901234567901234, 'f1-score': 0.7529411764705882, 'support': 81.0}, '1': {'precision': 0.7671232876712328, 'recall': 0.691358024691358, 'f1-score': 0.7272727272727273, 'support': 81.0}, 'accuracy': 0.7407407407407407, 'macro avg': {'precision': 0.7431122056333692, 'recall': 0.7407407407407407, 'f1-score': 0.7401069518716578, 'support': 162.0}, 'weighted avg': {'precision': 0.7431122056333692, 'recall': 0.7407407407407407, 'f1-score': 0.7401069518716578, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: bim\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.9383  prec=0.9176  recall=0.9630  f1=0.9398\n",
      "  roc_auc=0.9864\n",
      "  confusion_matrix: [[74, 7], [3, 78]]\n",
      "Predictions saved to: eval-VALSET/bim-bim-64-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/bim-bim-64-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.9382716049382716, 'precision': 0.9176470588235294, 'recall': 0.9629629629629629, 'f1': 0.9397590361445783, 'roc_auc': 0.9864349946654474, 'confusion_matrix': [[74, 7], [3, 78]], 'classification_report': {'0': {'precision': 0.961038961038961, 'recall': 0.9135802469135802, 'f1-score': 0.9367088607594937, 'support': 81.0}, '1': {'precision': 0.9176470588235294, 'recall': 0.9629629629629629, 'f1-score': 0.9397590361445783, 'support': 81.0}, 'accuracy': 0.9382716049382716, 'macro avg': {'precision': 0.9393430099312452, 'recall': 0.9382716049382716, 'f1-score': 0.938233948452036, 'support': 162.0}, 'weighted avg': {'precision': 0.9393430099312452, 'recall': 0.9382716049382716, 'f1-score': 0.938233948452036, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.9136  prec=0.8764  recall=0.9630  f1=0.9176\n",
      "  roc_auc=0.9790\n",
      "  confusion_matrix: [[70, 11], [3, 78]]\n",
      "Predictions saved to: eval-VALSET/bim-bim-64-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/bim-bim-64-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.9135802469135802, 'precision': 0.8764044943820225, 'recall': 0.9629629629629629, 'f1': 0.9176470588235294, 'roc_auc': 0.9790428288370675, 'confusion_matrix': [[70, 11], [3, 78]], 'classification_report': {'0': {'precision': 0.958904109589041, 'recall': 0.8641975308641975, 'f1-score': 0.9090909090909091, 'support': 81.0}, '1': {'precision': 0.8764044943820225, 'recall': 0.9629629629629629, 'f1-score': 0.9176470588235294, 'support': 81.0}, 'accuracy': 0.9135802469135802, 'macro avg': {'precision': 0.9176543019855318, 'recall': 0.9135802469135802, 'f1-score': 0.9133689839572192, 'support': 162.0}, 'weighted avg': {'precision': 0.9176543019855319, 'recall': 0.9135802469135802, 'f1-score': 0.9133689839572192, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: pgd\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.9383  prec=0.9176  recall=0.9630  f1=0.9398\n",
      "  roc_auc=0.9774\n",
      "  confusion_matrix: [[74, 7], [3, 78]]\n",
      "Predictions saved to: eval-VALSET/pgd-pgd-64-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/pgd-pgd-64-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.9382716049382716, 'precision': 0.9176470588235294, 'recall': 0.9629629629629629, 'f1': 0.9397590361445783, 'roc_auc': 0.9774424630391708, 'confusion_matrix': [[74, 7], [3, 78]], 'classification_report': {'0': {'precision': 0.961038961038961, 'recall': 0.9135802469135802, 'f1-score': 0.9367088607594937, 'support': 81.0}, '1': {'precision': 0.9176470588235294, 'recall': 0.9629629629629629, 'f1-score': 0.9397590361445783, 'support': 81.0}, 'accuracy': 0.9382716049382716, 'macro avg': {'precision': 0.9393430099312452, 'recall': 0.9382716049382716, 'f1-score': 0.938233948452036, 'support': 162.0}, 'weighted avg': {'precision': 0.9393430099312452, 'recall': 0.9382716049382716, 'f1-score': 0.938233948452036, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.9012  prec=0.8571  recall=0.9630  f1=0.9070\n",
      "  roc_auc=0.9809\n",
      "  confusion_matrix: [[68, 13], [3, 78]]\n",
      "Predictions saved to: eval-VALSET/pgd-pgd-64-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/pgd-pgd-64-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.9012345679012346, 'precision': 0.8571428571428571, 'recall': 0.9629629629629629, 'f1': 0.9069767441860465, 'roc_auc': 0.9809480262155159, 'confusion_matrix': [[68, 13], [3, 78]], 'classification_report': {'0': {'precision': 0.9577464788732394, 'recall': 0.8395061728395061, 'f1-score': 0.8947368421052632, 'support': 81.0}, '1': {'precision': 0.8571428571428571, 'recall': 0.9629629629629629, 'f1-score': 0.9069767441860465, 'support': 81.0}, 'accuracy': 0.9012345679012346, 'macro avg': {'precision': 0.9074446680080482, 'recall': 0.9012345679012346, 'f1-score': 0.9008567931456548, 'support': 162.0}, 'weighted avg': {'precision': 0.9074446680080481, 'recall': 0.9012345679012346, 'f1-score': 0.9008567931456548, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: df\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.5370  prec=0.5375  recall=0.5309  f1=0.5342\n",
      "  roc_auc=0.5813\n",
      "  confusion_matrix: [[44, 37], [38, 43]]\n",
      "Predictions saved to: eval-VALSET/df-df-64-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/df-df-64-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.5370370370370371, 'precision': 0.5375, 'recall': 0.5308641975308642, 'f1': 0.5341614906832298, 'roc_auc': 0.581313824112178, 'confusion_matrix': [[44, 37], [38, 43]], 'classification_report': {'0': {'precision': 0.5365853658536586, 'recall': 0.5432098765432098, 'f1-score': 0.5398773006134969, 'support': 81.0}, '1': {'precision': 0.5375, 'recall': 0.5308641975308642, 'f1-score': 0.5341614906832298, 'support': 81.0}, 'accuracy': 0.5370370370370371, 'macro avg': {'precision': 0.5370426829268293, 'recall': 0.537037037037037, 'f1-score': 0.5370193956483633, 'support': 162.0}, 'weighted avg': {'precision': 0.5370426829268292, 'recall': 0.5370370370370371, 'f1-score': 0.5370193956483633, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.5062  prec=0.5059  recall=0.5309  f1=0.5181\n",
      "  roc_auc=0.4893\n",
      "  confusion_matrix: [[39, 42], [38, 43]]\n",
      "Predictions saved to: eval-VALSET/df-df-64-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/df-df-64-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.5061728395061729, 'precision': 0.5058823529411764, 'recall': 0.5308641975308642, 'f1': 0.5180722891566265, 'roc_auc': 0.48925468678555095, 'confusion_matrix': [[39, 42], [38, 43]], 'classification_report': {'0': {'precision': 0.5064935064935064, 'recall': 0.48148148148148145, 'f1-score': 0.4936708860759494, 'support': 81.0}, '1': {'precision': 0.5058823529411764, 'recall': 0.5308641975308642, 'f1-score': 0.5180722891566265, 'support': 81.0}, 'accuracy': 0.5061728395061729, 'macro avg': {'precision': 0.5061879297173415, 'recall': 0.5061728395061729, 'f1-score': 0.5058715876162879, 'support': 162.0}, 'weighted avg': {'precision': 0.5061879297173414, 'recall': 0.5061728395061729, 'f1-score': 0.505871587616288, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: cw\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.5309  prec=0.5281  recall=0.5802  f1=0.5529\n",
      "  roc_auc=0.5853\n",
      "  confusion_matrix: [[39, 42], [34, 47]]\n",
      "Predictions saved to: eval-VALSET/cw-cw-64-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/cw-cw-64-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.5308641975308642, 'precision': 0.5280898876404494, 'recall': 0.5802469135802469, 'f1': 0.5529411764705883, 'roc_auc': 0.5852766346593506, 'confusion_matrix': [[39, 42], [34, 47]], 'classification_report': {'0': {'precision': 0.5342465753424658, 'recall': 0.48148148148148145, 'f1-score': 0.5064935064935064, 'support': 81.0}, '1': {'precision': 0.5280898876404494, 'recall': 0.5802469135802469, 'f1-score': 0.5529411764705883, 'support': 81.0}, 'accuracy': 0.5308641975308642, 'macro avg': {'precision': 0.5311682314914576, 'recall': 0.5308641975308642, 'f1-score': 0.5297173414820473, 'support': 162.0}, 'weighted avg': {'precision': 0.5311682314914576, 'recall': 0.5308641975308642, 'f1-score': 0.5297173414820473, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.5309  prec=0.5316  recall=0.5185  f1=0.5250\n",
      "  roc_auc=0.5297\n",
      "  confusion_matrix: [[44, 37], [39, 42]]\n",
      "Predictions saved to: eval-VALSET/cw-cw-64-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/cw-cw-64-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.5308641975308642, 'precision': 0.5316455696202531, 'recall': 0.5185185185185185, 'f1': 0.525, 'roc_auc': 0.5297210791037952, 'confusion_matrix': [[44, 37], [39, 42]], 'classification_report': {'0': {'precision': 0.5301204819277109, 'recall': 0.5432098765432098, 'f1-score': 0.5365853658536586, 'support': 81.0}, '1': {'precision': 0.5316455696202531, 'recall': 0.5185185185185185, 'f1-score': 0.525, 'support': 81.0}, 'accuracy': 0.5308641975308642, 'macro avg': {'precision': 0.530883025773982, 'recall': 0.5308641975308641, 'f1-score': 0.5307926829268292, 'support': 162.0}, 'weighted avg': {'precision': 0.530883025773982, 'recall': 0.5308641975308642, 'f1-score': 0.5307926829268294, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: fgsm\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.8704  prec=0.9054  recall=0.8272  f1=0.8645\n",
      "  roc_auc=0.9592\n",
      "  confusion_matrix: [[74, 7], [14, 67]]\n",
      "Predictions saved to: eval-VALSET/fgsm-fgsm-128-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/fgsm-fgsm-128-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.8703703703703703, 'precision': 0.9054054054054054, 'recall': 0.8271604938271605, 'f1': 0.864516129032258, 'roc_auc': 0.9591525682060662, 'confusion_matrix': [[74, 7], [14, 67]], 'classification_report': {'0': {'precision': 0.8409090909090909, 'recall': 0.9135802469135802, 'f1-score': 0.8757396449704142, 'support': 81.0}, '1': {'precision': 0.9054054054054054, 'recall': 0.8271604938271605, 'f1-score': 0.864516129032258, 'support': 81.0}, 'accuracy': 0.8703703703703703, 'macro avg': {'precision': 0.8731572481572482, 'recall': 0.8703703703703703, 'f1-score': 0.8701278870013361, 'support': 162.0}, 'weighted avg': {'precision': 0.873157248157248, 'recall': 0.8703703703703703, 'f1-score': 0.870127887001336, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.8951  prec=0.8721  recall=0.9259  f1=0.8982\n",
      "  roc_auc=0.9518\n",
      "  confusion_matrix: [[70, 11], [6, 75]]\n",
      "Predictions saved to: eval-VALSET/fgsm-fgsm-128-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/fgsm-fgsm-128-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.8950617283950617, 'precision': 0.872093023255814, 'recall': 0.9259259259259259, 'f1': 0.8982035928143712, 'roc_auc': 0.9518366102728242, 'confusion_matrix': [[70, 11], [6, 75]], 'classification_report': {'0': {'precision': 0.9210526315789473, 'recall': 0.8641975308641975, 'f1-score': 0.89171974522293, 'support': 81.0}, '1': {'precision': 0.872093023255814, 'recall': 0.9259259259259259, 'f1-score': 0.8982035928143712, 'support': 81.0}, 'accuracy': 0.8950617283950617, 'macro avg': {'precision': 0.8965728274173806, 'recall': 0.8950617283950617, 'f1-score': 0.8949616690186506, 'support': 162.0}, 'weighted avg': {'precision': 0.8965728274173806, 'recall': 0.8950617283950617, 'f1-score': 0.8949616690186505, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: bim\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.9568  prec=0.9512  recall=0.9630  f1=0.9571\n",
      "  roc_auc=0.9933\n",
      "  confusion_matrix: [[77, 4], [3, 78]]\n",
      "Predictions saved to: eval-VALSET/bim-bim-128-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/bim-bim-128-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.9567901234567902, 'precision': 0.9512195121951219, 'recall': 0.9629629629629629, 'f1': 0.9570552147239264, 'roc_auc': 0.9932937052278616, 'confusion_matrix': [[77, 4], [3, 78]], 'classification_report': {'0': {'precision': 0.9625, 'recall': 0.9506172839506173, 'f1-score': 0.9565217391304348, 'support': 81.0}, '1': {'precision': 0.9512195121951219, 'recall': 0.9629629629629629, 'f1-score': 0.9570552147239264, 'support': 81.0}, 'accuracy': 0.9567901234567902, 'macro avg': {'precision': 0.9568597560975609, 'recall': 0.9567901234567902, 'f1-score': 0.9567884769271806, 'support': 162.0}, 'weighted avg': {'precision': 0.9568597560975609, 'recall': 0.9567901234567902, 'f1-score': 0.9567884769271807, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.9568  prec=0.9625  recall=0.9506  f1=0.9565\n",
      "  roc_auc=0.9901\n",
      "  confusion_matrix: [[78, 3], [4, 77]]\n",
      "Predictions saved to: eval-VALSET/bim-bim-128-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/bim-bim-128-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.9567901234567902, 'precision': 0.9625, 'recall': 0.9506172839506173, 'f1': 0.9565217391304348, 'roc_auc': 0.9900929736320682, 'confusion_matrix': [[78, 3], [4, 77]], 'classification_report': {'0': {'precision': 0.9512195121951219, 'recall': 0.9629629629629629, 'f1-score': 0.9570552147239264, 'support': 81.0}, '1': {'precision': 0.9625, 'recall': 0.9506172839506173, 'f1-score': 0.9565217391304348, 'support': 81.0}, 'accuracy': 0.9567901234567902, 'macro avg': {'precision': 0.9568597560975609, 'recall': 0.9567901234567902, 'f1-score': 0.9567884769271806, 'support': 162.0}, 'weighted avg': {'precision': 0.9568597560975609, 'recall': 0.9567901234567902, 'f1-score': 0.9567884769271807, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: pgd\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.9753  prec=0.9753  recall=0.9753  f1=0.9753\n",
      "  roc_auc=0.9977\n",
      "  confusion_matrix: [[79, 2], [2, 79]]\n",
      "Predictions saved to: eval-VALSET/pgd-pgd-128-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/pgd-pgd-128-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.9753086419753086, 'precision': 0.9753086419753086, 'recall': 0.9753086419753086, 'f1': 0.9753086419753086, 'roc_auc': 0.9977137631458619, 'confusion_matrix': [[79, 2], [2, 79]], 'classification_report': {'0': {'precision': 0.9753086419753086, 'recall': 0.9753086419753086, 'f1-score': 0.9753086419753086, 'support': 81.0}, '1': {'precision': 0.9753086419753086, 'recall': 0.9753086419753086, 'f1-score': 0.9753086419753086, 'support': 81.0}, 'accuracy': 0.9753086419753086, 'macro avg': {'precision': 0.9753086419753086, 'recall': 0.9753086419753086, 'f1-score': 0.9753086419753086, 'support': 162.0}, 'weighted avg': {'precision': 0.9753086419753086, 'recall': 0.9753086419753086, 'f1-score': 0.9753086419753086, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.9630  prec=0.9747  recall=0.9506  f1=0.9625\n",
      "  roc_auc=0.9951\n",
      "  confusion_matrix: [[79, 2], [4, 77]]\n",
      "Predictions saved to: eval-VALSET/pgd-pgd-128-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/pgd-pgd-128-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.9629629629629629, 'precision': 0.9746835443037974, 'recall': 0.9506172839506173, 'f1': 0.9625, 'roc_auc': 0.9951226947111722, 'confusion_matrix': [[79, 2], [4, 77]], 'classification_report': {'0': {'precision': 0.9518072289156626, 'recall': 0.9753086419753086, 'f1-score': 0.9634146341463414, 'support': 81.0}, '1': {'precision': 0.9746835443037974, 'recall': 0.9506172839506173, 'f1-score': 0.9625, 'support': 81.0}, 'accuracy': 0.9629629629629629, 'macro avg': {'precision': 0.96324538660973, 'recall': 0.962962962962963, 'f1-score': 0.9629573170731707, 'support': 162.0}, 'weighted avg': {'precision': 0.96324538660973, 'recall': 0.9629629629629629, 'f1-score': 0.9629573170731708, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: df\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.6543  prec=0.6543  recall=0.6543  f1=0.6543\n",
      "  roc_auc=0.7011\n",
      "  confusion_matrix: [[53, 28], [28, 53]]\n",
      "Predictions saved to: eval-VALSET/df-df-128-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/df-df-128-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.654320987654321, 'precision': 0.654320987654321, 'recall': 0.654320987654321, 'f1': 0.654320987654321, 'roc_auc': 0.7011126352690138, 'confusion_matrix': [[53, 28], [28, 53]], 'classification_report': {'0': {'precision': 0.654320987654321, 'recall': 0.654320987654321, 'f1-score': 0.654320987654321, 'support': 81.0}, '1': {'precision': 0.654320987654321, 'recall': 0.654320987654321, 'f1-score': 0.654320987654321, 'support': 81.0}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.654320987654321, 'recall': 0.654320987654321, 'f1-score': 0.654320987654321, 'support': 162.0}, 'weighted avg': {'precision': 0.654320987654321, 'recall': 0.654320987654321, 'f1-score': 0.654320987654321, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.6296  prec=0.6364  recall=0.6049  f1=0.6203\n",
      "  roc_auc=0.6586\n",
      "  confusion_matrix: [[53, 28], [32, 49]]\n",
      "Predictions saved to: eval-VALSET/df-df-128-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/df-df-128-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.6296296296296297, 'precision': 0.6363636363636364, 'recall': 0.6049382716049383, 'f1': 0.620253164556962, 'roc_auc': 0.6585886297820454, 'confusion_matrix': [[53, 28], [32, 49]], 'classification_report': {'0': {'precision': 0.6235294117647059, 'recall': 0.654320987654321, 'f1-score': 0.6385542168674698, 'support': 81.0}, '1': {'precision': 0.6363636363636364, 'recall': 0.6049382716049383, 'f1-score': 0.620253164556962, 'support': 81.0}, 'accuracy': 0.6296296296296297, 'macro avg': {'precision': 0.6299465240641711, 'recall': 0.6296296296296297, 'f1-score': 0.6294036907122159, 'support': 162.0}, 'weighted avg': {'precision': 0.6299465240641712, 'recall': 0.6296296296296297, 'f1-score': 0.6294036907122159, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: cw\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.6481  prec=0.6333  recall=0.7037  f1=0.6667\n",
      "  roc_auc=0.7142\n",
      "  confusion_matrix: [[48, 33], [24, 57]]\n",
      "Predictions saved to: eval-VALSET/cw-cw-128-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/cw-cw-128-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.6481481481481481, 'precision': 0.6333333333333333, 'recall': 0.7037037037037037, 'f1': 0.6666666666666666, 'roc_auc': 0.7142203932327389, 'confusion_matrix': [[48, 33], [24, 57]], 'classification_report': {'0': {'precision': 0.6666666666666666, 'recall': 0.5925925925925926, 'f1-score': 0.6274509803921569, 'support': 81.0}, '1': {'precision': 0.6333333333333333, 'recall': 0.7037037037037037, 'f1-score': 0.6666666666666666, 'support': 81.0}, 'accuracy': 0.6481481481481481, 'macro avg': {'precision': 0.6499999999999999, 'recall': 0.6481481481481481, 'f1-score': 0.6470588235294117, 'support': 162.0}, 'weighted avg': {'precision': 0.65, 'recall': 0.6481481481481481, 'f1-score': 0.6470588235294117, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.5926  prec=0.5882  recall=0.6173  f1=0.6024\n",
      "  roc_auc=0.6251\n",
      "  confusion_matrix: [[46, 35], [31, 50]]\n",
      "Predictions saved to: eval-VALSET/cw-cw-128-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/cw-cw-128-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.5925925925925926, 'precision': 0.5882352941176471, 'recall': 0.6172839506172839, 'f1': 0.6024096385542169, 'roc_auc': 0.6251333638164914, 'confusion_matrix': [[46, 35], [31, 50]], 'classification_report': {'0': {'precision': 0.5974025974025974, 'recall': 0.5679012345679012, 'f1-score': 0.5822784810126582, 'support': 81.0}, '1': {'precision': 0.5882352941176471, 'recall': 0.6172839506172839, 'f1-score': 0.6024096385542169, 'support': 81.0}, 'accuracy': 0.5925925925925926, 'macro avg': {'precision': 0.5928189457601223, 'recall': 0.5925925925925926, 'f1-score': 0.5923440597834375, 'support': 162.0}, 'weighted avg': {'precision': 0.5928189457601223, 'recall': 0.5925925925925926, 'f1-score': 0.5923440597834376, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZES = [32, 64, 128]\n",
    "ATTACKS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n",
    "classifiers = ['LogisticRegression', 'RandomForest']\n",
    "for IMG_SIZE in IMG_SIZES:\n",
    "    for ATTACK in ATTACKS:\n",
    "        print (f'Attack Method: {ATTACK}\\n')\n",
    "        for classifier in classifiers:\n",
    "            print (f'\\n Classifier: {classifier}: \\n')\n",
    "            val_res = eval_val_from_npy(\n",
    "                 val_npy_path = f\"/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/val_raw.npy\",\n",
    "                 val_label_path = f\"/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/val_labels.npy\",\n",
    "                 model_out_dir = f\"/kaggle/working/models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                 return_predictions=True,\n",
    "                 use_mmap=False,\n",
    "                 csv_path=f\"./eval-VALSET/{ATTACK}-{ATTACK}-{IMG_SIZE}-{classifier}_test_result.csv\"\n",
    "            )\n",
    "            print(\"val metrics:\", val_res[\"metrics\"])\n",
    "        print ('_____________________\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T20:09:32.714514Z",
     "iopub.status.busy": "2025-10-18T20:09:32.714330Z",
     "iopub.status.idle": "2025-10-18T20:10:24.598859Z",
     "shell.execute_reply": "2025-10-18T20:10:24.597767Z",
     "shell.execute_reply.started": "2025-10-18T20:09:32.714499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating zip: /kaggle/working/models.zip\n",
      "  adding: cw-32-LogisticRegression/train_meta.json\n",
      "  adding: cw-32-LogisticRegression/clf.joblib\n",
      "  adding: cw-32-LogisticRegression/pipeline.joblib\n",
      "  adding: cw-32-LogisticRegression/scaler.joblib\n",
      "  adding: df-64-LogisticRegression/train_meta.json\n",
      "  adding: df-64-LogisticRegression/clf.joblib\n",
      "  adding: df-64-LogisticRegression/pipeline.joblib\n",
      "  adding: df-64-LogisticRegression/scaler.joblib\n",
      "  adding: bim-128-RandomForest/train_meta.json\n",
      "  adding: bim-128-RandomForest/clf.joblib\n",
      "  adding: bim-128-RandomForest/pipeline.joblib\n",
      "  adding: bim-128-RandomForest/scaler.joblib\n",
      "  adding: fgsm-32-LogisticRegression/train_meta.json\n",
      "  adding: fgsm-32-LogisticRegression/clf.joblib\n",
      "  adding: fgsm-32-LogisticRegression/pipeline.joblib\n",
      "  adding: fgsm-32-LogisticRegression/scaler.joblib\n",
      "  adding: bim-64-RandomForest/train_meta.json\n",
      "  adding: bim-64-RandomForest/clf.joblib\n",
      "  adding: bim-64-RandomForest/pipeline.joblib\n",
      "  adding: bim-64-RandomForest/scaler.joblib\n",
      "  adding: cw-128-RandomForest/train_meta.json\n",
      "  adding: cw-128-RandomForest/clf.joblib\n",
      "  adding: cw-128-RandomForest/pipeline.joblib\n",
      "  adding: cw-128-RandomForest/scaler.joblib\n",
      "  adding: fgsm-128-RandomForest/train_meta.json\n",
      "  adding: fgsm-128-RandomForest/clf.joblib\n",
      "  adding: fgsm-128-RandomForest/pipeline.joblib\n",
      "  adding: fgsm-128-RandomForest/scaler.joblib\n",
      "  adding: pgd-32-RandomForest/train_meta.json\n",
      "  adding: pgd-32-RandomForest/clf.joblib\n",
      "  adding: pgd-32-RandomForest/pipeline.joblib\n",
      "  adding: pgd-32-RandomForest/scaler.joblib\n",
      "  adding: cw-64-RandomForest/train_meta.json\n",
      "  adding: cw-64-RandomForest/clf.joblib\n",
      "  adding: cw-64-RandomForest/pipeline.joblib\n",
      "  adding: cw-64-RandomForest/scaler.joblib\n",
      "  adding: fgsm-128-LogisticRegression/train_meta.json\n",
      "  adding: fgsm-128-LogisticRegression/clf.joblib\n",
      "  adding: fgsm-128-LogisticRegression/pipeline.joblib\n",
      "  adding: fgsm-128-LogisticRegression/scaler.joblib\n",
      "  adding: pgd-32-LogisticRegression/train_meta.json\n",
      "  adding: pgd-32-LogisticRegression/clf.joblib\n",
      "  adding: pgd-32-LogisticRegression/pipeline.joblib\n",
      "  adding: pgd-32-LogisticRegression/scaler.joblib\n",
      "  adding: pgd-64-RandomForest/train_meta.json\n",
      "  adding: pgd-64-RandomForest/clf.joblib\n",
      "  adding: pgd-64-RandomForest/pipeline.joblib\n",
      "  adding: pgd-64-RandomForest/scaler.joblib\n",
      "  adding: pgd-64-LogisticRegression/train_meta.json\n",
      "  adding: pgd-64-LogisticRegression/clf.joblib\n",
      "  adding: pgd-64-LogisticRegression/pipeline.joblib\n",
      "  adding: pgd-64-LogisticRegression/scaler.joblib\n",
      "  adding: fgsm-64-LogisticRegression/train_meta.json\n",
      "  adding: fgsm-64-LogisticRegression/clf.joblib\n",
      "  adding: fgsm-64-LogisticRegression/pipeline.joblib\n",
      "  adding: fgsm-64-LogisticRegression/scaler.joblib\n",
      "  adding: df-64-RandomForest/train_meta.json\n",
      "  adding: df-64-RandomForest/clf.joblib\n",
      "  adding: df-64-RandomForest/pipeline.joblib\n",
      "  adding: df-64-RandomForest/scaler.joblib\n",
      "  adding: df-128-RandomForest/train_meta.json\n",
      "  adding: df-128-RandomForest/clf.joblib\n",
      "  adding: df-128-RandomForest/pipeline.joblib\n",
      "  adding: df-128-RandomForest/scaler.joblib\n",
      "  adding: fgsm-32-RandomForest/train_meta.json\n",
      "  adding: fgsm-32-RandomForest/clf.joblib\n",
      "  adding: fgsm-32-RandomForest/pipeline.joblib\n",
      "  adding: fgsm-32-RandomForest/scaler.joblib\n",
      "  adding: df-32-LogisticRegression/train_meta.json\n",
      "  adding: df-32-LogisticRegression/clf.joblib\n",
      "  adding: df-32-LogisticRegression/pipeline.joblib\n",
      "  adding: df-32-LogisticRegression/scaler.joblib\n",
      "  adding: df-128-LogisticRegression/train_meta.json\n",
      "  adding: df-128-LogisticRegression/clf.joblib\n",
      "  adding: df-128-LogisticRegression/pipeline.joblib\n",
      "  adding: df-128-LogisticRegression/scaler.joblib\n",
      "  adding: bim-128-LogisticRegression/train_meta.json\n",
      "  adding: bim-128-LogisticRegression/clf.joblib\n",
      "  adding: bim-128-LogisticRegression/pipeline.joblib\n",
      "  adding: bim-128-LogisticRegression/scaler.joblib\n",
      "  adding: bim-32-RandomForest/train_meta.json\n",
      "  adding: bim-32-RandomForest/clf.joblib\n",
      "  adding: bim-32-RandomForest/pipeline.joblib\n",
      "  adding: bim-32-RandomForest/scaler.joblib\n",
      "  adding: bim-32-LogisticRegression/train_meta.json\n",
      "  adding: bim-32-LogisticRegression/clf.joblib\n",
      "  adding: bim-32-LogisticRegression/pipeline.joblib\n",
      "  adding: bim-32-LogisticRegression/scaler.joblib\n",
      "  adding: bim-64-LogisticRegression/train_meta.json\n",
      "  adding: bim-64-LogisticRegression/clf.joblib\n",
      "  adding: bim-64-LogisticRegression/pipeline.joblib\n",
      "  adding: bim-64-LogisticRegression/scaler.joblib\n",
      "  adding: df-32-RandomForest/train_meta.json\n",
      "  adding: df-32-RandomForest/clf.joblib\n",
      "  adding: df-32-RandomForest/pipeline.joblib\n",
      "  adding: df-32-RandomForest/scaler.joblib\n",
      "  adding: pgd-128-LogisticRegression/train_meta.json\n",
      "  adding: pgd-128-LogisticRegression/clf.joblib\n",
      "  adding: pgd-128-LogisticRegression/pipeline.joblib\n",
      "  adding: pgd-128-LogisticRegression/scaler.joblib\n",
      "  adding: pgd-128-RandomForest/train_meta.json\n",
      "  adding: pgd-128-RandomForest/clf.joblib\n",
      "  adding: pgd-128-RandomForest/pipeline.joblib\n",
      "  adding: pgd-128-RandomForest/scaler.joblib\n",
      "  adding: fgsm-64-RandomForest/train_meta.json\n",
      "  adding: fgsm-64-RandomForest/clf.joblib\n",
      "  adding: fgsm-64-RandomForest/pipeline.joblib\n",
      "  adding: fgsm-64-RandomForest/scaler.joblib\n",
      "  adding: cw-32-RandomForest/train_meta.json\n",
      "  adding: cw-32-RandomForest/clf.joblib\n",
      "  adding: cw-32-RandomForest/pipeline.joblib\n",
      "  adding: cw-32-RandomForest/scaler.joblib\n",
      "  adding: cw-128-LogisticRegression/train_meta.json\n",
      "  adding: cw-128-LogisticRegression/clf.joblib\n",
      "  adding: cw-128-LogisticRegression/pipeline.joblib\n",
      "  adding: cw-128-LogisticRegression/scaler.joblib\n",
      "  adding: cw-64-LogisticRegression/train_meta.json\n",
      "  adding: cw-64-LogisticRegression/clf.joblib\n",
      "  adding: cw-64-LogisticRegression/pipeline.joblib\n",
      "  adding: cw-64-LogisticRegression/scaler.joblib\n",
      "Computing per-file SHA-256 and writing manifest: /kaggle/working/manifest-sha256.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10/3618908250.py:60: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  mf.write(f\"# manifest generated: {datetime.utcnow().isoformat()}Z\\n\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Created: /kaggle/working/models.zip\n",
      "Created: /kaggle/working/manifest-sha256.txt\n",
      "Created: /kaggle/working/models.zip.sha256\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------------\n",
    "# Config\n",
    "# -------------------------------\n",
    "input_dir = Path(\"/kaggle/working/models\")\n",
    "output_zip = Path(\"/kaggle/working/models.zip\")\n",
    "manifest_path = Path(\"/kaggle/working/manifest-sha256.txt\")\n",
    "chunk_size = 8 * 1024 * 1024  # 8 MB\n",
    "skip_files = {output_zip.name, manifest_path.name}\n",
    "\n",
    "# -------------------------------\n",
    "# Helper: compute SHA256\n",
    "# -------------------------------\n",
    "def sha256_of_file(path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with path.open(\"rb\") as f:\n",
    "        while True:\n",
    "            chunk = f.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "# -------------------------------\n",
    "# Collect files to zip\n",
    "# -------------------------------\n",
    "files_to_add = []\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for fname in files:\n",
    "        full = Path(root) / fname\n",
    "        rel = full.relative_to(input_dir)\n",
    "        rel_str = str(rel).replace(os.sep, \"/\")\n",
    "        if rel.name in skip_files:\n",
    "            continue\n",
    "        files_to_add.append((full, rel))\n",
    "\n",
    "if not files_to_add:\n",
    "    print(f\"No files found in {input_dir} to archive.\")\n",
    "else:\n",
    "    # -------------------------------\n",
    "    # Create zip\n",
    "    # -------------------------------\n",
    "    print(f\"Creating zip: {output_zip}\")\n",
    "    with zipfile.ZipFile(output_zip, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        for full, rel in files_to_add:\n",
    "            arcname = str(rel).replace(os.sep, \"/\")\n",
    "            print(f\"  adding: {arcname}\")\n",
    "            zf.write(full, arcname=arcname)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Create manifest\n",
    "    # -------------------------------\n",
    "    print(f\"Computing per-file SHA-256 and writing manifest: {manifest_path}\")\n",
    "    with manifest_path.open(\"w\", encoding=\"utf-8\") as mf:\n",
    "        mf.write(f\"# manifest generated: {datetime.utcnow().isoformat()}Z\\n\")\n",
    "        mf.write(f\"# input_dir: {input_dir}\\n\")\n",
    "        mf.write(\"# format: <sha256>  <relative/path>\\n\")\n",
    "        for full, rel in files_to_add:\n",
    "            rel_unix = str(rel).replace(os.sep, \"/\")\n",
    "            h = sha256_of_file(full)\n",
    "            size = full.stat().st_size\n",
    "            mf.write(f\"{h}  {rel_unix}  # {size} bytes\\n\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Compute zip SHA256\n",
    "    # -------------------------------\n",
    "    zip_hash = sha256_of_file(output_zip)\n",
    "    ziphash_path = output_zip.with_suffix(output_zip.suffix + \".sha256\")\n",
    "    with ziphash_path.open(\"w\", encoding=\"utf-8\") as zh:\n",
    "        zh.write(f\"{zip_hash}  {output_zip.name}\\n\")\n",
    "\n",
    "    print(\"Done.\")\n",
    "    print(f\"Created: {output_zip}\")\n",
    "    print(f\"Created: {manifest_path}\")\n",
    "    print(f\"Created: {ziphash_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T18:46:45.632399Z",
     "iopub.status.busy": "2025-10-20T18:46:45.632065Z",
     "iopub.status.idle": "2025-10-20T18:48:51.409532Z",
     "shell.execute_reply": "2025-10-20T18:48:51.407755Z",
     "shell.execute_reply.started": "2025-10-20T18:46:45.632380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.7744  prec=0.7528  recall=0.8171  f1=0.7836\n",
      "  roc_auc=0.8679\n",
      "Metrics saved to: eval/fgsm-fgsm-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.7073  prec=0.6889  recall=0.7561  f1=0.7209\n",
      "  roc_auc=0.7950\n",
      "Metrics saved to: eval/fgsm-fgsm-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5427  prec=0.5686  recall=0.3537  f1=0.4361\n",
      "  roc_auc=0.6792\n",
      "Metrics saved to: eval/fgsm-bim-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5427  prec=0.5556  recall=0.4268  f1=0.4828\n",
      "  roc_auc=0.5927\n",
      "Metrics saved to: eval/fgsm-bim-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5610  prec=0.5926  recall=0.3902  f1=0.4706\n",
      "  roc_auc=0.6557\n",
      "Metrics saved to: eval/fgsm-pgd-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5854  prec=0.6000  recall=0.5122  f1=0.5526\n",
      "  roc_auc=0.6191\n",
      "Metrics saved to: eval/fgsm-pgd-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5061  prec=0.5111  recall=0.2805  f1=0.3622\n",
      "  roc_auc=0.5171\n",
      "Metrics saved to: eval/fgsm-df-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5061  prec=0.5088  recall=0.3537  f1=0.4173\n",
      "  roc_auc=0.4990\n",
      "Metrics saved to: eval/fgsm-df-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.4762  recall=0.2439  f1=0.3226\n",
      "  roc_auc=0.5097\n",
      "Metrics saved to: eval/fgsm-cw-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5061  prec=0.5088  recall=0.3537  f1=0.4173\n",
      "  roc_auc=0.5033\n",
      "Metrics saved to: eval/fgsm-cw-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.6707  prec=0.8889  recall=0.3902  f1=0.5424\n",
      "  roc_auc=0.8229\n",
      "Metrics saved to: eval/bim-fgsm-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6037  prec=0.7179  recall=0.3415  f1=0.4628\n",
      "  roc_auc=0.6858\n",
      "Metrics saved to: eval/bim-fgsm-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.8537  prec=0.9394  recall=0.7561  f1=0.8378\n",
      "  roc_auc=0.9420\n",
      "Metrics saved to: eval/bim-bim-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.7256  prec=0.8136  recall=0.5854  f1=0.6809\n",
      "  roc_auc=0.8035\n",
      "Metrics saved to: eval/bim-bim-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.7988  prec=0.9298  recall=0.6463  f1=0.7626\n",
      "  roc_auc=0.9087\n",
      "Metrics saved to: eval/bim-pgd-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.7195  prec=0.8103  recall=0.5732  f1=0.6714\n",
      "  roc_auc=0.7925\n",
      "Metrics saved to: eval/bim-pgd-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5122  prec=0.6000  recall=0.0732  f1=0.1304\n",
      "  roc_auc=0.4833\n",
      "Metrics saved to: eval/bim-df-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5061  prec=0.5217  recall=0.1463  f1=0.2286\n",
      "  roc_auc=0.5021\n",
      "Metrics saved to: eval/bim-df-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5122  prec=0.6000  recall=0.0732  f1=0.1304\n",
      "  roc_auc=0.4946\n",
      "Metrics saved to: eval/bim-cw-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.1s remaining:    0.9s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5061  prec=0.5217  recall=0.1463  f1=0.2286\n",
      "  roc_auc=0.4873\n",
      "Metrics saved to: eval/bim-cw-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6829  prec=0.7679  recall=0.5244  f1=0.6232\n",
      "  roc_auc=0.8205\n",
      "Metrics saved to: eval/pgd-fgsm-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.6280  prec=0.7143  recall=0.4268  f1=0.5344\n",
      "  roc_auc=0.6897\n",
      "Metrics saved to: eval/pgd-fgsm-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.8415  prec=0.8415  recall=0.8415  f1=0.8415\n",
      "  roc_auc=0.9350\n",
      "Metrics saved to: eval/pgd-bim-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.7622  prec=0.8028  recall=0.6951  f1=0.7451\n",
      "  roc_auc=0.8348\n",
      "Metrics saved to: eval/pgd-bim-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.7866  prec=0.8219  recall=0.7317  f1=0.7742\n",
      "  roc_auc=0.8969\n",
      "Metrics saved to: eval/pgd-pgd-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.7500  prec=0.7971  recall=0.6707  f1=0.7285\n",
      "  roc_auc=0.8030\n",
      "Metrics saved to: eval/pgd-pgd-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4939  prec=0.4800  recall=0.1463  f1=0.2243\n",
      "  roc_auc=0.4845\n",
      "Metrics saved to: eval/pgd-df-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5366  prec=0.5882  recall=0.2439  f1=0.3448\n",
      "  roc_auc=0.5225\n",
      "Metrics saved to: eval/pgd-df-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.1585  f1=0.2407\n",
      "  roc_auc=0.4918\n",
      "Metrics saved to: eval/pgd-cw-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5305  prec=0.5758  recall=0.2317  f1=0.3304\n",
      "  roc_auc=0.5385\n",
      "Metrics saved to: eval/pgd-cw-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5427  prec=0.5412  recall=0.5610  f1=0.5509\n",
      "  roc_auc=0.5640\n",
      "Metrics saved to: eval/df-fgsm-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5427  prec=0.5432  recall=0.5366  f1=0.5399\n",
      "  roc_auc=0.5609\n",
      "Metrics saved to: eval/df-fgsm-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4390  prec=0.4265  recall=0.3537  f1=0.3867\n",
      "  roc_auc=0.3932\n",
      "Metrics saved to: eval/df-bim-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5244  prec=0.5256  recall=0.5000  f1=0.5125\n",
      "  roc_auc=0.5255\n",
      "Metrics saved to: eval/df-bim-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4573  prec=0.4507  recall=0.3902  f1=0.4183\n",
      "  roc_auc=0.4087\n",
      "Metrics saved to: eval/df-pgd-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5549  prec=0.5542  recall=0.5610  f1=0.5576\n",
      "  roc_auc=0.5544\n",
      "Metrics saved to: eval/df-pgd-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5427  prec=0.5412  recall=0.5610  f1=0.5509\n",
      "  roc_auc=0.5294\n",
      "Metrics saved to: eval/df-df-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5183  prec=0.5195  recall=0.4878  f1=0.5031\n",
      "  roc_auc=0.5027\n",
      "Metrics saved to: eval/df-df-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5305  prec=0.5301  recall=0.5366  f1=0.5333\n",
      "  roc_auc=0.5123\n",
      "Metrics saved to: eval/df-cw-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.4861  recall=0.4268  f1=0.4545\n",
      "  roc_auc=0.4942\n",
      "Metrics saved to: eval/df-cw-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5671  prec=0.5556  recall=0.6707  f1=0.6077\n",
      "  roc_auc=0.6169\n",
      "Metrics saved to: eval/cw-fgsm-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4512  prec=0.4524  recall=0.4634  f1=0.4578\n",
      "  roc_auc=0.4813\n",
      "Metrics saved to: eval/cw-fgsm-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4146  prec=0.4054  recall=0.3659  f1=0.3846\n",
      "  roc_auc=0.4209\n",
      "Metrics saved to: eval/cw-bim-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4695  prec=0.4713  recall=0.5000  f1=0.4852\n",
      "  roc_auc=0.4642\n",
      "Metrics saved to: eval/cw-bim-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4573  prec=0.4568  recall=0.4512  f1=0.4540\n",
      "  roc_auc=0.4285\n",
      "Metrics saved to: eval/cw-pgd-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4146  prec=0.4103  recall=0.3902  f1=0.4000\n",
      "  roc_auc=0.4174\n",
      "Metrics saved to: eval/cw-pgd-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.5366  f1=0.5176\n",
      "  roc_auc=0.5272\n",
      "Metrics saved to: eval/cw-df-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4939  prec=0.4945  recall=0.5488  f1=0.5202\n",
      "  roc_auc=0.5122\n",
      "Metrics saved to: eval/cw-df-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.5366  f1=0.5176\n",
      "  roc_auc=0.5021\n",
      "Metrics saved to: eval/cw-cw-32-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4939  prec=0.4945  recall=0.5488  f1=0.5202\n",
      "  roc_auc=0.4858\n",
      "Metrics saved to: eval/cw-cw-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.8354  prec=0.8313  recall=0.8415  f1=0.8364\n",
      "  roc_auc=0.9172\n",
      "Metrics saved to: eval/fgsm-fgsm-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.7073  prec=0.7237  recall=0.6707  f1=0.6962\n",
      "  roc_auc=0.7973\n",
      "Metrics saved to: eval/fgsm-fgsm-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6098  prec=0.6957  recall=0.3902  f1=0.5000\n",
      "  roc_auc=0.7295\n",
      "Metrics saved to: eval/fgsm-bim-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5671  prec=0.6038  recall=0.3902  f1=0.4741\n",
      "  roc_auc=0.6080\n",
      "Metrics saved to: eval/fgsm-bim-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5793  prec=0.6585  recall=0.3293  f1=0.4390\n",
      "  roc_auc=0.7223\n",
      "Metrics saved to: eval/fgsm-pgd-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5915  prec=0.6316  recall=0.4390  f1=0.5180\n",
      "  roc_auc=0.6469\n",
      "Metrics saved to: eval/fgsm-pgd-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.1707  f1=0.2545\n",
      "  roc_auc=0.5109\n",
      "Metrics saved to: eval/fgsm-df-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4939  prec=0.4878  recall=0.2439  f1=0.3252\n",
      "  roc_auc=0.5090\n",
      "Metrics saved to: eval/fgsm-df-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.1707  f1=0.2545\n",
      "  roc_auc=0.5132\n",
      "Metrics saved to: eval/fgsm-cw-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.2561  f1=0.3387\n",
      "  roc_auc=0.5065\n",
      "Metrics saved to: eval/fgsm-cw-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5976  prec=0.8636  recall=0.2317  f1=0.3654\n",
      "  roc_auc=0.7078\n",
      "Metrics saved to: eval/bim-fgsm-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5244  prec=0.6000  recall=0.1463  f1=0.2353\n",
      "  roc_auc=0.5590\n",
      "Metrics saved to: eval/bim-fgsm-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9573  prec=0.9630  recall=0.9512  f1=0.9571\n",
      "  roc_auc=0.9929\n",
      "Metrics saved to: eval/bim-bim-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9268  prec=0.9070  recall=0.9512  f1=0.9286\n",
      "  roc_auc=0.9813\n",
      "Metrics saved to: eval/bim-bim-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9512  prec=0.9625  recall=0.9390  f1=0.9506\n",
      "  roc_auc=0.9921\n",
      "Metrics saved to: eval/bim-pgd-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9268  prec=0.9070  recall=0.9512  f1=0.9286\n",
      "  roc_auc=0.9836\n",
      "Metrics saved to: eval/bim-pgd-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.2500  recall=0.0122  f1=0.0233\n",
      "  roc_auc=0.4393\n",
      "Metrics saved to: eval/bim-df-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4817  prec=0.3846  recall=0.0610  f1=0.1053\n",
      "  roc_auc=0.4575\n",
      "Metrics saved to: eval/bim-df-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.2500  recall=0.0122  f1=0.0233\n",
      "  roc_auc=0.4691\n",
      "Metrics saved to: eval/bim-cw-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4817  prec=0.3846  recall=0.0610  f1=0.1053\n",
      "  roc_auc=0.4726\n",
      "Metrics saved to: eval/bim-cw-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5854  prec=0.8500  recall=0.2073  f1=0.3333\n",
      "  roc_auc=0.7091\n",
      "Metrics saved to: eval/pgd-fgsm-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5122  prec=0.5556  recall=0.1220  f1=0.2000\n",
      "  roc_auc=0.5793\n",
      "Metrics saved to: eval/pgd-fgsm-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9634  prec=0.9634  recall=0.9634  f1=0.9634\n",
      "  roc_auc=0.9933\n",
      "Metrics saved to: eval/pgd-bim-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9390  prec=0.9091  recall=0.9756  f1=0.9412\n",
      "  roc_auc=0.9763\n",
      "Metrics saved to: eval/pgd-bim-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9573  prec=0.9630  recall=0.9512  f1=0.9571\n",
      "  roc_auc=0.9942\n",
      "Metrics saved to: eval/pgd-pgd-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9268  prec=0.9070  recall=0.9512  f1=0.9286\n",
      "  roc_auc=0.9770\n",
      "Metrics saved to: eval/pgd-pgd-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4817  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.4368\n",
      "Metrics saved to: eval/pgd-df-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4756  prec=0.3333  recall=0.0488  f1=0.0851\n",
      "  roc_auc=0.4322\n",
      "Metrics saved to: eval/pgd-df-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4817  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.4655\n",
      "Metrics saved to: eval/pgd-cw-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4817  prec=0.3846  recall=0.0610  f1=0.1053\n",
      "  roc_auc=0.4647\n",
      "Metrics saved to: eval/pgd-cw-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5976  prec=0.5930  recall=0.6220  f1=0.6071\n",
      "  roc_auc=0.6286\n",
      "Metrics saved to: eval/df-fgsm-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.4390  f1=0.4675\n",
      "  roc_auc=0.5029\n",
      "Metrics saved to: eval/df-fgsm-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.3110  prec=0.1026  recall=0.0488  f1=0.0661\n",
      "  roc_auc=0.1095\n",
      "Metrics saved to: eval/df-bim-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4512  prec=0.4375  recall=0.3415  f1=0.3836\n",
      "  roc_auc=0.4282\n",
      "Metrics saved to: eval/df-bim-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.2927  prec=0.0278  recall=0.0122  f1=0.0169\n",
      "  roc_auc=0.0952\n",
      "Metrics saved to: eval/df-pgd-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4695  prec=0.4627  recall=0.3780  f1=0.4161\n",
      "  roc_auc=0.4470\n",
      "Metrics saved to: eval/df-pgd-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5671  prec=0.5679  recall=0.5610  f1=0.5644\n",
      "  roc_auc=0.6014\n",
      "Metrics saved to: eval/df-df-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5366  prec=0.5385  recall=0.5122  f1=0.5250\n",
      "  roc_auc=0.5389\n",
      "Metrics saved to: eval/df-df-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5244  prec=0.5270  recall=0.4756  f1=0.5000\n",
      "  roc_auc=0.5690\n",
      "Metrics saved to: eval/df-cw-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.1s remaining:    0.9s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5122  prec=0.5135  recall=0.4634  f1=0.4872\n",
      "  roc_auc=0.5390\n",
      "Metrics saved to: eval/df-cw-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6159  prec=0.5905  recall=0.7561  f1=0.6631\n",
      "  roc_auc=0.6972\n",
      "Metrics saved to: eval/cw-fgsm-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5061  prec=0.5068  recall=0.4512  f1=0.4774\n",
      "  roc_auc=0.5643\n",
      "Metrics saved to: eval/cw-fgsm-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.3171  prec=0.2321  recall=0.1585  f1=0.1884\n",
      "  roc_auc=0.1968\n",
      "Metrics saved to: eval/cw-bim-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4573  prec=0.4462  recall=0.3537  f1=0.3946\n",
      "  roc_auc=0.4702\n",
      "Metrics saved to: eval/cw-bim-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.2805  prec=0.1400  recall=0.0854  f1=0.1061\n",
      "  roc_auc=0.1596\n",
      "Metrics saved to: eval/cw-pgd-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.4857  recall=0.4146  f1=0.4474\n",
      "  roc_auc=0.4761\n",
      "Metrics saved to: eval/cw-pgd-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5549  prec=0.5474  recall=0.6341  f1=0.5876\n",
      "  roc_auc=0.5944\n",
      "Metrics saved to: eval/cw-df-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.4857  recall=0.4146  f1=0.4474\n",
      "  roc_auc=0.4871\n",
      "Metrics saved to: eval/cw-df-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5122  prec=0.5114  recall=0.5488  f1=0.5294\n",
      "  roc_auc=0.5668\n",
      "Metrics saved to: eval/cw-cw-64-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.4390  f1=0.4675\n",
      "  roc_auc=0.5152\n",
      "Metrics saved to: eval/cw-cw-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9207  prec=0.9481  recall=0.8902  f1=0.9182\n",
      "  roc_auc=0.9597\n",
      "Metrics saved to: eval/fgsm-fgsm-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9146  prec=0.8953  recall=0.9390  f1=0.9167\n",
      "  roc_auc=0.9699\n",
      "Metrics saved to: eval/fgsm-fgsm-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5976  prec=0.8333  recall=0.2439  f1=0.3774\n",
      "  roc_auc=0.6692\n",
      "Metrics saved to: eval/fgsm-bim-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.6829  prec=0.8125  recall=0.4756  f1=0.6000\n",
      "  roc_auc=0.8131\n",
      "Metrics saved to: eval/fgsm-bim-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5915  prec=0.8261  recall=0.2317  f1=0.3619\n",
      "  roc_auc=0.6431\n",
      "Metrics saved to: eval/fgsm-pgd-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.7134  prec=0.8302  recall=0.5366  f1=0.6519\n",
      "  roc_auc=0.8235\n",
      "Metrics saved to: eval/fgsm-pgd-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5305  prec=0.6923  recall=0.1098  f1=0.1895\n",
      "  roc_auc=0.5474\n",
      "Metrics saved to: eval/fgsm-df-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.1098  f1=0.1800\n",
      "  roc_auc=0.5009\n",
      "Metrics saved to: eval/fgsm-df-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5244  prec=0.6667  recall=0.0976  f1=0.1702\n",
      "  roc_auc=0.5497\n",
      "Metrics saved to: eval/fgsm-cw-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4817  prec=0.4000  recall=0.0732  f1=0.1237\n",
      "  roc_auc=0.5243\n",
      "Metrics saved to: eval/fgsm-cw-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5122  prec=0.7500  recall=0.0366  f1=0.0698\n",
      "  roc_auc=0.5915\n",
      "Metrics saved to: eval/bim-fgsm-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4939  prec=0.3333  recall=0.0122  f1=0.0235\n",
      "  roc_auc=0.5205\n",
      "Metrics saved to: eval/bim-fgsm-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9878  prec=0.9878  recall=0.9878  f1=0.9878\n",
      "  roc_auc=0.9997\n",
      "Metrics saved to: eval/bim-bim-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9817  prec=0.9759  recall=0.9878  f1=0.9818\n",
      "  roc_auc=0.9989\n",
      "Metrics saved to: eval/bim-bim-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9939  prec=0.9880  recall=1.0000  f1=0.9939\n",
      "  roc_auc=0.9999\n",
      "Metrics saved to: eval/bim-pgd-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9817  prec=0.9759  recall=0.9878  f1=0.9818\n",
      "  roc_auc=0.9990\n",
      "Metrics saved to: eval/bim-pgd-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.0122  f1=0.0238\n",
      "  roc_auc=0.3604\n",
      "Metrics saved to: eval/bim-df-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.3776\n",
      "Metrics saved to: eval/bim-df-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.0122  f1=0.0238\n",
      "  roc_auc=0.3919\n",
      "Metrics saved to: eval/bim-cw-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4939  prec=0.3333  recall=0.0122  f1=0.0235\n",
      "  roc_auc=0.4227\n",
      "Metrics saved to: eval/bim-cw-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5122  prec=1.0000  recall=0.0244  f1=0.0476\n",
      "  roc_auc=0.5781\n",
      "Metrics saved to: eval/pgd-fgsm-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.1s remaining:    0.9s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.5183\n",
      "Metrics saved to: eval/pgd-fgsm-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9878  prec=1.0000  recall=0.9756  f1=0.9877\n",
      "  roc_auc=0.9993\n",
      "Metrics saved to: eval/pgd-bim-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9817  prec=0.9759  recall=0.9878  f1=0.9818\n",
      "  roc_auc=0.9993\n",
      "Metrics saved to: eval/pgd-bim-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9939  prec=1.0000  recall=0.9878  f1=0.9939\n",
      "  roc_auc=1.0000\n",
      "Metrics saved to: eval/pgd-pgd-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9817  prec=0.9759  recall=0.9878  f1=0.9818\n",
      "  roc_auc=0.9990\n",
      "Metrics saved to: eval/pgd-pgd-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.3553\n",
      "Metrics saved to: eval/pgd-df-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.3950\n",
      "Metrics saved to: eval/pgd-df-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.3891\n",
      "Metrics saved to: eval/pgd-cw-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.4269\n",
      "Metrics saved to: eval/pgd-cw-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6646  prec=0.6517  recall=0.7073  f1=0.6784\n",
      "  roc_auc=0.7214\n",
      "Metrics saved to: eval/df-fgsm-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.6463  prec=0.6463  recall=0.6463  f1=0.6463\n",
      "  roc_auc=0.6957\n",
      "Metrics saved to: eval/df-fgsm-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.3110  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.0552\n",
      "Metrics saved to: eval/df-bim-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.3598  prec=0.1714  recall=0.0732  f1=0.1026\n",
      "  roc_auc=0.2125\n",
      "Metrics saved to: eval/df-bim-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.3110  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.0186\n",
      "Metrics saved to: eval/df-pgd-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.3598  prec=0.1714  recall=0.0732  f1=0.1026\n",
      "  roc_auc=0.2169\n",
      "Metrics saved to: eval/df-pgd-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6524  prec=0.6437  recall=0.6829  f1=0.6627\n",
      "  roc_auc=0.7017\n",
      "Metrics saved to: eval/df-df-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5976  prec=0.6081  recall=0.5488  f1=0.5769\n",
      "  roc_auc=0.6152\n",
      "Metrics saved to: eval/df-df-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6220  prec=0.6220  recall=0.6220  f1=0.6220\n",
      "  roc_auc=0.6727\n",
      "Metrics saved to: eval/df-cw-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5854  prec=0.5972  recall=0.5244  f1=0.5584\n",
      "  roc_auc=0.6158\n",
      "Metrics saved to: eval/df-cw-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.7134  prec=0.6636  recall=0.8659  f1=0.7513\n",
      "  roc_auc=0.7891\n",
      "Metrics saved to: eval/cw-fgsm-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5976  prec=0.5889  recall=0.6463  f1=0.6163\n",
      "  roc_auc=0.6315\n",
      "Metrics saved to: eval/cw-fgsm-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.2988  prec=0.0769  recall=0.0366  f1=0.0496\n",
      "  roc_auc=0.1179\n",
      "Metrics saved to: eval/cw-bim-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.3659  prec=0.2885  recall=0.1829  f1=0.2239\n",
      "  roc_auc=0.2559\n",
      "Metrics saved to: eval/cw-bim-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.2805  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.0669\n",
      "Metrics saved to: eval/cw-pgd-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.3415  prec=0.2292  recall=0.1341  f1=0.1692\n",
      "  roc_auc=0.2590\n",
      "Metrics saved to: eval/cw-pgd-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6402  prec=0.6211  recall=0.7195  f1=0.6667\n",
      "  roc_auc=0.6991\n",
      "Metrics saved to: eval/cw-df-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5671  prec=0.5647  recall=0.5854  f1=0.5749\n",
      "  roc_auc=0.5848\n",
      "Metrics saved to: eval/cw-df-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6220  prec=0.6087  recall=0.6829  f1=0.6437\n",
      "  roc_auc=0.6773\n",
      "Metrics saved to: eval/cw-cw-128-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5671  prec=0.5647  recall=0.5854  f1=0.5749\n",
      "  roc_auc=0.6105\n",
      "Metrics saved to: eval/cw-cw-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "classifier = ['LogisticRegression', 'RandomForest']\n",
    "IMG_SIZES = [32, 64, 128]\n",
    "\n",
    "ATTACKS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n",
    "DATASETS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n",
    "\n",
    "for IMG_SIZE in IMG_SIZES:\n",
    "    for ATTACK in ATTACKS:\n",
    "        for DATASET in DATASETS:\n",
    "            for classifier in classifiers:\n",
    "                print(f'Evaluate Against Test Set (Image Size: {IMG_SIZE}) \\n Method: {ATTACK} \\n Dataset: {DATASET} \\n Classifier: {classifier}\\n')\n",
    "                eval_test_from_npy(\n",
    "                    test_clean_npy_path=f'/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{DATASET}/test_clean_raw.npy',\n",
    "                    test_adv_npy_path=f'/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{DATASET}/test_adv_raw.npy',\n",
    "                    model_out_dir=f\"/kaggle/working/models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                    test_labels_npy_path=None,\n",
    "                    return_predictions=False,\n",
    "                    use_mmap=False,\n",
    "                    csv_path=f\"./eval/{ATTACK}-{DATASET}-{IMG_SIZE}-{classifier}_test_result.csv\"\n",
    "                )\n",
    "                print ('_________________________\\n')\n",
    "        \n",
    "            print ('===============================\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T15:29:36.360241Z",
     "iopub.status.busy": "2025-10-19T15:29:36.359926Z",
     "iopub.status.idle": "2025-10-19T15:31:22.830853Z",
     "shell.execute_reply": "2025-10-19T15:31:22.829787Z",
     "shell.execute_reply.started": "2025-10-19T15:29:36.360222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: fgsm \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.7744  prec=0.7528  recall=0.8171  f1=0.7836\n",
      "  roc_auc=0.8679\n",
      "Metrics saved to: eval/fgsm-fgsm-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: fgsm \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.7073  prec=0.6889  recall=0.7561  f1=0.7209\n",
      "  roc_auc=0.7950\n",
      "Metrics saved to: eval/fgsm-fgsm-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: bim \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5427  prec=0.5686  recall=0.3537  f1=0.4361\n",
      "  roc_auc=0.6792\n",
      "Metrics saved to: eval/fgsm-bim-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: bim \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5427  prec=0.5556  recall=0.4268  f1=0.4828\n",
      "  roc_auc=0.5927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to: eval/fgsm-bim-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: pgd \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5610  prec=0.5926  recall=0.3902  f1=0.4706\n",
      "  roc_auc=0.6557\n",
      "Metrics saved to: eval/fgsm-pgd-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: pgd \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5854  prec=0.6000  recall=0.5122  f1=0.5526\n",
      "  roc_auc=0.6191\n",
      "Metrics saved to: eval/fgsm-pgd-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: df \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5061  prec=0.5111  recall=0.2805  f1=0.3622\n",
      "  roc_auc=0.5171\n",
      "Metrics saved to: eval/fgsm-df-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: df \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5061  prec=0.5088  recall=0.3537  f1=0.4173\n",
      "  roc_auc=0.4990\n",
      "Metrics saved to: eval/fgsm-df-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: cw \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.4762  recall=0.2439  f1=0.3226\n",
      "  roc_auc=0.5097\n",
      "Metrics saved to: eval/fgsm-cw-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: fgsm \n",
      " Dataset: cw \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5061  prec=0.5088  recall=0.3537  f1=0.4173\n",
      "  roc_auc=0.5033\n",
      "Metrics saved to: eval/fgsm-cw-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: fgsm \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.6707  prec=0.8889  recall=0.3902  f1=0.5424\n",
      "  roc_auc=0.8229\n",
      "Metrics saved to: eval/bim-fgsm-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: fgsm \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6037  prec=0.7179  recall=0.3415  f1=0.4628\n",
      "  roc_auc=0.6858\n",
      "Metrics saved to: eval/bim-fgsm-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: bim \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.8537  prec=0.9394  recall=0.7561  f1=0.8378\n",
      "  roc_auc=0.9420\n",
      "Metrics saved to: eval/bim-bim-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: bim \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.7256  prec=0.8136  recall=0.5854  f1=0.6809\n",
      "  roc_auc=0.8035\n",
      "Metrics saved to: eval/bim-bim-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: pgd \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.7988  prec=0.9298  recall=0.6463  f1=0.7626\n",
      "  roc_auc=0.9087\n",
      "Metrics saved to: eval/bim-pgd-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: pgd \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.7195  prec=0.8103  recall=0.5732  f1=0.6714\n",
      "  roc_auc=0.7925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to: eval/bim-pgd-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: df \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5122  prec=0.6000  recall=0.0732  f1=0.1304\n",
      "  roc_auc=0.4833\n",
      "Metrics saved to: eval/bim-df-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: df \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5061  prec=0.5217  recall=0.1463  f1=0.2286\n",
      "  roc_auc=0.5021\n",
      "Metrics saved to: eval/bim-df-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: cw \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5122  prec=0.6000  recall=0.0732  f1=0.1304\n",
      "  roc_auc=0.4946\n",
      "Metrics saved to: eval/bim-cw-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: bim \n",
      " Dataset: cw \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5061  prec=0.5217  recall=0.1463  f1=0.2286\n",
      "  roc_auc=0.4873\n",
      "Metrics saved to: eval/bim-cw-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: fgsm \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6829  prec=0.7679  recall=0.5244  f1=0.6232\n",
      "  roc_auc=0.8205\n",
      "Metrics saved to: eval/pgd-fgsm-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: fgsm \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.6280  prec=0.7143  recall=0.4268  f1=0.5344\n",
      "  roc_auc=0.6897\n",
      "Metrics saved to: eval/pgd-fgsm-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: bim \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.8415  prec=0.8415  recall=0.8415  f1=0.8415\n",
      "  roc_auc=0.9350\n",
      "Metrics saved to: eval/pgd-bim-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: bim \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.7622  prec=0.8028  recall=0.6951  f1=0.7451\n",
      "  roc_auc=0.8348\n",
      "Metrics saved to: eval/pgd-bim-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: pgd \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.7866  prec=0.8219  recall=0.7317  f1=0.7742\n",
      "  roc_auc=0.8969\n",
      "Metrics saved to: eval/pgd-pgd-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: pgd \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.7500  prec=0.7971  recall=0.6707  f1=0.7285\n",
      "  roc_auc=0.8030\n",
      "Metrics saved to: eval/pgd-pgd-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: df \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4939  prec=0.4800  recall=0.1463  f1=0.2243\n",
      "  roc_auc=0.4845\n",
      "Metrics saved to: eval/pgd-df-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: df \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5366  prec=0.5882  recall=0.2439  f1=0.3448\n",
      "  roc_auc=0.5225\n",
      "Metrics saved to: eval/pgd-df-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: cw \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.1585  f1=0.2407\n",
      "  roc_auc=0.4918\n",
      "Metrics saved to: eval/pgd-cw-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: pgd \n",
      " Dataset: cw \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5305  prec=0.5758  recall=0.2317  f1=0.3304\n",
      "  roc_auc=0.5385\n",
      "Metrics saved to: eval/pgd-cw-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: fgsm \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5427  prec=0.5412  recall=0.5610  f1=0.5509\n",
      "  roc_auc=0.5640\n",
      "Metrics saved to: eval/df-fgsm-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: fgsm \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5427  prec=0.5432  recall=0.5366  f1=0.5399\n",
      "  roc_auc=0.5609\n",
      "Metrics saved to: eval/df-fgsm-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: bim \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4390  prec=0.4265  recall=0.3537  f1=0.3867\n",
      "  roc_auc=0.3932\n",
      "Metrics saved to: eval/df-bim-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: bim \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5244  prec=0.5256  recall=0.5000  f1=0.5125\n",
      "  roc_auc=0.5255\n",
      "Metrics saved to: eval/df-bim-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: pgd \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4573  prec=0.4507  recall=0.3902  f1=0.4183\n",
      "  roc_auc=0.4087\n",
      "Metrics saved to: eval/df-pgd-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: pgd \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5549  prec=0.5542  recall=0.5610  f1=0.5576\n",
      "  roc_auc=0.5544\n",
      "Metrics saved to: eval/df-pgd-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: df \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5427  prec=0.5412  recall=0.5610  f1=0.5509\n",
      "  roc_auc=0.5294\n",
      "Metrics saved to: eval/df-df-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: df \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5183  prec=0.5195  recall=0.4878  f1=0.5031\n",
      "  roc_auc=0.5027\n",
      "Metrics saved to: eval/df-df-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: cw \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5305  prec=0.5301  recall=0.5366  f1=0.5333\n",
      "  roc_auc=0.5123\n",
      "Metrics saved to: eval/df-cw-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: df \n",
      " Dataset: cw \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.4861  recall=0.4268  f1=0.4545\n",
      "  roc_auc=0.4942\n",
      "Metrics saved to: eval/df-cw-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: fgsm \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5671  prec=0.5556  recall=0.6707  f1=0.6077\n",
      "  roc_auc=0.6169\n",
      "Metrics saved to: eval/cw-fgsm-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: fgsm \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.1s remaining:    0.9s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4512  prec=0.4524  recall=0.4634  f1=0.4578\n",
      "  roc_auc=0.4813\n",
      "Metrics saved to: eval/cw-fgsm-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: bim \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4146  prec=0.4054  recall=0.3659  f1=0.3846\n",
      "  roc_auc=0.4209\n",
      "Metrics saved to: eval/cw-bim-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: bim \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4695  prec=0.4713  recall=0.5000  f1=0.4852\n",
      "  roc_auc=0.4642\n",
      "Metrics saved to: eval/cw-bim-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: pgd \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4573  prec=0.4568  recall=0.4512  f1=0.4540\n",
      "  roc_auc=0.4285\n",
      "Metrics saved to: eval/cw-pgd-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: pgd \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4146  prec=0.4103  recall=0.3902  f1=0.4000\n",
      "  roc_auc=0.4174\n",
      "Metrics saved to: eval/cw-pgd-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: df \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.5366  f1=0.5176\n",
      "  roc_auc=0.5272\n",
      "Metrics saved to: eval/cw-df-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: df \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4939  prec=0.4945  recall=0.5488  f1=0.5202\n",
      "  roc_auc=0.5122\n",
      "Metrics saved to: eval/cw-df-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: cw \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.5366  f1=0.5176\n",
      "  roc_auc=0.5021\n",
      "Metrics saved to: eval/cw-cw-32-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 32) \n",
      " Method: cw \n",
      " Dataset: cw \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4939  prec=0.4945  recall=0.5488  f1=0.5202\n",
      "  roc_auc=0.4858\n",
      "Metrics saved to: eval/cw-cw-32-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: fgsm \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.8354  prec=0.8313  recall=0.8415  f1=0.8364\n",
      "  roc_auc=0.9172\n",
      "Metrics saved to: eval/fgsm-fgsm-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: fgsm \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.7073  prec=0.7237  recall=0.6707  f1=0.6962\n",
      "  roc_auc=0.7973\n",
      "Metrics saved to: eval/fgsm-fgsm-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: bim \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6098  prec=0.6957  recall=0.3902  f1=0.5000\n",
      "  roc_auc=0.7295\n",
      "Metrics saved to: eval/fgsm-bim-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: bim \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5671  prec=0.6038  recall=0.3902  f1=0.4741\n",
      "  roc_auc=0.6080\n",
      "Metrics saved to: eval/fgsm-bim-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: pgd \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5793  prec=0.6585  recall=0.3293  f1=0.4390\n",
      "  roc_auc=0.7223\n",
      "Metrics saved to: eval/fgsm-pgd-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: pgd \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5915  prec=0.6316  recall=0.4390  f1=0.5180\n",
      "  roc_auc=0.6469\n",
      "Metrics saved to: eval/fgsm-pgd-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: df \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.1707  f1=0.2545\n",
      "  roc_auc=0.5109\n",
      "Metrics saved to: eval/fgsm-df-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: df \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4939  prec=0.4878  recall=0.2439  f1=0.3252\n",
      "  roc_auc=0.5090\n",
      "Metrics saved to: eval/fgsm-df-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: cw \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.1707  f1=0.2545\n",
      "  roc_auc=0.5132\n",
      "Metrics saved to: eval/fgsm-cw-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: fgsm \n",
      " Dataset: cw \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.2561  f1=0.3387\n",
      "  roc_auc=0.5065\n",
      "Metrics saved to: eval/fgsm-cw-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: fgsm \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5976  prec=0.8636  recall=0.2317  f1=0.3654\n",
      "  roc_auc=0.7078\n",
      "Metrics saved to: eval/bim-fgsm-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: fgsm \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5244  prec=0.6000  recall=0.1463  f1=0.2353\n",
      "  roc_auc=0.5590\n",
      "Metrics saved to: eval/bim-fgsm-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: bim \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9573  prec=0.9630  recall=0.9512  f1=0.9571\n",
      "  roc_auc=0.9929\n",
      "Metrics saved to: eval/bim-bim-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: bim \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9268  prec=0.9070  recall=0.9512  f1=0.9286\n",
      "  roc_auc=0.9813\n",
      "Metrics saved to: eval/bim-bim-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: pgd \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9512  prec=0.9625  recall=0.9390  f1=0.9506\n",
      "  roc_auc=0.9921\n",
      "Metrics saved to: eval/bim-pgd-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: pgd \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9268  prec=0.9070  recall=0.9512  f1=0.9286\n",
      "  roc_auc=0.9836\n",
      "Metrics saved to: eval/bim-pgd-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: df \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.2500  recall=0.0122  f1=0.0233\n",
      "  roc_auc=0.4393\n",
      "Metrics saved to: eval/bim-df-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: df \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4817  prec=0.3846  recall=0.0610  f1=0.1053\n",
      "  roc_auc=0.4575\n",
      "Metrics saved to: eval/bim-df-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: cw \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.2500  recall=0.0122  f1=0.0233\n",
      "  roc_auc=0.4691\n",
      "Metrics saved to: eval/bim-cw-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: bim \n",
      " Dataset: cw \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4817  prec=0.3846  recall=0.0610  f1=0.1053\n",
      "  roc_auc=0.4726\n",
      "Metrics saved to: eval/bim-cw-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: fgsm \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5854  prec=0.8500  recall=0.2073  f1=0.3333\n",
      "  roc_auc=0.7091\n",
      "Metrics saved to: eval/pgd-fgsm-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: fgsm \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5122  prec=0.5556  recall=0.1220  f1=0.2000\n",
      "  roc_auc=0.5793\n",
      "Metrics saved to: eval/pgd-fgsm-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: bim \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9634  prec=0.9634  recall=0.9634  f1=0.9634\n",
      "  roc_auc=0.9933\n",
      "Metrics saved to: eval/pgd-bim-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: bim \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9390  prec=0.9091  recall=0.9756  f1=0.9412\n",
      "  roc_auc=0.9763\n",
      "Metrics saved to: eval/pgd-bim-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: pgd \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9573  prec=0.9630  recall=0.9512  f1=0.9571\n",
      "  roc_auc=0.9942\n",
      "Metrics saved to: eval/pgd-pgd-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: pgd \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9268  prec=0.9070  recall=0.9512  f1=0.9286\n",
      "  roc_auc=0.9770\n",
      "Metrics saved to: eval/pgd-pgd-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: df \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4817  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.4368\n",
      "Metrics saved to: eval/pgd-df-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: df \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4756  prec=0.3333  recall=0.0488  f1=0.0851\n",
      "  roc_auc=0.4322\n",
      "Metrics saved to: eval/pgd-df-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: cw \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4817  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.4655\n",
      "Metrics saved to: eval/pgd-cw-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: pgd \n",
      " Dataset: cw \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4817  prec=0.3846  recall=0.0610  f1=0.1053\n",
      "  roc_auc=0.4647\n",
      "Metrics saved to: eval/pgd-cw-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: fgsm \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5976  prec=0.5930  recall=0.6220  f1=0.6071\n",
      "  roc_auc=0.6286\n",
      "Metrics saved to: eval/df-fgsm-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: fgsm \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.4390  f1=0.4675\n",
      "  roc_auc=0.5029\n",
      "Metrics saved to: eval/df-fgsm-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: bim \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.3110  prec=0.1026  recall=0.0488  f1=0.0661\n",
      "  roc_auc=0.1095\n",
      "Metrics saved to: eval/df-bim-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: bim \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4512  prec=0.4375  recall=0.3415  f1=0.3836\n",
      "  roc_auc=0.4282\n",
      "Metrics saved to: eval/df-bim-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: pgd \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.2927  prec=0.0278  recall=0.0122  f1=0.0169\n",
      "  roc_auc=0.0952\n",
      "Metrics saved to: eval/df-pgd-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: pgd \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4695  prec=0.4627  recall=0.3780  f1=0.4161\n",
      "  roc_auc=0.4470\n",
      "Metrics saved to: eval/df-pgd-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: df \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5671  prec=0.5679  recall=0.5610  f1=0.5644\n",
      "  roc_auc=0.6014\n",
      "Metrics saved to: eval/df-df-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: df \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5366  prec=0.5385  recall=0.5122  f1=0.5250\n",
      "  roc_auc=0.5389\n",
      "Metrics saved to: eval/df-df-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: cw \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5244  prec=0.5270  recall=0.4756  f1=0.5000\n",
      "  roc_auc=0.5690\n",
      "Metrics saved to: eval/df-cw-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: df \n",
      " Dataset: cw \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5122  prec=0.5135  recall=0.4634  f1=0.4872\n",
      "  roc_auc=0.5390\n",
      "Metrics saved to: eval/df-cw-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: fgsm \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6159  prec=0.5905  recall=0.7561  f1=0.6631\n",
      "  roc_auc=0.6972\n",
      "Metrics saved to: eval/cw-fgsm-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: fgsm \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5061  prec=0.5068  recall=0.4512  f1=0.4774\n",
      "  roc_auc=0.5643\n",
      "Metrics saved to: eval/cw-fgsm-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: bim \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.3171  prec=0.2321  recall=0.1585  f1=0.1884\n",
      "  roc_auc=0.1968\n",
      "Metrics saved to: eval/cw-bim-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: bim \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4573  prec=0.4462  recall=0.3537  f1=0.3946\n",
      "  roc_auc=0.4702\n",
      "Metrics saved to: eval/cw-bim-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: pgd \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.2805  prec=0.1400  recall=0.0854  f1=0.1061\n",
      "  roc_auc=0.1596\n",
      "Metrics saved to: eval/cw-pgd-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: pgd \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.4857  recall=0.4146  f1=0.4474\n",
      "  roc_auc=0.4761\n",
      "Metrics saved to: eval/cw-pgd-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: df \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5549  prec=0.5474  recall=0.6341  f1=0.5876\n",
      "  roc_auc=0.5944\n",
      "Metrics saved to: eval/cw-df-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: df \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.4857  recall=0.4146  f1=0.4474\n",
      "  roc_auc=0.4871\n",
      "Metrics saved to: eval/cw-df-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: cw \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5122  prec=0.5114  recall=0.5488  f1=0.5294\n",
      "  roc_auc=0.5668\n",
      "Metrics saved to: eval/cw-cw-64-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 64) \n",
      " Method: cw \n",
      " Dataset: cw \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.4390  f1=0.4675\n",
      "  roc_auc=0.5152\n",
      "Metrics saved to: eval/cw-cw-64-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: fgsm \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9207  prec=0.9481  recall=0.8902  f1=0.9182\n",
      "  roc_auc=0.9597\n",
      "Metrics saved to: eval/fgsm-fgsm-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: fgsm \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9146  prec=0.8953  recall=0.9390  f1=0.9167\n",
      "  roc_auc=0.9699\n",
      "Metrics saved to: eval/fgsm-fgsm-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: bim \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5976  prec=0.8333  recall=0.2439  f1=0.3774\n",
      "  roc_auc=0.6692\n",
      "Metrics saved to: eval/fgsm-bim-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: bim \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.6829  prec=0.8125  recall=0.4756  f1=0.6000\n",
      "  roc_auc=0.8131\n",
      "Metrics saved to: eval/fgsm-bim-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: pgd \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5915  prec=0.8261  recall=0.2317  f1=0.3619\n",
      "  roc_auc=0.6431\n",
      "Metrics saved to: eval/fgsm-pgd-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: pgd \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.7134  prec=0.8302  recall=0.5366  f1=0.6519\n",
      "  roc_auc=0.8235\n",
      "Metrics saved to: eval/fgsm-pgd-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: df \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5305  prec=0.6923  recall=0.1098  f1=0.1895\n",
      "  roc_auc=0.5474\n",
      "Metrics saved to: eval/fgsm-df-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: df \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.1098  f1=0.1800\n",
      "  roc_auc=0.5009\n",
      "Metrics saved to: eval/fgsm-df-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: cw \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5244  prec=0.6667  recall=0.0976  f1=0.1702\n",
      "  roc_auc=0.5497\n",
      "Metrics saved to: eval/fgsm-cw-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: fgsm \n",
      " Dataset: cw \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4817  prec=0.4000  recall=0.0732  f1=0.1237\n",
      "  roc_auc=0.5243\n",
      "Metrics saved to: eval/fgsm-cw-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: fgsm \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5122  prec=0.7500  recall=0.0366  f1=0.0698\n",
      "  roc_auc=0.5915\n",
      "Metrics saved to: eval/bim-fgsm-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: fgsm \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.1s remaining:    0.9s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4939  prec=0.3333  recall=0.0122  f1=0.0235\n",
      "  roc_auc=0.5205\n",
      "Metrics saved to: eval/bim-fgsm-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: bim \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9878  prec=0.9878  recall=0.9878  f1=0.9878\n",
      "  roc_auc=0.9997\n",
      "Metrics saved to: eval/bim-bim-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: bim \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9817  prec=0.9759  recall=0.9878  f1=0.9818\n",
      "  roc_auc=0.9989\n",
      "Metrics saved to: eval/bim-bim-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: pgd \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9939  prec=0.9880  recall=1.0000  f1=0.9939\n",
      "  roc_auc=0.9999\n",
      "Metrics saved to: eval/bim-pgd-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: pgd \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9817  prec=0.9759  recall=0.9878  f1=0.9818\n",
      "  roc_auc=0.9990\n",
      "Metrics saved to: eval/bim-pgd-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: df \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.0122  f1=0.0238\n",
      "  roc_auc=0.3604\n",
      "Metrics saved to: eval/bim-df-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: df \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.3776\n",
      "Metrics saved to: eval/bim-df-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: cw \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.0122  f1=0.0238\n",
      "  roc_auc=0.3919\n",
      "Metrics saved to: eval/bim-cw-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: bim \n",
      " Dataset: cw \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4939  prec=0.3333  recall=0.0122  f1=0.0235\n",
      "  roc_auc=0.4227\n",
      "Metrics saved to: eval/bim-cw-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: fgsm \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5122  prec=1.0000  recall=0.0244  f1=0.0476\n",
      "  roc_auc=0.5781\n",
      "Metrics saved to: eval/pgd-fgsm-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: fgsm \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.5183\n",
      "Metrics saved to: eval/pgd-fgsm-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: bim \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9878  prec=1.0000  recall=0.9756  f1=0.9877\n",
      "  roc_auc=0.9993\n",
      "Metrics saved to: eval/pgd-bim-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: bim \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9817  prec=0.9759  recall=0.9878  f1=0.9818\n",
      "  roc_auc=0.9993\n",
      "Metrics saved to: eval/pgd-bim-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: pgd \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9939  prec=1.0000  recall=0.9878  f1=0.9939\n",
      "  roc_auc=1.0000\n",
      "Metrics saved to: eval/pgd-pgd-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: pgd \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9817  prec=0.9759  recall=0.9878  f1=0.9818\n",
      "  roc_auc=0.9990\n",
      "Metrics saved to: eval/pgd-pgd-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: df \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.3553\n",
      "Metrics saved to: eval/pgd-df-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: df \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.3950\n",
      "Metrics saved to: eval/pgd-df-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: cw \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.3891\n",
      "Metrics saved to: eval/pgd-cw-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: pgd \n",
      " Dataset: cw \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.4269\n",
      "Metrics saved to: eval/pgd-cw-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: fgsm \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6646  prec=0.6517  recall=0.7073  f1=0.6784\n",
      "  roc_auc=0.7214\n",
      "Metrics saved to: eval/df-fgsm-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: fgsm \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.6463  prec=0.6463  recall=0.6463  f1=0.6463\n",
      "  roc_auc=0.6957\n",
      "Metrics saved to: eval/df-fgsm-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: bim \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.3110  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.0552\n",
      "Metrics saved to: eval/df-bim-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: bim \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.3598  prec=0.1714  recall=0.0732  f1=0.1026\n",
      "  roc_auc=0.2125\n",
      "Metrics saved to: eval/df-bim-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: pgd \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.3110  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.0186\n",
      "Metrics saved to: eval/df-pgd-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: pgd \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.3598  prec=0.1714  recall=0.0732  f1=0.1026\n",
      "  roc_auc=0.2169\n",
      "Metrics saved to: eval/df-pgd-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: df \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6524  prec=0.6437  recall=0.6829  f1=0.6627\n",
      "  roc_auc=0.7017\n",
      "Metrics saved to: eval/df-df-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: df \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5976  prec=0.6081  recall=0.5488  f1=0.5769\n",
      "  roc_auc=0.6152\n",
      "Metrics saved to: eval/df-df-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: cw \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6220  prec=0.6220  recall=0.6220  f1=0.6220\n",
      "  roc_auc=0.6727\n",
      "Metrics saved to: eval/df-cw-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: df \n",
      " Dataset: cw \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5854  prec=0.5972  recall=0.5244  f1=0.5584\n",
      "  roc_auc=0.6158\n",
      "Metrics saved to: eval/df-cw-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: fgsm \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.7134  prec=0.6636  recall=0.8659  f1=0.7513\n",
      "  roc_auc=0.7891\n",
      "Metrics saved to: eval/cw-fgsm-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: fgsm \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5976  prec=0.5889  recall=0.6463  f1=0.6163\n",
      "  roc_auc=0.6315\n",
      "Metrics saved to: eval/cw-fgsm-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: bim \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.2988  prec=0.0769  recall=0.0366  f1=0.0496\n",
      "  roc_auc=0.1179\n",
      "Metrics saved to: eval/cw-bim-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: bim \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.1s remaining:    0.9s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.3659  prec=0.2885  recall=0.1829  f1=0.2239\n",
      "  roc_auc=0.2559\n",
      "Metrics saved to: eval/cw-bim-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: pgd \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.2805  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.0669\n",
      "Metrics saved to: eval/cw-pgd-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: pgd \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.3415  prec=0.2292  recall=0.1341  f1=0.1692\n",
      "  roc_auc=0.2590\n",
      "Metrics saved to: eval/cw-pgd-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: df \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6402  prec=0.6211  recall=0.7195  f1=0.6667\n",
      "  roc_auc=0.6991\n",
      "Metrics saved to: eval/cw-df-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: df \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5671  prec=0.5647  recall=0.5854  f1=0.5749\n",
      "  roc_auc=0.5848\n",
      "Metrics saved to: eval/cw-df-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: cw \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6220  prec=0.6087  recall=0.6829  f1=0.6437\n",
      "  roc_auc=0.6773\n",
      "Metrics saved to: eval/cw-cw-128-LogisticRegression_test_result.csv\n",
      "Evaluate Against Test Set (Image Size: 128) \n",
      " Method: cw \n",
      " Dataset: cw \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5671  prec=0.5647  recall=0.5854  f1=0.5749\n",
      "  roc_auc=0.6105\n",
      "Metrics saved to: eval/cw-cw-128-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "classifier = 'LogisticRegression'\n",
    "IMG_SIZES = [32, 64, 128]\n",
    "\n",
    "ATTACKS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n",
    "DATASETS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n",
    "classifiers = ['LogisticRegression', 'RandomForest']\n",
    "\n",
    "for IMG_SIZE in IMG_SIZES:\n",
    "    for ATTACK in ATTACKS:\n",
    "        for DATASET in DATASETS:\n",
    "            for classifier in classifiers:\n",
    "                print(f'Evaluate Against Test Set (Image Size: {IMG_SIZE}) \\n Method: {ATTACK} \\n Dataset: {DATASET} \\n')\n",
    "                eval_test_from_npy(\n",
    "                    test_clean_npy_path=f'/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{DATASET}/test_clean_raw.npy',\n",
    "                    test_adv_npy_path=f'/kaggle/input/layerpfs-dataset/{IMG_SIZE}x{IMG_SIZE}/{DATASET}/test_adv_raw.npy',\n",
    "                    model_out_dir=f\"/kaggle/working/models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                    test_labels_npy_path=None,\n",
    "                    return_predictions=False,\n",
    "                    use_mmap=False,\n",
    "                    csv_path=f\"./eval/{ATTACK}-{DATASET}-{IMG_SIZE}-{classifier}_test_result.csv\"\n",
    "                )\n",
    "            print ('_________________________\\n')\n",
    "    \n",
    "        print ('===============================\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T18:48:51.410538Z",
     "iopub.status.busy": "2025-10-20T18:48:51.410353Z",
     "iopub.status.idle": "2025-10-20T18:48:51.450775Z",
     "shell.execute_reply": "2025-10-20T18:48:51.449795Z",
     "shell.execute_reply.started": "2025-10-20T18:48:51.410522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating zip: /kaggle/working/evals.zip\n",
      "  adding: df-pgd-64-RandomForest_test_result.csv\n",
      "  adding: pgd-bim-32-RandomForest_test_result.csv\n",
      "  adding: df-fgsm-64-RandomForest_test_result.csv\n",
      "  adding: cw-cw-64-LogisticRegression_test_result.csv\n",
      "  adding: fgsm-pgd-128-LogisticRegression_test_result.csv\n",
      "  adding: df-bim-64-RandomForest_test_result.csv\n",
      "  adding: pgd-cw-128-LogisticRegression_test_result.csv\n",
      "  adding: bim-pgd-32-LogisticRegression_test_result.csv\n",
      "  adding: pgd-fgsm-32-LogisticRegression_test_result.csv\n",
      "  adding: cw-fgsm-128-LogisticRegression_test_result.csv\n",
      "  adding: pgd-bim-128-RandomForest_test_result.csv\n",
      "  adding: bim-bim-128-LogisticRegression_test_result.csv\n",
      "  adding: bim-df-64-LogisticRegression_test_result.csv\n",
      "  adding: df-fgsm-128-LogisticRegression_test_result.csv\n",
      "  adding: df-pgd-128-RandomForest_test_result.csv\n",
      "  adding: df-pgd-32-LogisticRegression_test_result.csv\n",
      "  adding: cw-bim-128-LogisticRegression_test_result.csv\n",
      "  adding: fgsm-bim-128-LogisticRegression_test_result.csv\n",
      "  adding: pgd-cw-64-RandomForest_test_result.csv\n",
      "  adding: bim-pgd-128-RandomForest_test_result.csv\n",
      "  adding: cw-pgd-128-LogisticRegression_test_result.csv\n",
      "  adding: fgsm-fgsm-64-RandomForest_test_result.csv\n",
      "  adding: bim-bim-32-LogisticRegression_test_result.csv\n",
      "  adding: pgd-pgd-64-LogisticRegression_test_result.csv\n",
      "  adding: pgd-cw-32-RandomForest_test_result.csv\n",
      "  adding: bim-cw-32-LogisticRegression_test_result.csv\n",
      "  adding: pgd-df-32-RandomForest_test_result.csv\n",
      "  adding: df-pgd-32-RandomForest_test_result.csv\n",
      "  adding: fgsm-fgsm-64-LogisticRegression_test_result.csv\n",
      "  adding: pgd-bim-128-LogisticRegression_test_result.csv\n",
      "  adding: df-fgsm-32-LogisticRegression_test_result.csv\n",
      "  adding: cw-df-32-LogisticRegression_test_result.csv\n",
      "  adding: cw-bim-64-LogisticRegression_test_result.csv\n",
      "  adding: pgd-pgd-128-LogisticRegression_test_result.csv\n",
      "  adding: df-bim-128-RandomForest_test_result.csv\n",
      "  adding: df-df-64-RandomForest_test_result.csv\n",
      "  adding: fgsm-bim-32-RandomForest_test_result.csv\n",
      "  adding: df-bim-128-LogisticRegression_test_result.csv\n",
      "  adding: bim-bim-32-RandomForest_test_result.csv\n",
      "  adding: pgd-cw-32-LogisticRegression_test_result.csv\n",
      "  adding: df-df-32-LogisticRegression_test_result.csv\n",
      "  adding: df-bim-64-LogisticRegression_test_result.csv\n",
      "  adding: pgd-fgsm-32-RandomForest_test_result.csv\n",
      "  adding: cw-pgd-64-LogisticRegression_test_result.csv\n",
      "  adding: pgd-fgsm-128-RandomForest_test_result.csv\n",
      "  adding: fgsm-fgsm-128-RandomForest_test_result.csv\n",
      "  adding: pgd-pgd-32-LogisticRegression_test_result.csv\n",
      "  adding: fgsm-cw-32-RandomForest_test_result.csv\n",
      "  adding: fgsm-bim-128-RandomForest_test_result.csv\n",
      "  adding: pgd-bim-64-RandomForest_test_result.csv\n",
      "  adding: pgd-cw-64-LogisticRegression_test_result.csv\n",
      "  adding: df-fgsm-64-LogisticRegression_test_result.csv\n",
      "  adding: cw-df-64-RandomForest_test_result.csv\n",
      "  adding: fgsm-fgsm-32-LogisticRegression_test_result.csv\n",
      "  adding: fgsm-bim-64-LogisticRegression_test_result.csv\n",
      "  adding: cw-df-64-LogisticRegression_test_result.csv\n",
      "  adding: fgsm-fgsm-128-LogisticRegression_test_result.csv\n",
      "  adding: pgd-bim-32-LogisticRegression_test_result.csv\n",
      "  adding: bim-cw-64-RandomForest_test_result.csv\n",
      "  adding: fgsm-bim-32-LogisticRegression_test_result.csv\n",
      "  adding: bim-fgsm-64-RandomForest_test_result.csv\n",
      "  adding: bim-df-32-LogisticRegression_test_result.csv\n",
      "  adding: fgsm-pgd-128-RandomForest_test_result.csv\n",
      "  adding: fgsm-cw-64-LogisticRegression_test_result.csv\n",
      "  adding: pgd-df-64-RandomForest_test_result.csv\n",
      "  adding: fgsm-df-64-LogisticRegression_test_result.csv\n",
      "  adding: pgd-df-64-LogisticRegression_test_result.csv\n",
      "  adding: df-cw-64-LogisticRegression_test_result.csv\n",
      "  adding: df-fgsm-32-RandomForest_test_result.csv\n",
      "  adding: df-df-128-RandomForest_test_result.csv\n",
      "  adding: fgsm-cw-128-LogisticRegression_test_result.csv\n",
      "  adding: pgd-cw-128-RandomForest_test_result.csv\n",
      "  adding: fgsm-pgd-64-RandomForest_test_result.csv\n",
      "  adding: pgd-fgsm-64-RandomForest_test_result.csv\n",
      "  adding: pgd-df-128-RandomForest_test_result.csv\n",
      "  adding: df-bim-32-LogisticRegression_test_result.csv\n",
      "  adding: df-fgsm-128-RandomForest_test_result.csv\n",
      "  adding: fgsm-pgd-64-LogisticRegression_test_result.csv\n",
      "  adding: bim-cw-64-LogisticRegression_test_result.csv\n",
      "  adding: cw-bim-128-RandomForest_test_result.csv\n",
      "  adding: bim-df-64-RandomForest_test_result.csv\n",
      "  adding: fgsm-df-64-RandomForest_test_result.csv\n",
      "  adding: pgd-pgd-128-RandomForest_test_result.csv\n",
      "  adding: df-cw-32-RandomForest_test_result.csv\n",
      "  adding: bim-bim-128-RandomForest_test_result.csv\n",
      "  adding: df-cw-32-LogisticRegression_test_result.csv\n",
      "  adding: df-df-64-LogisticRegression_test_result.csv\n",
      "  adding: cw-cw-128-LogisticRegression_test_result.csv\n",
      "  adding: pgd-df-32-LogisticRegression_test_result.csv\n",
      "  adding: pgd-bim-64-LogisticRegression_test_result.csv\n",
      "  adding: bim-pgd-64-LogisticRegression_test_result.csv\n",
      "  adding: bim-bim-64-LogisticRegression_test_result.csv\n",
      "  adding: fgsm-df-128-LogisticRegression_test_result.csv\n",
      "  adding: bim-cw-128-LogisticRegression_test_result.csv\n",
      "  adding: fgsm-pgd-32-RandomForest_test_result.csv\n",
      "  adding: cw-df-32-RandomForest_test_result.csv\n",
      "  adding: fgsm-cw-32-LogisticRegression_test_result.csv\n",
      "  adding: cw-fgsm-64-RandomForest_test_result.csv\n",
      "  adding: pgd-fgsm-64-LogisticRegression_test_result.csv\n",
      "  adding: df-pgd-64-LogisticRegression_test_result.csv\n",
      "  adding: cw-pgd-32-LogisticRegression_test_result.csv\n",
      "  adding: fgsm-bim-64-RandomForest_test_result.csv\n",
      "  adding: bim-df-32-RandomForest_test_result.csv\n",
      "  adding: df-df-32-RandomForest_test_result.csv\n",
      "  adding: bim-pgd-64-RandomForest_test_result.csv\n",
      "  adding: cw-fgsm-64-LogisticRegression_test_result.csv\n",
      "  adding: df-df-128-LogisticRegression_test_result.csv\n",
      "  adding: df-cw-128-LogisticRegression_test_result.csv\n",
      "  adding: bim-df-128-RandomForest_test_result.csv\n",
      "  adding: bim-cw-128-RandomForest_test_result.csv\n",
      "  adding: cw-fgsm-32-LogisticRegression_test_result.csv\n",
      "  adding: cw-cw-32-RandomForest_test_result.csv\n",
      "  adding: pgd-fgsm-128-LogisticRegression_test_result.csv\n",
      "  adding: pgd-df-128-LogisticRegression_test_result.csv\n",
      "  adding: cw-bim-32-RandomForest_test_result.csv\n",
      "  adding: cw-cw-128-RandomForest_test_result.csv\n",
      "  adding: bim-fgsm-128-LogisticRegression_test_result.csv\n",
      "  adding: df-pgd-128-LogisticRegression_test_result.csv\n",
      "  adding: bim-cw-32-RandomForest_test_result.csv\n",
      "  adding: pgd-pgd-64-RandomForest_test_result.csv\n",
      "  adding: df-bim-32-RandomForest_test_result.csv\n",
      "  adding: bim-fgsm-32-LogisticRegression_test_result.csv\n",
      "  adding: cw-fgsm-128-RandomForest_test_result.csv\n",
      "  adding: fgsm-df-128-RandomForest_test_result.csv\n",
      "  adding: bim-bim-64-RandomForest_test_result.csv\n",
      "  adding: cw-cw-64-RandomForest_test_result.csv\n",
      "  adding: cw-df-128-LogisticRegression_test_result.csv\n",
      "  adding: bim-fgsm-64-LogisticRegression_test_result.csv\n",
      "  adding: cw-pgd-128-RandomForest_test_result.csv\n",
      "  adding: cw-fgsm-32-RandomForest_test_result.csv\n",
      "  adding: bim-fgsm-32-RandomForest_test_result.csv\n",
      "  adding: bim-fgsm-128-RandomForest_test_result.csv\n",
      "  adding: fgsm-cw-64-RandomForest_test_result.csv\n",
      "  adding: cw-df-128-RandomForest_test_result.csv\n",
      "  adding: cw-cw-32-LogisticRegression_test_result.csv\n",
      "  adding: df-cw-64-RandomForest_test_result.csv\n",
      "  adding: fgsm-df-32-RandomForest_test_result.csv\n",
      "  adding: fgsm-fgsm-32-RandomForest_test_result.csv\n",
      "  adding: pgd-pgd-32-RandomForest_test_result.csv\n",
      "  adding: bim-pgd-128-LogisticRegression_test_result.csv\n",
      "  adding: fgsm-cw-128-RandomForest_test_result.csv\n",
      "  adding: cw-pgd-64-RandomForest_test_result.csv\n",
      "  adding: cw-pgd-32-RandomForest_test_result.csv\n",
      "  adding: cw-bim-64-RandomForest_test_result.csv\n",
      "  adding: bim-pgd-32-RandomForest_test_result.csv\n",
      "  adding: df-cw-128-RandomForest_test_result.csv\n",
      "  adding: cw-bim-32-LogisticRegression_test_result.csv\n",
      "  adding: fgsm-pgd-32-LogisticRegression_test_result.csv\n",
      "  adding: bim-df-128-LogisticRegression_test_result.csv\n",
      "  adding: fgsm-df-32-LogisticRegression_test_result.csv\n",
      "Computing per-file SHA-256 and writing manifest: /kaggle/working/manifest-eval-sha256.txt\n",
      "Done.\n",
      "Created: /kaggle/working/evals.zip\n",
      "Created: /kaggle/working/manifest-eval-sha256.txt\n",
      "Created: /kaggle/working/evals.zip.sha256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10/2260558218.py:60: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  mf.write(f\"# manifest generated: {datetime.utcnow().isoformat()}Z\\n\")\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------------\n",
    "# Config\n",
    "# -------------------------------\n",
    "input_dir = Path(\"/kaggle/working/eval\")\n",
    "output_zip = Path(\"/kaggle/working/evals.zip\")\n",
    "manifest_path = Path(\"/kaggle/working/manifest-eval-sha256.txt\")\n",
    "chunk_size = 8 * 1024 * 1024  # 8 MB\n",
    "skip_files = {output_zip.name, manifest_path.name}\n",
    "\n",
    "# -------------------------------\n",
    "# Helper: compute SHA256\n",
    "# -------------------------------\n",
    "def sha256_of_file(path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with path.open(\"rb\") as f:\n",
    "        while True:\n",
    "            chunk = f.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "# -------------------------------\n",
    "# Collect files to zip\n",
    "# -------------------------------\n",
    "files_to_add = []\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for fname in files:\n",
    "        full = Path(root) / fname\n",
    "        rel = full.relative_to(input_dir)\n",
    "        rel_str = str(rel).replace(os.sep, \"/\")\n",
    "        if rel.name in skip_files:\n",
    "            continue\n",
    "        files_to_add.append((full, rel))\n",
    "\n",
    "if not files_to_add:\n",
    "    print(f\"No files found in {input_dir} to archive.\")\n",
    "else:\n",
    "    # -------------------------------\n",
    "    # Create zip\n",
    "    # -------------------------------\n",
    "    print(f\"Creating zip: {output_zip}\")\n",
    "    with zipfile.ZipFile(output_zip, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        for full, rel in files_to_add:\n",
    "            arcname = str(rel).replace(os.sep, \"/\")\n",
    "            print(f\"  adding: {arcname}\")\n",
    "            zf.write(full, arcname=arcname)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Create manifest\n",
    "    # -------------------------------\n",
    "    print(f\"Computing per-file SHA-256 and writing manifest: {manifest_path}\")\n",
    "    with manifest_path.open(\"w\", encoding=\"utf-8\") as mf:\n",
    "        mf.write(f\"# manifest generated: {datetime.utcnow().isoformat()}Z\\n\")\n",
    "        mf.write(f\"# input_dir: {input_dir}\\n\")\n",
    "        mf.write(\"# format: <sha256>  <relative/path>\\n\")\n",
    "        for full, rel in files_to_add:\n",
    "            rel_unix = str(rel).replace(os.sep, \"/\")\n",
    "            h = sha256_of_file(full)\n",
    "            size = full.stat().st_size\n",
    "            mf.write(f\"{h}  {rel_unix}  # {size} bytes\\n\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Compute zip SHA256\n",
    "    # -------------------------------\n",
    "    zip_hash = sha256_of_file(output_zip)\n",
    "    ziphash_path = output_zip.with_suffix(output_zip.suffix + \".sha256\")\n",
    "    with ziphash_path.open(\"w\", encoding=\"utf-8\") as zh:\n",
    "        zh.write(f\"{zip_hash}  {output_zip.name}\\n\")\n",
    "\n",
    "    print(\"Done.\")\n",
    "    print(f\"Created: {output_zip}\")\n",
    "    print(f\"Created: {manifest_path}\")\n",
    "    print(f\"Created: {ziphash_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T18:49:31.440087Z",
     "iopub.status.busy": "2025-10-20T18:49:31.439780Z",
     "iopub.status.idle": "2025-10-20T18:49:31.460714Z",
     "shell.execute_reply": "2025-10-20T18:49:31.459814Z",
     "shell.execute_reply.started": "2025-10-20T18:49:31.440070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating zip: /kaggle/working/evals-VALSET.zip\n",
      "  adding: cw-cw-64-LogisticRegression_test_result.csv\n",
      "  adding: pgd-pgd-32-RandomForest_test_result_predictions.csv\n",
      "  adding: fgsm-fgsm-32-LogisticRegression_test_result_predictions.csv\n",
      "  adding: bim-bim-128-LogisticRegression_test_result.csv\n",
      "  adding: pgd-pgd-64-LogisticRegression_test_result_predictions.csv\n",
      "  adding: cw-cw-128-LogisticRegression_test_result_predictions.csv\n",
      "  adding: fgsm-fgsm-64-RandomForest_test_result.csv\n",
      "  adding: bim-bim-32-LogisticRegression_test_result.csv\n",
      "  adding: pgd-pgd-64-LogisticRegression_test_result.csv\n",
      "  adding: fgsm-fgsm-64-LogisticRegression_test_result.csv\n",
      "  adding: cw-cw-32-LogisticRegression_test_result_predictions.csv\n",
      "  adding: bim-bim-64-LogisticRegression_test_result_predictions.csv\n",
      "  adding: pgd-pgd-128-LogisticRegression_test_result.csv\n",
      "  adding: df-df-64-RandomForest_test_result.csv\n",
      "  adding: fgsm-fgsm-128-RandomForest_test_result_predictions.csv\n",
      "  adding: bim-bim-32-RandomForest_test_result.csv\n",
      "  adding: fgsm-fgsm-64-RandomForest_test_result_predictions.csv\n",
      "  adding: df-df-32-LogisticRegression_test_result.csv\n",
      "  adding: fgsm-fgsm-128-RandomForest_test_result.csv\n",
      "  adding: pgd-pgd-32-LogisticRegression_test_result.csv\n",
      "  adding: df-df-128-RandomForest_test_result_predictions.csv\n",
      "  adding: df-df-64-RandomForest_test_result_predictions.csv\n",
      "  adding: cw-cw-64-RandomForest_test_result_predictions.csv\n",
      "  adding: fgsm-fgsm-32-LogisticRegression_test_result.csv\n",
      "  adding: fgsm-fgsm-128-LogisticRegression_test_result.csv\n",
      "  adding: cw-cw-64-LogisticRegression_test_result_predictions.csv\n",
      "  adding: df-df-128-LogisticRegression_test_result_predictions.csv\n",
      "  adding: bim-bim-128-LogisticRegression_test_result_predictions.csv\n",
      "  adding: bim-bim-128-RandomForest_test_result_predictions.csv\n",
      "  adding: df-df-128-RandomForest_test_result.csv\n",
      "  adding: df-df-32-RandomForest_test_result_predictions.csv\n",
      "  adding: pgd-pgd-128-RandomForest_test_result_predictions.csv\n",
      "  adding: bim-bim-32-RandomForest_test_result_predictions.csv\n",
      "  adding: pgd-pgd-128-RandomForest_test_result.csv\n",
      "  adding: bim-bim-64-RandomForest_test_result_predictions.csv\n",
      "  adding: bim-bim-128-RandomForest_test_result.csv\n",
      "  adding: fgsm-fgsm-128-LogisticRegression_test_result_predictions.csv\n",
      "  adding: df-df-64-LogisticRegression_test_result.csv\n",
      "  adding: cw-cw-128-RandomForest_test_result_predictions.csv\n",
      "  adding: cw-cw-128-LogisticRegression_test_result.csv\n",
      "  adding: bim-bim-64-LogisticRegression_test_result.csv\n",
      "  adding: df-df-64-LogisticRegression_test_result_predictions.csv\n",
      "  adding: fgsm-fgsm-32-RandomForest_test_result_predictions.csv\n",
      "  adding: pgd-pgd-32-LogisticRegression_test_result_predictions.csv\n",
      "  adding: bim-bim-32-LogisticRegression_test_result_predictions.csv\n",
      "  adding: df-df-32-RandomForest_test_result.csv\n",
      "  adding: df-df-128-LogisticRegression_test_result.csv\n",
      "  adding: cw-cw-32-RandomForest_test_result.csv\n",
      "  adding: cw-cw-128-RandomForest_test_result.csv\n",
      "  adding: pgd-pgd-64-RandomForest_test_result.csv\n",
      "  adding: bim-bim-64-RandomForest_test_result.csv\n",
      "  adding: cw-cw-64-RandomForest_test_result.csv\n",
      "  adding: df-df-32-LogisticRegression_test_result_predictions.csv\n",
      "  adding: fgsm-fgsm-64-LogisticRegression_test_result_predictions.csv\n",
      "  adding: cw-cw-32-LogisticRegression_test_result.csv\n",
      "  adding: pgd-pgd-64-RandomForest_test_result_predictions.csv\n",
      "  adding: fgsm-fgsm-32-RandomForest_test_result.csv\n",
      "  adding: pgd-pgd-32-RandomForest_test_result.csv\n",
      "  adding: pgd-pgd-128-LogisticRegression_test_result_predictions.csv\n",
      "  adding: cw-cw-32-RandomForest_test_result_predictions.csv\n",
      "Computing per-file SHA-256 and writing manifest: /kaggle/working/manifest-evals-VALSET-sha256.txt\n",
      "Done.\n",
      "Created: /kaggle/working/evals-VALSET.zip\n",
      "Created: /kaggle/working/manifest-evals-VALSET-sha256.txt\n",
      "Created: /kaggle/working/evals-VALSET.zip.sha256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10/3829959068.py:60: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  mf.write(f\"# manifest generated: {datetime.utcnow().isoformat()}Z\\n\")\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------------\n",
    "# Config\n",
    "# -------------------------------\n",
    "input_dir = Path(\"/kaggle/working/eval-VALSET\")\n",
    "output_zip = Path(\"/kaggle/working/evals-VALSET.zip\")\n",
    "manifest_path = Path(\"/kaggle/working/manifest-evals-VALSET-sha256.txt\")\n",
    "chunk_size = 8 * 1024 * 1024  # 8 MB\n",
    "skip_files = {output_zip.name, manifest_path.name}\n",
    "\n",
    "# -------------------------------\n",
    "# Helper: compute SHA256\n",
    "# -------------------------------\n",
    "def sha256_of_file(path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with path.open(\"rb\") as f:\n",
    "        while True:\n",
    "            chunk = f.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "# -------------------------------\n",
    "# Collect files to zip\n",
    "# -------------------------------\n",
    "files_to_add = []\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for fname in files:\n",
    "        full = Path(root) / fname\n",
    "        rel = full.relative_to(input_dir)\n",
    "        rel_str = str(rel).replace(os.sep, \"/\")\n",
    "        if rel.name in skip_files:\n",
    "            continue\n",
    "        files_to_add.append((full, rel))\n",
    "\n",
    "if not files_to_add:\n",
    "    print(f\"No files found in {input_dir} to archive.\")\n",
    "else:\n",
    "    # -------------------------------\n",
    "    # Create zip\n",
    "    # -------------------------------\n",
    "    print(f\"Creating zip: {output_zip}\")\n",
    "    with zipfile.ZipFile(output_zip, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        for full, rel in files_to_add:\n",
    "            arcname = str(rel).replace(os.sep, \"/\")\n",
    "            print(f\"  adding: {arcname}\")\n",
    "            zf.write(full, arcname=arcname)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Create manifest\n",
    "    # -------------------------------\n",
    "    print(f\"Computing per-file SHA-256 and writing manifest: {manifest_path}\")\n",
    "    with manifest_path.open(\"w\", encoding=\"utf-8\") as mf:\n",
    "        mf.write(f\"# manifest generated: {datetime.utcnow().isoformat()}Z\\n\")\n",
    "        mf.write(f\"# input_dir: {input_dir}\\n\")\n",
    "        mf.write(\"# format: <sha256>  <relative/path>\\n\")\n",
    "        for full, rel in files_to_add:\n",
    "            rel_unix = str(rel).replace(os.sep, \"/\")\n",
    "            h = sha256_of_file(full)\n",
    "            size = full.stat().st_size\n",
    "            mf.write(f\"{h}  {rel_unix}  # {size} bytes\\n\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Compute zip SHA256\n",
    "    # -------------------------------\n",
    "    zip_hash = sha256_of_file(output_zip)\n",
    "    ziphash_path = output_zip.with_suffix(output_zip.suffix + \".sha256\")\n",
    "    with ziphash_path.open(\"w\", encoding=\"utf-8\") as zh:\n",
    "        zh.write(f\"{zip_hash}  {output_zip.name}\\n\")\n",
    "\n",
    "    print(\"Done.\")\n",
    "    print(f\"Created: {output_zip}\")\n",
    "    print(f\"Created: {manifest_path}\")\n",
    "    print(f\"Created: {ziphash_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T18:43:29.231843Z",
     "iopub.status.busy": "2025-10-20T18:43:29.231629Z",
     "iopub.status.idle": "2025-10-20T18:43:29.247041Z",
     "shell.execute_reply": "2025-10-20T18:43:29.246345Z",
     "shell.execute_reply.started": "2025-10-20T18:43:29.231827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 510185)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "def clear_eval_dir(target: str = \"/kaggle/working/eval\") -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Remove all items directly under `target` (keeps the target directory).\n",
    "    No confirmation, no prompts.\n",
    "\n",
    "    Returns:\n",
    "        (removed_count, approx_removed_bytes)\n",
    "    \"\"\"\n",
    "    p = Path(target)\n",
    "    if not p.exists() or not p.is_dir():\n",
    "        return 0, 0\n",
    "\n",
    "    removed_count = 0\n",
    "    removed_bytes = 0\n",
    "\n",
    "    for child in p.iterdir():\n",
    "        try:\n",
    "            if child.is_dir() and not child.is_symlink():\n",
    "                # estimate size (best-effort) then remove directory tree\n",
    "                size = 0\n",
    "                for root, _, files in os.walk(child, followlinks=False):\n",
    "                    for f in files:\n",
    "                        try:\n",
    "                            size += (Path(root) / f).stat().st_size\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                shutil.rmtree(child)\n",
    "                removed_bytes += size\n",
    "            else:\n",
    "                try:\n",
    "                    removed_bytes += child.stat().st_size\n",
    "                except Exception:\n",
    "                    pass\n",
    "                child.unlink()\n",
    "            removed_count += 1\n",
    "        except Exception:\n",
    "            # ignore errors and continue\n",
    "            continue\n",
    "\n",
    "    return removed_count, removed_bytes\n",
    "\n",
    "clear_eval_dir('/kaggle/working/eval-VALSET')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpuV5e8",
   "dataSources": [
    {
     "datasetId": 8500680,
     "sourceId": 13395796,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8509378,
     "sourceId": 13408163,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31155,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
