{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f9b4b8-ce18-4623-83a5-0441baac1ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "\n",
    "def _save_json(p, obj):\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(p, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "\n",
    "def train_from_npy(\n",
    "    train_npy_path,\n",
    "    model_out_dir,\n",
    "    train_labels_npy_path,\n",
    "    random_seed=42,\n",
    "    mem_limit_bytes=100_000_000_000,\n",
    "    use_mmap=False,\n",
    "    classifier='LogisticRegression',\n",
    "    n_jobs = -1\n",
    "):\n",
    "    train_npy_path = Path(train_npy_path)\n",
    "    if not train_npy_path.exists():\n",
    "        raise FileNotFoundError(f\"Train npy not found: {train_npy_path}\")\n",
    "\n",
    "    model_out_dir = Path(model_out_dir)\n",
    "    model_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    X_train = np.load(str(train_npy_path), mmap_mode=\"r\" if use_mmap else None)\n",
    "    if X_train.ndim != 2:\n",
    "        raise RuntimeError(f\"train array must be 2D. got shape={X_train.shape}\")\n",
    "\n",
    "    labels_path = Path(train_labels_npy_path)\n",
    "    if not labels_path.exists():\n",
    "        raise FileNotFoundError(f\"Provided train_labels_npy_path does not exist: {labels_path}\")\n",
    "    y_train = np.load(str(labels_path), mmap_mode=\"r\" if use_mmap else None)\n",
    "    if y_train.shape[0] != X_train.shape[0]:\n",
    "        raise RuntimeError(f\"train labels length ({y_train.shape[0]}) != train rows ({X_train.shape[0]})\")\n",
    "\n",
    "    y_train = y_train.astype(np.int64)\n",
    "    unique = np.unique(y_train)\n",
    "    if unique.size != 2 or not np.array_equal(np.sort(unique), np.array([0, 1])):\n",
    "        raise RuntimeError(f\"train labels must contain exactly two classes 0 and 1. found: {unique}\")\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "\n",
    "    estimated_bytes = getattr(X_train, \"nbytes\", X_train.size * X_train.itemsize)\n",
    "    if estimated_bytes > mem_limit_bytes:\n",
    "        raise MemoryError(\n",
    "            f\"Estimated train bytes {estimated_bytes} > mem_limit_bytes {mem_limit_bytes}. \"\n",
    "            \"Either increase mem_limit_bytes, reduce dataset size, or use use_mmap=True and implement chunked/out-of-core training.\"\n",
    "        )\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    if classifier == 'LogisticRegression':\n",
    "        print ('Using LogisticRegression as classifier')\n",
    "        clf = LogisticRegression(random_state=random_seed, n_jobs=n_jobs, verbose=1)\n",
    "    elif classifier == 'RandomForest':\n",
    "        print ('Using RandomForest as classifier')\n",
    "        clf = RandomForestClassifier(random_state=random_seed, n_jobs=n_jobs, verbose=1)\n",
    "    else:\n",
    "        print ('Using SVC as classifier')\n",
    "        clf = SVC(random_state=random_seed, verbose=0)\n",
    "\n",
    "    pipeline = Pipeline([(\"scaler\", scaler), (\"clf\", clf)])\n",
    "\n",
    "    print(f\"Fitting pipeline\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    try:\n",
    "        y_pred_train, y_score_train = _predict_and_score(pipeline, None, None, X_train)\n",
    "        train_metrics = _compute_metrics(y_train, y_pred_train, y_score_train)\n",
    "\n",
    "        print(\"TRAIN Eval results:\")\n",
    "        print(f\"  acc={train_metrics['accuracy']:.4f}  prec={train_metrics['precision']:.4f}  \"\n",
    "              f\"recall={train_metrics['recall']:.4f}  f1={train_metrics['f1']:.4f}\")\n",
    "        if train_metrics.get(\"roc_auc\") is not None:\n",
    "            print(f\"  roc_auc={train_metrics['roc_auc']:.4f}\")\n",
    "        print(\"  confusion_matrix:\", train_metrics[\"confusion_matrix\"])\n",
    "    except Exception as e:\n",
    "\n",
    "        print(\"Warning: failed to compute train metrics:\", e)\n",
    "        train_metrics = None\n",
    "\n",
    "    pipeline_path = model_out_dir / \"pipeline.joblib\"\n",
    "    scaler_path = model_out_dir / \"scaler.joblib\"\n",
    "    clf_path = model_out_dir / \"clf.joblib\"\n",
    "    meta_out = model_out_dir / \"train_meta.json\"\n",
    "\n",
    "    joblib.dump(pipeline, pipeline_path)\n",
    "    joblib.dump(pipeline.named_steps[\"scaler\"], scaler_path)\n",
    "    joblib.dump(pipeline.named_steps[\"clf\"], clf_path)\n",
    "\n",
    "    meta_obj = {\n",
    "        \"train_npy\": str(train_npy_path),\n",
    "        \"train_labels_npy\": str(train_labels_npy_path),\n",
    "        \"train_rows\": int(X_train.shape[0]),\n",
    "        \"C\": None,\n",
    "        \"random_seed\": int(random_seed),\n",
    "        \"use_mmap\": bool(use_mmap),\n",
    "        # store train metrics (or null) so you have a record\n",
    "        \"train_metrics\": train_metrics,\n",
    "    }\n",
    "    _save_json(meta_out, meta_obj)\n",
    "\n",
    "    print(\"Saved pipeline ->\", pipeline_path)\n",
    "    print(\"Saved scaler ->\", scaler_path)\n",
    "    print(\"Saved classifier ->\", clf_path)\n",
    "    return str(model_out_dir)\n",
    "\n",
    "def _load_model(model_out_dir):\n",
    "    \"\"\"Load pipeline if present, else scaler+clf. Returns (pipeline, scaler, clf).\"\"\"\n",
    "    model_out_dir = Path(model_out_dir)\n",
    "    pipeline_path = model_out_dir / \"pipeline.joblib\"\n",
    "    scaler_path = model_out_dir / \"scaler.joblib\"\n",
    "    clf_path = model_out_dir / \"clf.joblib\"\n",
    "\n",
    "    pipeline = None\n",
    "    scaler = None\n",
    "    clf = None\n",
    "\n",
    "    if pipeline_path.exists():\n",
    "        pipeline = joblib.load(pipeline_path)\n",
    "    else:\n",
    "        if scaler_path.exists():\n",
    "            scaler = joblib.load(scaler_path)\n",
    "        if clf_path.exists():\n",
    "            clf = joblib.load(clf_path)\n",
    "        if scaler is None or clf is None:\n",
    "            raise FileNotFoundError(\"Could not find pipeline or scaler+clf in model_out_dir.\")\n",
    "    return pipeline, scaler, clf\n",
    "\n",
    "\n",
    "def _compute_metrics(y_true, y_pred, y_score):\n",
    "    metrics = {}\n",
    "    metrics[\"accuracy\"] = float(accuracy_score(y_true, y_pred))\n",
    "    metrics[\"precision\"] = float(precision_score(y_true, y_pred, zero_division=0))\n",
    "    metrics[\"recall\"] = float(recall_score(y_true, y_pred, zero_division=0))\n",
    "    metrics[\"f1\"] = float(f1_score(y_true, y_pred, zero_division=0))\n",
    "    try:\n",
    "        if y_score is not None and len(np.unique(y_true)) == 2:\n",
    "            metrics[\"roc_auc\"] = float(roc_auc_score(y_true, y_score))\n",
    "        else:\n",
    "            metrics[\"roc_auc\"] = None\n",
    "    except Exception:\n",
    "        metrics[\"roc_auc\"] = None\n",
    "    metrics[\"confusion_matrix\"] = confusion_matrix(y_true, y_pred).tolist()\n",
    "    metrics[\"classification_report\"] = classification_report(y_true, y_pred, zero_division=0, output_dict=True)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def _predict_and_score(pipeline, scaler, clf, X_test):\n",
    "    y_score = None\n",
    "    if pipeline is not None:\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        if hasattr(pipeline, \"predict_proba\"):\n",
    "            try:\n",
    "                y_score = pipeline.predict_proba(X_test)[:, 1]\n",
    "            except Exception:\n",
    "                y_score = None\n",
    "        else:\n",
    "            try:\n",
    "                clf_ = pipeline.named_steps[\"clf\"]\n",
    "                scaler_ = pipeline.named_steps[\"scaler\"]\n",
    "                if hasattr(clf_, \"decision_function\"):\n",
    "                    y_score = clf_.decision_function(scaler_.transform(X_test))\n",
    "            except Exception:\n",
    "                y_score = None\n",
    "    else:\n",
    "        X_t = scaler.transform(X_test)\n",
    "        y_pred = clf.predict(X_t)\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            y_score = clf.predict_proba(X_t)[:, 1]\n",
    "        elif hasattr(clf, \"decision_function\"):\n",
    "            y_score = clf.decision_function(X_t)\n",
    "    return y_pred, y_score\n",
    "\n",
    "\n",
    "def eval_val_from_npy(\n",
    "    val_npy_path,\n",
    "    val_label_path,\n",
    "    model_out_dir=\"./models\",\n",
    "    return_predictions=False,\n",
    "    use_mmap=False,\n",
    "):\n",
    "    val_npy_path = Path(val_npy_path)\n",
    "    val_label_path = Path(val_label_path)\n",
    "    if not val_npy_path.exists():\n",
    "        raise FileNotFoundError(f\"val_npy not found: {val_clean_npy_path}\")\n",
    "\n",
    "    X_test = np.load(str(val_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n",
    "    y_test = np.load(str(val_label_path), mmap_mode=\"r\" if use_mmap else None).astype(np.uint8)\n",
    "    \n",
    "    if X_test.shape[0] != y_test.shape[0]:\n",
    "        raise RuntimeError(f\"val X rows ({X_test.shape[0]}) != val labels length ({y_test.shape[0]})\")\n",
    "\n",
    "    pipeline, scaler, clf = _load_model(model_out_dir)\n",
    "\n",
    "    y_pred, y_score = _predict_and_score(pipeline, scaler, clf, X_test)\n",
    "\n",
    "    metrics = _compute_metrics(y_test, y_pred, y_score)\n",
    "\n",
    "    print(\"VAL Eval results:\")\n",
    "    print(f\"  acc={metrics['accuracy']:.4f}  prec={metrics['precision']:.4f}  recall={metrics['recall']:.4f}  f1={metrics['f1']:.4f}\")\n",
    "    if metrics[\"roc_auc\"] is not None:\n",
    "        print(f\"  roc_auc={metrics['roc_auc']:.4f}\")\n",
    "    print(\"  confusion_matrix:\", metrics[\"confusion_matrix\"])\n",
    "\n",
    "    return {\n",
    "        \"metrics\": metrics,\n",
    "        \"y_true\": y_test if return_predictions else None,\n",
    "        \"y_pred\": y_pred if return_predictions else None,\n",
    "        \"y_score\": y_score if return_predictions else None,\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_test_from_npy(\n",
    "    test_clean_npy_path,\n",
    "    test_adv_npy_path=None,\n",
    "    model_out_dir=\"./models\",\n",
    "    test_labels_npy_path=None,\n",
    "    return_predictions=False,\n",
    "    use_mmap=False,\n",
    "):\n",
    "    test_clean_npy_path = Path(test_clean_npy_path)\n",
    "    if not test_clean_npy_path.exists():\n",
    "        raise FileNotFoundError(f\"test_clean npy not found: {test_clean_npy_path}\")\n",
    "\n",
    "    if test_adv_npy_path is None:\n",
    "        if test_labels_npy_path is None:\n",
    "            raise ValueError(\"Single-file mode requires test_labels_npy_path.\")\n",
    "        X_test = np.load(str(test_clean_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n",
    "        y_test = np.load(str(test_labels_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.uint8)\n",
    "        if X_test.shape[0] != y_test.shape[0]:\n",
    "            raise RuntimeError(f\"test X rows ({X_test.shape[0]}) != test labels length ({y_test.shape[0]})\")\n",
    "    else:\n",
    "        test_adv_npy_path = Path(test_adv_npy_path)\n",
    "        if not test_adv_npy_path.exists():\n",
    "            raise FileNotFoundError(f\"test_adv npy not found: {test_adv_npy_path}\")\n",
    "        X_clean = np.load(str(test_clean_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n",
    "        X_adv = np.load(str(test_adv_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n",
    "        X_test = np.vstack([X_clean, X_adv])\n",
    "        if test_labels_npy_path is not None:\n",
    "            y_test = np.load(str(test_labels_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.uint8)\n",
    "            if y_test.shape[0] != X_test.shape[0]:\n",
    "                raise RuntimeError(f\"test labels length ({y_test.shape[0]}) != stacked test rows ({X_test.shape[0]})\")\n",
    "        else:\n",
    "            y_test = np.concatenate([np.zeros(X_clean.shape[0], dtype=np.uint8),\n",
    "                                     np.ones(X_adv.shape[0], dtype=np.uint8)])\n",
    "\n",
    "    pipeline, scaler, clf = _load_model(model_out_dir)\n",
    "\n",
    "    y_pred, y_score = _predict_and_score(pipeline, scaler, clf, X_test)\n",
    "\n",
    "    metrics = _compute_metrics(y_test, y_pred, y_score)\n",
    "\n",
    "    print(\"TEST Eval results:\")\n",
    "    print(f\"  acc={metrics['accuracy']:.4f}  prec={metrics['precision']:.4f}  recall={metrics['recall']:.4f}  f1={metrics['f1']:.4f}\")\n",
    "    if metrics[\"roc_auc\"] is not None:\n",
    "        print(f\"  roc_auc={metrics['roc_auc']:.4f}\")\n",
    "    print(\"  confusion_matrix:\", metrics[\"confusion_matrix\"])\n",
    "\n",
    "    return {\n",
    "        \"metrics\": metrics,\n",
    "        \"y_true\": y_test if return_predictions else None,\n",
    "        \"y_pred\": y_pred if return_predictions else None,\n",
    "        \"y_score\": y_score if return_predictions else None,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c8fec-37b4-4d9b-b4c7-c69f2bf2410b",
   "metadata": {},
   "source": [
    "# Change the Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4aa5c77-77ff-4f08-ac44-6b6ff28cf5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "\n",
    "def _save_json(p, obj):\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(p, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "\n",
    "def train_from_npy(\n",
    "    train_npy_path,\n",
    "    model_out_dir,\n",
    "    train_labels_npy_path,\n",
    "    random_seed=42,\n",
    "    mem_limit_bytes=100_000_000_000,\n",
    "    use_mmap=False,\n",
    "    classifier='LogisticRegression'\n",
    "):\n",
    "    train_npy_path = Path(train_npy_path)\n",
    "    if not train_npy_path.exists():\n",
    "        raise FileNotFoundError(f\"Train npy not found: {train_npy_path}\")\n",
    "\n",
    "    model_out_dir = Path(model_out_dir)\n",
    "    model_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    X_train = np.load(str(train_npy_path), mmap_mode=\"r\" if use_mmap else None)\n",
    "    if X_train.ndim != 2:\n",
    "        raise RuntimeError(f\"train array must be 2D. got shape={X_train.shape}\")\n",
    "\n",
    "    labels_path = Path(train_labels_npy_path)\n",
    "    if not labels_path.exists():\n",
    "        raise FileNotFoundError(f\"Provided train_labels_npy_path does not exist: {labels_path}\")\n",
    "    y_train = np.load(str(labels_path), mmap_mode=\"r\" if use_mmap else None)\n",
    "    if y_train.shape[0] != X_train.shape[0]:\n",
    "        raise RuntimeError(f\"train labels length ({y_train.shape[0]}) != train rows ({X_train.shape[0]})\")\n",
    "\n",
    "    y_train = y_train.astype(np.int64)\n",
    "    unique = np.unique(y_train)\n",
    "    if unique.size != 2 or not np.array_equal(np.sort(unique), np.array([0, 1])):\n",
    "        raise RuntimeError(f\"train labels must contain exactly two classes 0 and 1. found: {unique}\")\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "\n",
    "    estimated_bytes = getattr(X_train, \"nbytes\", X_train.size * X_train.itemsize)\n",
    "    if estimated_bytes > mem_limit_bytes:\n",
    "        raise MemoryError(\n",
    "            f\"Estimated train bytes {estimated_bytes} > mem_limit_bytes {mem_limit_bytes}. \"\n",
    "            \"Either increase mem_limit_bytes, reduce dataset size, or use use_mmap=True and implement chunked/out-of-core training.\"\n",
    "        )\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    if classifier == 'LogisticRegression':\n",
    "        print ('Using LogisticRegression as classifier')\n",
    "        clf = LogisticRegression(random_state=random_seed, n_jobs=-1, verbose=1)\n",
    "    elif classifier == 'RandomForest':\n",
    "        print ('Using RandomForest as classifier')\n",
    "        clf = RandomForestClassifier(random_state=random_seed, n_jobs=-1, verbose=1)\n",
    "    else:\n",
    "        print ('Using SVC as classifier')\n",
    "        clf = SVC(random_state=random_seed, verbose=0)\n",
    "\n",
    "    pipeline = Pipeline([(\"scaler\", scaler), (\"clf\", clf)])\n",
    "\n",
    "    print(f\"Fitting pipeline\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    try:\n",
    "        y_pred_train, y_score_train = _predict_and_score(pipeline, None, None, X_train)\n",
    "        train_metrics = _compute_metrics(y_train, y_pred_train, y_score_train)\n",
    "\n",
    "        print(\"TRAIN Eval results:\")\n",
    "        print(f\"  acc={train_metrics['accuracy']:.4f}  prec={train_metrics['precision']:.4f}  \"\n",
    "              f\"recall={train_metrics['recall']:.4f}  f1={train_metrics['f1']:.4f}\")\n",
    "        if train_metrics.get(\"roc_auc\") is not None:\n",
    "            print(f\"  roc_auc={train_metrics['roc_auc']:.4f}\")\n",
    "        print(\"  confusion_matrix:\", train_metrics[\"confusion_matrix\"])\n",
    "    except Exception as e:\n",
    "\n",
    "        print(\"Warning: failed to compute train metrics:\", e)\n",
    "        train_metrics = None\n",
    "\n",
    "    pipeline_path = model_out_dir / \"pipeline.joblib\"\n",
    "    scaler_path = model_out_dir / \"scaler.joblib\"\n",
    "    clf_path = model_out_dir / \"clf.joblib\"\n",
    "    meta_out = model_out_dir / \"train_meta.json\"\n",
    "\n",
    "    joblib.dump(pipeline, pipeline_path)\n",
    "    joblib.dump(pipeline.named_steps[\"scaler\"], scaler_path)\n",
    "    joblib.dump(pipeline.named_steps[\"clf\"], clf_path)\n",
    "\n",
    "    meta_obj = {\n",
    "        \"train_npy\": str(train_npy_path),\n",
    "        \"train_labels_npy\": str(train_labels_npy_path),\n",
    "        \"train_rows\": int(X_train.shape[0]),\n",
    "        \"C\": None,\n",
    "        \"random_seed\": int(random_seed),\n",
    "        \"use_mmap\": bool(use_mmap),\n",
    "        # store train metrics (or null) so you have a record\n",
    "        \"train_metrics\": train_metrics,\n",
    "    }\n",
    "    _save_json(meta_out, meta_obj)\n",
    "\n",
    "    print(\"Saved pipeline ->\", pipeline_path)\n",
    "    print(\"Saved scaler ->\", scaler_path)\n",
    "    print(\"Saved classifier ->\", clf_path)\n",
    "    return str(model_out_dir)\n",
    "\n",
    "def _load_model(model_out_dir):\n",
    "    \"\"\"Load pipeline if present, else scaler+clf. Returns (pipeline, scaler, clf).\"\"\"\n",
    "    model_out_dir = Path(model_out_dir)\n",
    "    pipeline_path = model_out_dir / \"pipeline.joblib\"\n",
    "    scaler_path = model_out_dir / \"scaler.joblib\"\n",
    "    clf_path = model_out_dir / \"clf.joblib\"\n",
    "\n",
    "    pipeline = None\n",
    "    scaler = None\n",
    "    clf = None\n",
    "\n",
    "    if pipeline_path.exists():\n",
    "        pipeline = joblib.load(pipeline_path)\n",
    "    else:\n",
    "        if scaler_path.exists():\n",
    "            scaler = joblib.load(scaler_path)\n",
    "        if clf_path.exists():\n",
    "            clf = joblib.load(clf_path)\n",
    "        if scaler is None or clf is None:\n",
    "            raise FileNotFoundError(\"Could not find pipeline or scaler+clf in model_out_dir.\")\n",
    "    return pipeline, scaler, clf\n",
    "\n",
    "\n",
    "def _compute_metrics(y_true, y_pred, y_score):\n",
    "    metrics = {}\n",
    "    metrics[\"accuracy\"] = float(accuracy_score(y_true, y_pred))\n",
    "    metrics[\"precision\"] = float(precision_score(y_true, y_pred, zero_division=0))\n",
    "    metrics[\"recall\"] = float(recall_score(y_true, y_pred, zero_division=0))\n",
    "    metrics[\"f1\"] = float(f1_score(y_true, y_pred, zero_division=0))\n",
    "    try:\n",
    "        if y_score is not None and len(np.unique(y_true)) == 2:\n",
    "            metrics[\"roc_auc\"] = float(roc_auc_score(y_true, y_score))\n",
    "        else:\n",
    "            metrics[\"roc_auc\"] = None\n",
    "    except Exception:\n",
    "        metrics[\"roc_auc\"] = None\n",
    "    metrics[\"confusion_matrix\"] = confusion_matrix(y_true, y_pred).tolist()\n",
    "    metrics[\"classification_report\"] = classification_report(y_true, y_pred, zero_division=0, output_dict=True)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def _predict_and_score(pipeline, scaler, clf, X_test):\n",
    "    y_score = None\n",
    "    if pipeline is not None:\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        if hasattr(pipeline, \"predict_proba\"):\n",
    "            try:\n",
    "                y_score = pipeline.predict_proba(X_test)[:, 1]\n",
    "            except Exception:\n",
    "                y_score = None\n",
    "        else:\n",
    "            try:\n",
    "                clf_ = pipeline.named_steps[\"clf\"]\n",
    "                scaler_ = pipeline.named_steps[\"scaler\"]\n",
    "                if hasattr(clf_, \"decision_function\"):\n",
    "                    y_score = clf_.decision_function(scaler_.transform(X_test))\n",
    "            except Exception:\n",
    "                y_score = None\n",
    "    else:\n",
    "        X_t = scaler.transform(X_test)\n",
    "        y_pred = clf.predict(X_t)\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            y_score = clf.predict_proba(X_t)[:, 1]\n",
    "        elif hasattr(clf, \"decision_function\"):\n",
    "            y_score = clf.decision_function(X_t)\n",
    "    return y_pred, y_score\n",
    "\n",
    "\n",
    "def eval_val_from_npy(\n",
    "    val_npy_path,\n",
    "    val_label_path,\n",
    "    model_out_dir=\"./models\",\n",
    "    return_predictions=False,\n",
    "    use_mmap=False,\n",
    "    csv_path=None,  # <-- Added argument\n",
    "):\n",
    "    val_npy_path = Path(val_npy_path)\n",
    "    val_label_path = Path(val_label_path)\n",
    "    if not val_npy_path.exists():\n",
    "        raise FileNotFoundError(f\"val_npy not found: {val_npy_path}\")\n",
    "\n",
    "    X_test = np.load(str(val_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n",
    "    y_test = np.load(str(val_label_path), mmap_mode=\"r\" if use_mmap else None).astype(np.uint8)\n",
    "    \n",
    "    if X_test.shape[0] != y_test.shape[0]:\n",
    "        raise RuntimeError(f\"val X rows ({X_test.shape[0]}) != val labels length ({y_test.shape[0]})\")\n",
    "\n",
    "    pipeline, scaler, clf = _load_model(model_out_dir)\n",
    "\n",
    "    y_pred, y_score = _predict_and_score(pipeline, scaler, clf, X_test)\n",
    "\n",
    "    metrics = _compute_metrics(y_test, y_pred, y_score)\n",
    "\n",
    "    print(\"VAL Eval results:\")\n",
    "    print(f\"  acc={metrics['accuracy']:.4f}  prec={metrics['precision']:.4f}  recall={metrics['recall']:.4f}  f1={metrics['f1']:.4f}\")\n",
    "    if metrics[\"roc_auc\"] is not None:\n",
    "        print(f\"  roc_auc={metrics['roc_auc']:.4f}\")\n",
    "    print(\"  confusion_matrix:\", metrics[\"confusion_matrix\"])\n",
    "\n",
    "    if csv_path is not None:\n",
    "        csv_path = Path(csv_path)\n",
    "        csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        metrics_df = pd.DataFrame([metrics])\n",
    "        metrics_df.to_csv(csv_path, index=False)\n",
    "\n",
    "        if return_predictions:\n",
    "            preds_path = csv_path.with_name(csv_path.stem + \"_predictions.csv\")\n",
    "            preds_df = pd.DataFrame({\n",
    "                \"y_true\": y_test,\n",
    "                \"y_pred\": y_pred,\n",
    "                \"y_score\": y_score\n",
    "            })\n",
    "            preds_df.to_csv(preds_path, index=False)\n",
    "            print(f\"Predictions saved to: {preds_path}\")\n",
    "\n",
    "        print(f\"Metrics saved to: {csv_path}\")\n",
    "    return {\n",
    "        \"metrics\": metrics,\n",
    "        \"y_true\": y_test if return_predictions else None,\n",
    "        \"y_pred\": y_pred if return_predictions else None,\n",
    "        \"y_score\": y_score if return_predictions else None,\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_test_from_npy(\n",
    "    test_clean_npy_path,\n",
    "    test_adv_npy_path=None,\n",
    "    model_out_dir=\"./models\",\n",
    "    test_labels_npy_path=None,\n",
    "    return_predictions=False,\n",
    "    use_mmap=False,\n",
    "    csv_path=None,  \n",
    "):\n",
    "    test_clean_npy_path = Path(test_clean_npy_path)\n",
    "    if not test_clean_npy_path.exists():\n",
    "        raise FileNotFoundError(f\"test_clean npy not found: {test_clean_npy_path}\")\n",
    "\n",
    "    if test_adv_npy_path is None:\n",
    "        if test_labels_npy_path is None:\n",
    "            raise ValueError(\"Single-file mode requires test_labels_npy_path.\")\n",
    "        X_test = np.load(str(test_clean_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n",
    "        y_test = np.load(str(test_labels_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.uint8)\n",
    "        if X_test.shape[0] != y_test.shape[0]:\n",
    "            raise RuntimeError(f\"test X rows ({X_test.shape[0]}) != test labels length ({y_test.shape[0]})\")\n",
    "    else:\n",
    "        test_adv_npy_path = Path(test_adv_npy_path)\n",
    "        if not test_adv_npy_path.exists():\n",
    "            raise FileNotFoundError(f\"test_adv npy not found: {test_adv_npy_path}\")\n",
    "        X_clean = np.load(str(test_clean_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n",
    "        X_adv = np.load(str(test_adv_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n",
    "        X_test = np.vstack([X_clean, X_adv])\n",
    "        if test_labels_npy_path is not None:\n",
    "            y_test = np.load(str(test_labels_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.uint8)\n",
    "            if y_test.shape[0] != X_test.shape[0]:\n",
    "                raise RuntimeError(f\"test labels length ({y_test.shape[0]}) != stacked test rows ({X_test.shape[0]})\")\n",
    "        else:\n",
    "            y_test = np.concatenate([\n",
    "                np.zeros(X_clean.shape[0], dtype=np.uint8),\n",
    "                np.ones(X_adv.shape[0], dtype=np.uint8)\n",
    "            ])\n",
    "\n",
    "    pipeline, scaler, clf = _load_model(model_out_dir)\n",
    "    y_pred, y_score = _predict_and_score(pipeline, scaler, clf, X_test)\n",
    "    metrics = _compute_metrics(y_test, y_pred, y_score)\n",
    "\n",
    "    print(\"TEST Eval results:\")\n",
    "    print(f\"  acc={metrics['accuracy']:.4f}  prec={metrics['precision']:.4f}  recall={metrics['recall']:.4f}  f1={metrics['f1']:.4f}\")\n",
    "    if metrics[\"roc_auc\"] is not None:\n",
    "        print(f\"  roc_auc={metrics['roc_auc']:.4f}\")\n",
    "\n",
    "    if csv_path is not None:\n",
    "        csv_path = Path(csv_path)\n",
    "        csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        metrics_df = pd.DataFrame([metrics])\n",
    "        metrics_df.to_csv(csv_path, index=False)\n",
    "\n",
    "        if return_predictions:\n",
    "            preds_path = csv_path.with_name(csv_path.stem + \"_predictions.csv\")\n",
    "            preds_df = pd.DataFrame({\n",
    "                \"y_true\": y_test,\n",
    "                \"y_pred\": y_pred,\n",
    "                \"y_score\": y_score\n",
    "            })\n",
    "            preds_df.to_csv(preds_path, index=False)\n",
    "            print(f\"Predictions saved to: {preds_path}\")\n",
    "\n",
    "        print(f\"Metrics saved to: {csv_path}\")\n",
    "\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7101157-2b44-4b43-aa94-0a3068caf7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 512 - fgsm - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/fgsm-512-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/fgsm-512-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/fgsm-512-LogisticRegression/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/fgsm-512-LogisticRegression'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 512\n",
    "ATTACK = 'fgsm'\n",
    "classifier = 'LogisticRegression'\n",
    "\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"./{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"./{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=200_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier,\n",
    "                n_jobs = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ecf9345-76b5-45e8-b090-9c23a9ad3b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 512 - fgsm - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of 100 | elapsed:   12.3s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   14.4s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/fgsm-512-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/fgsm-512-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/fgsm-512-RandomForest/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/fgsm-512-RandomForest'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 512\n",
    "ATTACK = 'fgsm'\n",
    "classifier = 'RandomForest'\n",
    "\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"./{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"./{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=200_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6764621b-f302-4b77-b6b3-100e95c0131c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 512 - bim - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/bim-512-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/bim-512-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/bim-512-LogisticRegression/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/bim-512-LogisticRegression'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 512\n",
    "ATTACK = 'bim'\n",
    "classifier = 'LogisticRegression'\n",
    "\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"./{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"./{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=200_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bf007e4-f4ba-4f6f-8cd7-ba2c0677c5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 512 - bim - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of 100 | elapsed:    7.5s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    8.6s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/bim-512-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/bim-512-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/bim-512-RandomForest/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/bim-512-RandomForest'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 512\n",
    "ATTACK = 'bim'\n",
    "classifier = 'RandomForest'\n",
    "\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"./{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"./{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=200_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "774fb397-20a6-40af-b4e7-12aad6069467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 512 - pgd - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/pgd-512-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/pgd-512-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/pgd-512-LogisticRegression/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/pgd-512-LogisticRegression'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 512\n",
    "ATTACK = 'pgd'\n",
    "classifier = 'LogisticRegression'\n",
    "\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"./{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"./{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=200_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a815786-5638-465e-866a-5553ffb8a66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 512 - pgd - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of 100 | elapsed:    7.7s remaining:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    9.7s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/pgd-512-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/pgd-512-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/pgd-512-RandomForest/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/pgd-512-RandomForest'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 512\n",
    "ATTACK = 'pgd'\n",
    "classifier = 'RandomForest'\n",
    "\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"./{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"./{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=200_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b7f3049-84df-4824-8eb4-a542f4f42008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 512 - df - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/home/ubuntu/anaconda3/envs/kaggle_ml/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=0.9979  prec=1.0000  recall=0.9959  f1=0.9979\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [2, 484]]\n",
      "Saved pipeline -> models/df-512-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/df-512-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/df-512-LogisticRegression/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/df-512-LogisticRegression'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 512\n",
    "ATTACK = 'df'\n",
    "classifier = 'LogisticRegression'\n",
    "\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"./{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"./{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=200_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier,\n",
    "                n_jobs = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d4a09d9-e560-41e9-8741-e1a229069622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 512 - df - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of 100 | elapsed:   16.9s remaining:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   21.4s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/df-512-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/df-512-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/df-512-RandomForest/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/df-512-RandomForest'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 512\n",
    "ATTACK = 'df'\n",
    "classifier = 'RandomForest'\n",
    "\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"./{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"./{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=200_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e5bba8b-07c9-44c3-9ee1-4f808ac62270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 512 - cw - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/cw-512-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/cw-512-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/cw-512-LogisticRegression/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/cw-512-LogisticRegression'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 512\n",
    "ATTACK = 'cw'\n",
    "classifier = 'LogisticRegression'\n",
    "\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"./{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"./{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=200_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier,\n",
    "                n_jobs = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3d954ef-a371-45bf-8531-cf97c3eaa79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 512 - cw - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of 100 | elapsed:   16.8s remaining:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   21.4s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/cw-512-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/cw-512-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/cw-512-RandomForest/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/cw-512-RandomForest'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 512\n",
    "ATTACK = 'cw'\n",
    "classifier = 'RandomForest'\n",
    "\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"./{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"./{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=200_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75906032-b0e1-4c42-8447-d0276590bbdc",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a28b16-6610-46cb-a402-f382b964a190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Method: fgsm\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.8765  prec=0.8588  recall=0.9012  f1=0.8795\n",
      "  roc_auc=0.9482\n",
      "  confusion_matrix: [[69, 12], [8, 73]]\n",
      "Predictions saved to: eval-VALSET/fgsm-fgsm-512-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/fgsm-fgsm-512-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.8765432098765432, 'precision': 0.8588235294117647, 'recall': 0.9012345679012346, 'f1': 0.8795180722891566, 'roc_auc': 0.9481786313062033, 'confusion_matrix': [[69, 12], [8, 73]], 'classification_report': {'0': {'precision': 0.8961038961038961, 'recall': 0.8518518518518519, 'f1-score': 0.8734177215189873, 'support': 81.0}, '1': {'precision': 0.8588235294117647, 'recall': 0.9012345679012346, 'f1-score': 0.8795180722891566, 'support': 81.0}, 'accuracy': 0.8765432098765432, 'macro avg': {'precision': 0.8774637127578304, 'recall': 0.8765432098765432, 'f1-score': 0.876467896904072, 'support': 162.0}, 'weighted avg': {'precision': 0.8774637127578304, 'recall': 0.8765432098765432, 'f1-score': 0.876467896904072, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.9259  prec=0.9157  recall=0.9383  f1=0.9268\n",
      "  roc_auc=0.9561\n",
      "  confusion_matrix: [[74, 7], [5, 76]]\n",
      "Predictions saved to: eval-VALSET/fgsm-fgsm-512-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/fgsm-fgsm-512-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.9259259259259259, 'precision': 0.9156626506024096, 'recall': 0.9382716049382716, 'f1': 0.926829268292683, 'roc_auc': 0.9561042524005487, 'confusion_matrix': [[74, 7], [5, 76]], 'classification_report': {'0': {'precision': 0.9367088607594937, 'recall': 0.9135802469135802, 'f1-score': 0.925, 'support': 81.0}, '1': {'precision': 0.9156626506024096, 'recall': 0.9382716049382716, 'f1-score': 0.926829268292683, 'support': 81.0}, 'accuracy': 0.9259259259259259, 'macro avg': {'precision': 0.9261857556809516, 'recall': 0.9259259259259258, 'f1-score': 0.9259146341463416, 'support': 162.0}, 'weighted avg': {'precision': 0.9261857556809516, 'recall': 0.9259259259259259, 'f1-score': 0.9259146341463415, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: bim\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[81, 0], [0, 81]]\n",
      "Predictions saved to: eval-VALSET/bim-bim-512-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/bim-bim-512-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'roc_auc': 1.0, 'confusion_matrix': [[81, 0], [0, 81]], 'classification_report': {'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81.0}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[81, 0], [0, 81]]\n",
      "Predictions saved to: eval-VALSET/bim-bim-512-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/bim-bim-512-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'roc_auc': 0.9999999999999999, 'confusion_matrix': [[81, 0], [0, 81]], 'classification_report': {'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81.0}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: pgd\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[81, 0], [0, 81]]\n",
      "Predictions saved to: eval-VALSET/pgd-pgd-512-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/pgd-pgd-512-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'roc_auc': 1.0, 'confusion_matrix': [[81, 0], [0, 81]], 'classification_report': {'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81.0}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[81, 0], [0, 81]]\n",
      "Predictions saved to: eval-VALSET/pgd-pgd-512-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/pgd-pgd-512-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'roc_auc': 1.0, 'confusion_matrix': [[81, 0], [0, 81]], 'classification_report': {'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81.0}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: df\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.6049  prec=0.6133  recall=0.5679  f1=0.5897\n",
      "  roc_auc=0.6308\n",
      "  confusion_matrix: [[52, 29], [35, 46]]\n",
      "Predictions saved to: eval-VALSET/df-df-512-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/df-df-512-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.6049382716049383, 'precision': 0.6133333333333333, 'recall': 0.5679012345679012, 'f1': 0.5897435897435898, 'roc_auc': 0.6308489559518367, 'confusion_matrix': [[52, 29], [35, 46]], 'classification_report': {'0': {'precision': 0.5977011494252874, 'recall': 0.6419753086419753, 'f1-score': 0.6190476190476191, 'support': 81.0}, '1': {'precision': 0.6133333333333333, 'recall': 0.5679012345679012, 'f1-score': 0.5897435897435898, 'support': 81.0}, 'accuracy': 0.6049382716049383, 'macro avg': {'precision': 0.6055172413793104, 'recall': 0.6049382716049383, 'f1-score': 0.6043956043956045, 'support': 162.0}, 'weighted avg': {'precision': 0.6055172413793103, 'recall': 0.6049382716049383, 'f1-score': 0.6043956043956044, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.5370  prec=0.5357  recall=0.5556  f1=0.5455\n",
      "  roc_auc=0.5435\n",
      "  confusion_matrix: [[42, 39], [36, 45]]\n",
      "Predictions saved to: eval-VALSET/df-df-512-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/df-df-512-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.5370370370370371, 'precision': 0.5357142857142857, 'recall': 0.5555555555555556, 'f1': 0.5454545454545454, 'roc_auc': 0.5435147081237616, 'confusion_matrix': [[42, 39], [36, 45]], 'classification_report': {'0': {'precision': 0.5384615384615384, 'recall': 0.5185185185185185, 'f1-score': 0.5283018867924528, 'support': 81.0}, '1': {'precision': 0.5357142857142857, 'recall': 0.5555555555555556, 'f1-score': 0.5454545454545454, 'support': 81.0}, 'accuracy': 0.5370370370370371, 'macro avg': {'precision': 0.5370879120879121, 'recall': 0.537037037037037, 'f1-score': 0.5368782161234991, 'support': 162.0}, 'weighted avg': {'precision': 0.5370879120879121, 'recall': 0.5370370370370371, 'f1-score': 0.5368782161234991, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: cw\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.5864  prec=0.5833  recall=0.6049  f1=0.5939\n",
      "  roc_auc=0.6427\n",
      "  confusion_matrix: [[46, 35], [32, 49]]\n",
      "Predictions saved to: eval-VALSET/cw-cw-512-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/cw-cw-512-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.5864197530864198, 'precision': 0.5833333333333334, 'recall': 0.6049382716049383, 'f1': 0.593939393939394, 'roc_auc': 0.6427373875933547, 'confusion_matrix': [[46, 35], [32, 49]], 'classification_report': {'0': {'precision': 0.5897435897435898, 'recall': 0.5679012345679012, 'f1-score': 0.5786163522012578, 'support': 81.0}, '1': {'precision': 0.5833333333333334, 'recall': 0.6049382716049383, 'f1-score': 0.593939393939394, 'support': 81.0}, 'accuracy': 0.5864197530864198, 'macro avg': {'precision': 0.5865384615384616, 'recall': 0.5864197530864197, 'f1-score': 0.586277873070326, 'support': 162.0}, 'weighted avg': {'precision': 0.5865384615384616, 'recall': 0.5864197530864198, 'f1-score': 0.5862778730703259, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.5864  prec=0.5972  recall=0.5309  f1=0.5621\n",
      "  roc_auc=0.6294\n",
      "  confusion_matrix: [[52, 29], [38, 43]]\n",
      "Predictions saved to: eval-VALSET/cw-cw-512-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/cw-cw-512-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.5864197530864198, 'precision': 0.5972222222222222, 'recall': 0.5308641975308642, 'f1': 0.5620915032679739, 'roc_auc': 0.6294010059442159, 'confusion_matrix': [[52, 29], [38, 43]], 'classification_report': {'0': {'precision': 0.5777777777777777, 'recall': 0.6419753086419753, 'f1-score': 0.6081871345029239, 'support': 81.0}, '1': {'precision': 0.5972222222222222, 'recall': 0.5308641975308642, 'f1-score': 0.5620915032679739, 'support': 81.0}, 'accuracy': 0.5864197530864198, 'macro avg': {'precision': 0.5874999999999999, 'recall': 0.5864197530864197, 'f1-score': 0.5851393188854489, 'support': 162.0}, 'weighted avg': {'precision': 0.5875, 'recall': 0.5864197530864198, 'f1-score': 0.585139318885449, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "ATTACKS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n",
    "classifiers = ['LogisticRegression', 'RandomForest']\n",
    "IMG_SIZE = 512\n",
    "for ATTACK in ATTACKS:\n",
    "    print (f'Attack Method: {ATTACK}\\n')\n",
    "    for classifier in classifiers:\n",
    "        print (f'\\n Classifier: {classifier}: \\n')\n",
    "        val_res = eval_val_from_npy(\n",
    "             val_npy_path = f\"./{ATTACK}/val_raw.npy\",\n",
    "             val_label_path = f\"./{ATTACK}/val_labels.npy\",\n",
    "             model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "             return_predictions=True,\n",
    "             use_mmap=False,\n",
    "             csv_path=f\"./eval-VALSET/{ATTACK}-{ATTACK}-{IMG_SIZE}-{classifier}_test_result.csv\"\n",
    "        )\n",
    "        print(\"val metrics:\", val_res[\"metrics\"])\n",
    "    print ('_____________________\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a80191c-94f3-4df4-862c-c1053905ed93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: fgsm \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.8841  prec=0.8889  recall=0.8780  f1=0.8834\n",
      "  roc_auc=0.9484\n",
      "Metrics saved to: eval/fgsm-fgsm-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: fgsm \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9512  prec=0.9625  recall=0.9390  f1=0.9506\n",
      "  roc_auc=0.9816\n",
      "Metrics saved to: eval/fgsm-fgsm-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: fgsm \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9329  prec=0.8989  recall=0.9756  f1=0.9357\n",
      "  roc_auc=0.9896\n",
      "Metrics saved to: eval/fgsm-bim-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: fgsm \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9146  prec=0.9595  recall=0.8659  f1=0.9103\n",
      "  roc_auc=0.9274\n",
      "Metrics saved to: eval/fgsm-bim-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: fgsm \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9146  prec=0.8953  recall=0.9390  f1=0.9167\n",
      "  roc_auc=0.9819\n",
      "Metrics saved to: eval/fgsm-pgd-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: fgsm \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.8963  prec=0.9577  recall=0.8293  f1=0.8889\n",
      "  roc_auc=0.9062\n",
      "Metrics saved to: eval/fgsm-pgd-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: fgsm \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4878  prec=0.4375  recall=0.0854  f1=0.1429\n",
      "  roc_auc=0.4920\n",
      "Metrics saved to: eval/fgsm-df-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: fgsm \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.0366  f1=0.0682\n",
      "  roc_auc=0.5314\n",
      "Metrics saved to: eval/fgsm-df-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: fgsm \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5244  prec=0.5909  recall=0.1585  f1=0.2500\n",
      "  roc_auc=0.5248\n",
      "Metrics saved to: eval/fgsm-cw-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: fgsm \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5061  prec=0.5714  recall=0.0488  f1=0.0899\n",
      "  roc_auc=0.5146\n",
      "Metrics saved to: eval/fgsm-cw-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: bim \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5671  prec=1.0000  recall=0.1341  f1=0.2366\n",
      "  roc_auc=0.8510\n",
      "Metrics saved to: eval/bim-fgsm-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: bim \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5122  prec=1.0000  recall=0.0244  f1=0.0476\n",
      "  roc_auc=0.7583\n",
      "Metrics saved to: eval/bim-fgsm-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: bim \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "Metrics saved to: eval/bim-bim-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: bim \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "Metrics saved to: eval/bim-bim-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: bim \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "Metrics saved to: eval/bim-pgd-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: bim \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "Metrics saved to: eval/bim-pgd-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: bim \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.4594\n",
      "Metrics saved to: eval/bim-df-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: bim \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.4300\n",
      "Metrics saved to: eval/bim-df-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: bim \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.5253\n",
      "Metrics saved to: eval/bim-cw-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: bim \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.4356\n",
      "Metrics saved to: eval/bim-cw-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: pgd \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5671  prec=1.0000  recall=0.1341  f1=0.2366\n",
      "  roc_auc=0.8488\n",
      "Metrics saved to: eval/pgd-fgsm-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: pgd \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5061  prec=1.0000  recall=0.0122  f1=0.0241\n",
      "  roc_auc=0.7623\n",
      "Metrics saved to: eval/pgd-fgsm-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: pgd \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "Metrics saved to: eval/pgd-bim-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: pgd \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "Metrics saved to: eval/pgd-bim-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: pgd \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "Metrics saved to: eval/pgd-pgd-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: pgd \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "Metrics saved to: eval/pgd-pgd-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: pgd \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.4582\n",
      "Metrics saved to: eval/pgd-df-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: pgd \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.4477\n",
      "Metrics saved to: eval/pgd-df-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: pgd \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.5232\n",
      "Metrics saved to: eval/pgd-cw-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: pgd \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.4897\n",
      "Metrics saved to: eval/pgd-cw-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: df \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.4207  prec=0.4133  recall=0.3780  f1=0.3949\n",
      "  roc_auc=0.4162\n",
      "Metrics saved to: eval/df-fgsm-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: df \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4329  prec=0.4321  recall=0.4268  f1=0.4294\n",
      "  roc_auc=0.3875\n",
      "Metrics saved to: eval/df-fgsm-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: df \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.2317  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.0004\n",
      "Metrics saved to: eval/df-bim-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: df \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.2683  prec=0.1481  recall=0.0976  f1=0.1176\n",
      "  roc_auc=0.1611\n",
      "Metrics saved to: eval/df-bim-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: df \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.2317  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.0001\n",
      "Metrics saved to: eval/df-pgd-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: df \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.2561  prec=0.1154  recall=0.0732  f1=0.0896\n",
      "  roc_auc=0.1572\n",
      "Metrics saved to: eval/df-pgd-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: df \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5427  prec=0.5368  recall=0.6220  f1=0.5763\n",
      "  roc_auc=0.6193\n",
      "Metrics saved to: eval/df-df-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: df \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5610  prec=0.5490  recall=0.6829  f1=0.6087\n",
      "  roc_auc=0.5492\n",
      "Metrics saved to: eval/df-df-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: df \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.5366  f1=0.5176\n",
      "  roc_auc=0.5757\n",
      "Metrics saved to: eval/df-cw-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: df \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5488  prec=0.5400  recall=0.6585  f1=0.5934\n",
      "  roc_auc=0.5354\n",
      "Metrics saved to: eval/df-cw-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: cw \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6951  prec=0.6702  recall=0.7683  f1=0.7159\n",
      "  roc_auc=0.7559\n",
      "Metrics saved to: eval/cw-fgsm-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: cw \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.7073  prec=0.6735  recall=0.8049  f1=0.7333\n",
      "  roc_auc=0.7789\n",
      "Metrics saved to: eval/cw-fgsm-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: cw \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.8110  prec=0.7257  recall=1.0000  f1=0.8410\n",
      "  roc_auc=0.9274\n",
      "Metrics saved to: eval/cw-bim-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: cw \n",
      " Dataset: bim \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.6890  prec=0.6632  recall=0.7683  f1=0.7119\n",
      "  roc_auc=0.7552\n",
      "Metrics saved to: eval/cw-bim-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: cw \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.7805  prec=0.7130  recall=0.9390  f1=0.8105\n",
      "  roc_auc=0.9024\n",
      "Metrics saved to: eval/cw-pgd-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: cw \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.6768  prec=0.6559  recall=0.7439  f1=0.6971\n",
      "  roc_auc=0.7316\n",
      "Metrics saved to: eval/cw-pgd-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: cw \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5305  prec=0.5373  recall=0.4390  f1=0.4832\n",
      "  roc_auc=0.5422\n",
      "Metrics saved to: eval/cw-df-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: cw \n",
      " Dataset: df \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5061  prec=0.5077  recall=0.4024  f1=0.4490\n",
      "  roc_auc=0.5127\n",
      "Metrics saved to: eval/cw-df-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: cw \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression\n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5976  prec=0.6026  recall=0.5732  f1=0.5875\n",
      "  roc_auc=0.6391\n",
      "Metrics saved to: eval/cw-cw-512-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 512) \n",
      " Method: cw \n",
      " Dataset: cw \n",
      " Classifier: RandomForest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.6280  prec=0.6235  recall=0.6463  f1=0.6347\n",
      "  roc_auc=0.6492\n",
      "Metrics saved to: eval/cw-cw-512-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "classifier = ['LogisticRegression', 'RandomForest']\n",
    "IMG_SIZES = 512\n",
    "\n",
    "ATTACKS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n",
    "DATASETS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n",
    "\n",
    "\n",
    "for ATTACK in ATTACKS:\n",
    "    for DATASET in DATASETS:\n",
    "        for classifier in classifiers:\n",
    "            print(f'Evaluate Against Test Set (Image Size: {IMG_SIZE}) \\n Method: {ATTACK} \\n Dataset: {DATASET} \\n Classifier: {classifier}\\n')\n",
    "            eval_test_from_npy(\n",
    "                test_clean_npy_path=f'./{DATASET}/test_clean_raw.npy',\n",
    "                test_adv_npy_path=f'./{DATASET}/test_adv_raw.npy',\n",
    "                model_out_dir=f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                test_labels_npy_path=None,\n",
    "                return_predictions=False,\n",
    "                use_mmap=False,\n",
    "                csv_path=f\"./eval/{ATTACK}-{DATASET}-{IMG_SIZE}-{classifier}_test_result.csv\"\n",
    "            )\n",
    "            print ('_________________________\\n')\n",
    "    \n",
    "        print ('===============================\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf837beb-c7aa-4a47-a44d-bd3b817abbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4595bf67-0aea-4795-b148-9d4b2b8b8b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
