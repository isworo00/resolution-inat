{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-20T12:32:27.993784Z",
     "iopub.status.busy": "2025-10-20T12:32:27.993398Z",
     "iopub.status.idle": "2025-10-20T12:32:28.016341Z",
     "shell.execute_reply": "2025-10-20T12:32:28.015590Z",
     "shell.execute_reply.started": "2025-10-20T12:32:27.993762Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "\n",
    "def _save_json(p, obj):\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(p, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "\n",
    "def train_from_npy(\n",
    "    train_npy_path,\n",
    "    model_out_dir,\n",
    "    train_labels_npy_path,\n",
    "    random_seed=42,\n",
    "    mem_limit_bytes=100_000_000_000,\n",
    "    use_mmap=False,\n",
    "    classifier='LogisticRegression'\n",
    "):\n",
    "    train_npy_path = Path(train_npy_path)\n",
    "    if not train_npy_path.exists():\n",
    "        raise FileNotFoundError(f\"Train npy not found: {train_npy_path}\")\n",
    "\n",
    "    model_out_dir = Path(model_out_dir)\n",
    "    model_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    X_train = np.load(str(train_npy_path), mmap_mode=\"r\" if use_mmap else None)\n",
    "    if X_train.ndim != 2:\n",
    "        raise RuntimeError(f\"train array must be 2D. got shape={X_train.shape}\")\n",
    "\n",
    "    labels_path = Path(train_labels_npy_path)\n",
    "    if not labels_path.exists():\n",
    "        raise FileNotFoundError(f\"Provided train_labels_npy_path does not exist: {labels_path}\")\n",
    "    y_train = np.load(str(labels_path), mmap_mode=\"r\" if use_mmap else None)\n",
    "    if y_train.shape[0] != X_train.shape[0]:\n",
    "        raise RuntimeError(f\"train labels length ({y_train.shape[0]}) != train rows ({X_train.shape[0]})\")\n",
    "\n",
    "    y_train = y_train.astype(np.int64)\n",
    "    unique = np.unique(y_train)\n",
    "    if unique.size != 2 or not np.array_equal(np.sort(unique), np.array([0, 1])):\n",
    "        raise RuntimeError(f\"train labels must contain exactly two classes 0 and 1. found: {unique}\")\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "\n",
    "    estimated_bytes = getattr(X_train, \"nbytes\", X_train.size * X_train.itemsize)\n",
    "    if estimated_bytes > mem_limit_bytes:\n",
    "        raise MemoryError(\n",
    "            f\"Estimated train bytes {estimated_bytes} > mem_limit_bytes {mem_limit_bytes}. \"\n",
    "            \"Either increase mem_limit_bytes, reduce dataset size, or use use_mmap=True and implement chunked/out-of-core training.\"\n",
    "        )\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    if classifier == 'LogisticRegression':\n",
    "        print ('Using LogisticRegression as classifier')\n",
    "        clf = LogisticRegression(random_state=random_seed, n_jobs=-1, verbose=1)\n",
    "    elif classifier == 'RandomForest':\n",
    "        print ('Using RandomForest as classifier')\n",
    "        clf = RandomForestClassifier(random_state=random_seed, n_jobs=-1, verbose=1)\n",
    "    else:\n",
    "        print ('Using SVC as classifier')\n",
    "        clf = SVC(random_state=random_seed, verbose=0)\n",
    "\n",
    "    pipeline = Pipeline([(\"scaler\", scaler), (\"clf\", clf)])\n",
    "\n",
    "    print(f\"Fitting pipeline\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    try:\n",
    "        y_pred_train, y_score_train = _predict_and_score(pipeline, None, None, X_train)\n",
    "        train_metrics = _compute_metrics(y_train, y_pred_train, y_score_train)\n",
    "\n",
    "        print(\"TRAIN Eval results:\")\n",
    "        print(f\"  acc={train_metrics['accuracy']:.4f}  prec={train_metrics['precision']:.4f}  \"\n",
    "              f\"recall={train_metrics['recall']:.4f}  f1={train_metrics['f1']:.4f}\")\n",
    "        if train_metrics.get(\"roc_auc\") is not None:\n",
    "            print(f\"  roc_auc={train_metrics['roc_auc']:.4f}\")\n",
    "        print(\"  confusion_matrix:\", train_metrics[\"confusion_matrix\"])\n",
    "    except Exception as e:\n",
    "\n",
    "        print(\"Warning: failed to compute train metrics:\", e)\n",
    "        train_metrics = None\n",
    "\n",
    "    pipeline_path = model_out_dir / \"pipeline.joblib\"\n",
    "    scaler_path = model_out_dir / \"scaler.joblib\"\n",
    "    clf_path = model_out_dir / \"clf.joblib\"\n",
    "    meta_out = model_out_dir / \"train_meta.json\"\n",
    "\n",
    "    joblib.dump(pipeline, pipeline_path)\n",
    "    joblib.dump(pipeline.named_steps[\"scaler\"], scaler_path)\n",
    "    joblib.dump(pipeline.named_steps[\"clf\"], clf_path)\n",
    "\n",
    "    meta_obj = {\n",
    "        \"train_npy\": str(train_npy_path),\n",
    "        \"train_labels_npy\": str(train_labels_npy_path),\n",
    "        \"train_rows\": int(X_train.shape[0]),\n",
    "        \"C\": None,\n",
    "        \"random_seed\": int(random_seed),\n",
    "        \"use_mmap\": bool(use_mmap),\n",
    "        \"train_metrics\": train_metrics,\n",
    "    }\n",
    "    _save_json(meta_out, meta_obj)\n",
    "\n",
    "    print(\"Saved pipeline ->\", pipeline_path)\n",
    "    print(\"Saved scaler ->\", scaler_path)\n",
    "    print(\"Saved classifier ->\", clf_path)\n",
    "    return str(model_out_dir)\n",
    "\n",
    "def _load_model(model_out_dir):\n",
    "    model_out_dir = Path(model_out_dir)\n",
    "    pipeline_path = model_out_dir / \"pipeline.joblib\"\n",
    "    scaler_path = model_out_dir / \"scaler.joblib\"\n",
    "    clf_path = model_out_dir / \"clf.joblib\"\n",
    "\n",
    "    pipeline = None\n",
    "    scaler = None\n",
    "    clf = None\n",
    "\n",
    "    if pipeline_path.exists():\n",
    "        pipeline = joblib.load(pipeline_path)\n",
    "    else:\n",
    "        if scaler_path.exists():\n",
    "            scaler = joblib.load(scaler_path)\n",
    "        if clf_path.exists():\n",
    "            clf = joblib.load(clf_path)\n",
    "        if scaler is None or clf is None:\n",
    "            raise FileNotFoundError(\"Could not find pipeline or scaler+clf in model_out_dir.\")\n",
    "    return pipeline, scaler, clf\n",
    "\n",
    "\n",
    "def _compute_metrics(y_true, y_pred, y_score):\n",
    "    metrics = {}\n",
    "    metrics[\"accuracy\"] = float(accuracy_score(y_true, y_pred))\n",
    "    metrics[\"precision\"] = float(precision_score(y_true, y_pred, zero_division=0))\n",
    "    metrics[\"recall\"] = float(recall_score(y_true, y_pred, zero_division=0))\n",
    "    metrics[\"f1\"] = float(f1_score(y_true, y_pred, zero_division=0))\n",
    "    try:\n",
    "        if y_score is not None and len(np.unique(y_true)) == 2:\n",
    "            metrics[\"roc_auc\"] = float(roc_auc_score(y_true, y_score))\n",
    "        else:\n",
    "            metrics[\"roc_auc\"] = None\n",
    "    except Exception:\n",
    "        metrics[\"roc_auc\"] = None\n",
    "    metrics[\"confusion_matrix\"] = confusion_matrix(y_true, y_pred).tolist()\n",
    "    metrics[\"classification_report\"] = classification_report(y_true, y_pred, zero_division=0, output_dict=True)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def _predict_and_score(pipeline, scaler, clf, X_test):\n",
    "    y_score = None\n",
    "    if pipeline is not None:\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        if hasattr(pipeline, \"predict_proba\"):\n",
    "            try:\n",
    "                y_score = pipeline.predict_proba(X_test)[:, 1]\n",
    "            except Exception:\n",
    "                y_score = None\n",
    "        else:\n",
    "            try:\n",
    "                clf_ = pipeline.named_steps[\"clf\"]\n",
    "                scaler_ = pipeline.named_steps[\"scaler\"]\n",
    "                if hasattr(clf_, \"decision_function\"):\n",
    "                    y_score = clf_.decision_function(scaler_.transform(X_test))\n",
    "            except Exception:\n",
    "                y_score = None\n",
    "    else:\n",
    "        X_t = scaler.transform(X_test)\n",
    "        y_pred = clf.predict(X_t)\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            y_score = clf.predict_proba(X_t)[:, 1]\n",
    "        elif hasattr(clf, \"decision_function\"):\n",
    "            y_score = clf.decision_function(X_t)\n",
    "    return y_pred, y_score\n",
    "\n",
    "\n",
    "def eval_val_from_npy(\n",
    "    val_npy_path,\n",
    "    val_label_path,\n",
    "    model_out_dir=\"./models\",\n",
    "    return_predictions=False,\n",
    "    use_mmap=False,\n",
    "    csv_path=None,  \n",
    "):\n",
    "    val_npy_path = Path(val_npy_path)\n",
    "    val_label_path = Path(val_label_path)\n",
    "    if not val_npy_path.exists():\n",
    "        raise FileNotFoundError(f\"val_npy not found: {val_npy_path}\")\n",
    "\n",
    "    X_test = np.load(str(val_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n",
    "    y_test = np.load(str(val_label_path), mmap_mode=\"r\" if use_mmap else None).astype(np.uint8)\n",
    "    \n",
    "    if X_test.shape[0] != y_test.shape[0]:\n",
    "        raise RuntimeError(f\"val X rows ({X_test.shape[0]}) != val labels length ({y_test.shape[0]})\")\n",
    "\n",
    "    pipeline, scaler, clf = _load_model(model_out_dir)\n",
    "\n",
    "    y_pred, y_score = _predict_and_score(pipeline, scaler, clf, X_test)\n",
    "\n",
    "    metrics = _compute_metrics(y_test, y_pred, y_score)\n",
    "\n",
    "    print(\"VAL Eval results:\")\n",
    "    print(f\"  acc={metrics['accuracy']:.4f}  prec={metrics['precision']:.4f}  recall={metrics['recall']:.4f}  f1={metrics['f1']:.4f}\")\n",
    "    if metrics[\"roc_auc\"] is not None:\n",
    "        print(f\"  roc_auc={metrics['roc_auc']:.4f}\")\n",
    "    print(\"  confusion_matrix:\", metrics[\"confusion_matrix\"])\n",
    "\n",
    "    if csv_path is not None:\n",
    "        csv_path = Path(csv_path)\n",
    "        csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        metrics_df = pd.DataFrame([metrics])\n",
    "        metrics_df.to_csv(csv_path, index=False)\n",
    "\n",
    "        if return_predictions:\n",
    "            preds_path = csv_path.with_name(csv_path.stem + \"_predictions.csv\")\n",
    "            preds_df = pd.DataFrame({\n",
    "                \"y_true\": y_test,\n",
    "                \"y_pred\": y_pred,\n",
    "                \"y_score\": y_score\n",
    "            })\n",
    "            preds_df.to_csv(preds_path, index=False)\n",
    "            print(f\"Predictions saved to: {preds_path}\")\n",
    "\n",
    "        print(f\"Metrics saved to: {csv_path}\")\n",
    "\n",
    "    return {\n",
    "        \"metrics\": metrics,\n",
    "        \"y_true\": y_test if return_predictions else None,\n",
    "        \"y_pred\": y_pred if return_predictions else None,\n",
    "        \"y_score\": y_score if return_predictions else None,\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_test_from_npy(\n",
    "    test_clean_npy_path,\n",
    "    test_adv_npy_path=None,\n",
    "    model_out_dir=\"./models\",\n",
    "    test_labels_npy_path=None,\n",
    "    return_predictions=False,\n",
    "    use_mmap=False,\n",
    "    csv_path=None,  \n",
    "):\n",
    "    test_clean_npy_path = Path(test_clean_npy_path)\n",
    "    if not test_clean_npy_path.exists():\n",
    "        raise FileNotFoundError(f\"test_clean npy not found: {test_clean_npy_path}\")\n",
    "\n",
    "    if test_adv_npy_path is None:\n",
    "        if test_labels_npy_path is None:\n",
    "            raise ValueError(\"Single-file mode requires test_labels_npy_path.\")\n",
    "        X_test = np.load(str(test_clean_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n",
    "        y_test = np.load(str(test_labels_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.uint8)\n",
    "        if X_test.shape[0] != y_test.shape[0]:\n",
    "            raise RuntimeError(f\"test X rows ({X_test.shape[0]}) != test labels length ({y_test.shape[0]})\")\n",
    "    else:\n",
    "        test_adv_npy_path = Path(test_adv_npy_path)\n",
    "        if not test_adv_npy_path.exists():\n",
    "            raise FileNotFoundError(f\"test_adv npy not found: {test_adv_npy_path}\")\n",
    "        X_clean = np.load(str(test_clean_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n",
    "        X_adv = np.load(str(test_adv_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.float32)\n",
    "        X_test = np.vstack([X_clean, X_adv])\n",
    "        if test_labels_npy_path is not None:\n",
    "            y_test = np.load(str(test_labels_npy_path), mmap_mode=\"r\" if use_mmap else None).astype(np.uint8)\n",
    "            if y_test.shape[0] != X_test.shape[0]:\n",
    "                raise RuntimeError(f\"test labels length ({y_test.shape[0]}) != stacked test rows ({X_test.shape[0]})\")\n",
    "        else:\n",
    "            y_test = np.concatenate([\n",
    "                np.zeros(X_clean.shape[0], dtype=np.uint8),\n",
    "                np.ones(X_adv.shape[0], dtype=np.uint8)\n",
    "            ])\n",
    "\n",
    "    pipeline, scaler, clf = _load_model(model_out_dir)\n",
    "    y_pred, y_score = _predict_and_score(pipeline, scaler, clf, X_test)\n",
    "    metrics = _compute_metrics(y_test, y_pred, y_score)\n",
    "\n",
    "    print(\"TEST Eval results:\")\n",
    "    print(f\"  acc={metrics['accuracy']:.4f}  prec={metrics['precision']:.4f}  recall={metrics['recall']:.4f}  f1={metrics['f1']:.4f}\")\n",
    "    if metrics[\"roc_auc\"] is not None:\n",
    "        print(f\"  roc_auc={metrics['roc_auc']:.4f}\")\n",
    "\n",
    "    if csv_path is not None:\n",
    "        csv_path = Path(csv_path)\n",
    "        csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        metrics_df = pd.DataFrame([metrics])\n",
    "        metrics_df.to_csv(csv_path, index=False)\n",
    "\n",
    "        if return_predictions:\n",
    "            preds_path = csv_path.with_name(csv_path.stem + \"_predictions.csv\")\n",
    "            preds_df = pd.DataFrame({\n",
    "                \"y_true\": y_test,\n",
    "                \"y_pred\": y_pred,\n",
    "                \"y_score\": y_score\n",
    "            })\n",
    "            preds_df.to_csv(preds_path, index=False)\n",
    "            print(f\"Predictions saved to: {preds_path}\")\n",
    "\n",
    "        print(f\"Metrics saved to: {csv_path}\")\n",
    "\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T20:18:31.735299Z",
     "iopub.status.busy": "2025-10-18T20:18:31.734793Z",
     "iopub.status.idle": "2025-10-18T20:21:04.508626Z",
     "shell.execute_reply": "2025-10-18T20:21:04.507598Z",
     "shell.execute_reply.started": "2025-10-18T20:18:31.735277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 256 - fgsm - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    1.8s remaining:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/fgsm-256-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/fgsm-256-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/fgsm-256-RandomForest/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/fgsm-256-RandomForest'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 256\n",
    "ATTACK =  'fgsm'\n",
    "classifier = 'RandomForest'\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=100_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T20:21:04.509645Z",
     "iopub.status.busy": "2025-10-18T20:21:04.509446Z",
     "iopub.status.idle": "2025-10-18T20:23:41.454532Z",
     "shell.execute_reply": "2025-10-18T20:23:41.453500Z",
     "shell.execute_reply.started": "2025-10-18T20:21:04.509627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 256 - bim - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    1.2s remaining:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/bim-256-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/bim-256-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/bim-256-RandomForest/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/bim-256-RandomForest'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 256\n",
    "ATTACK =  'bim'\n",
    "classifier = 'RandomForest'\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=100_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T20:23:41.455211Z",
     "iopub.status.busy": "2025-10-18T20:23:41.455044Z",
     "iopub.status.idle": "2025-10-18T20:26:21.444915Z",
     "shell.execute_reply": "2025-10-18T20:26:21.443787Z",
     "shell.execute_reply.started": "2025-10-18T20:23:41.455195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 256 - pgd - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    1.2s remaining:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/pgd-256-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/pgd-256-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/pgd-256-RandomForest/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/pgd-256-RandomForest'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 256\n",
    "ATTACK =  'pgd'\n",
    "classifier = 'RandomForest'\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=100_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T20:26:21.445767Z",
     "iopub.status.busy": "2025-10-18T20:26:21.445580Z",
     "iopub.status.idle": "2025-10-18T20:28:37.780894Z",
     "shell.execute_reply": "2025-10-18T20:28:37.779763Z",
     "shell.execute_reply.started": "2025-10-18T20:26:21.445751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 256 - df - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    2.3s remaining:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/df-256-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/df-256-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/df-256-RandomForest/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/df-256-RandomForest'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 256\n",
    "ATTACK =  'df'\n",
    "classifier = 'RandomForest'\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=100_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T20:28:37.781607Z",
     "iopub.status.busy": "2025-10-18T20:28:37.781442Z",
     "iopub.status.idle": "2025-10-18T20:30:55.916661Z",
     "shell.execute_reply": "2025-10-18T20:30:55.915594Z",
     "shell.execute_reply.started": "2025-10-18T20:28:37.781592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 256 - cw - RandomForest \n",
      "\n",
      "Using RandomForest as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:    2.2s remaining:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/cw-256-RandomForest/pipeline.joblib\n",
      "Saved scaler -> models/cw-256-RandomForest/scaler.joblib\n",
      "Saved classifier -> models/cw-256-RandomForest/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/cw-256-RandomForest'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 256\n",
    "ATTACK =  'cw'\n",
    "classifier = 'RandomForest'\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=100_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T20:30:55.917544Z",
     "iopub.status.busy": "2025-10-18T20:30:55.917352Z",
     "iopub.status.idle": "2025-10-18T20:32:18.834944Z",
     "shell.execute_reply": "2025-10-18T20:32:18.833830Z",
     "shell.execute_reply.started": "2025-10-18T20:30:55.917527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 256 - fgsm - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/fgsm-256-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/fgsm-256-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/fgsm-256-LogisticRegression/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/fgsm-256-LogisticRegression'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 256\n",
    "ATTACK =  'fgsm'\n",
    "classifier = 'LogisticRegression'\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=100_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T20:32:18.835639Z",
     "iopub.status.busy": "2025-10-18T20:32:18.835468Z",
     "iopub.status.idle": "2025-10-18T20:34:02.566686Z",
     "shell.execute_reply": "2025-10-18T20:34:02.565661Z",
     "shell.execute_reply.started": "2025-10-18T20:32:18.835624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 256 - bim - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/bim-256-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/bim-256-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/bim-256-LogisticRegression/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/bim-256-LogisticRegression'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 256\n",
    "ATTACK =  'bim'\n",
    "classifier = 'LogisticRegression'\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=100_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T20:34:30.303257Z",
     "iopub.status.busy": "2025-10-18T20:34:30.302906Z",
     "iopub.status.idle": "2025-10-18T20:36:51.419160Z",
     "shell.execute_reply": "2025-10-18T20:36:51.417913Z",
     "shell.execute_reply.started": "2025-10-18T20:34:30.303241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 256 - pgd - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/pgd-256-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/pgd-256-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/pgd-256-LogisticRegression/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/pgd-256-LogisticRegression'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 256\n",
    "ATTACK =  'pgd'\n",
    "classifier = 'LogisticRegression'\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=100_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T20:36:51.578010Z",
     "iopub.status.busy": "2025-10-18T20:36:51.577848Z",
     "iopub.status.idle": "2025-10-18T20:47:15.734734Z",
     "shell.execute_reply": "2025-10-18T20:47:15.733342Z",
     "shell.execute_reply.started": "2025-10-18T20:36:51.577995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 256 - df - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=0.9969  prec=0.9979  recall=0.9959  f1=0.9969\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[485, 1], [2, 484]]\n",
      "Saved pipeline -> models/df-256-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/df-256-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/df-256-LogisticRegression/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/df-256-LogisticRegression'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 256\n",
    "ATTACK =  'df'\n",
    "classifier = 'LogisticRegression'\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=100_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T20:53:12.639091Z",
     "iopub.status.busy": "2025-10-18T20:53:12.638700Z",
     "iopub.status.idle": "2025-10-18T21:00:57.065016Z",
     "shell.execute_reply": "2025-10-18T21:00:57.064151Z",
     "shell.execute_reply.started": "2025-10-18T20:53:12.639068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 256 - cw - LogisticRegression \n",
      "\n",
      "Using LogisticRegression as classifier\n",
      "Fitting pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[486, 0], [0, 486]]\n",
      "Saved pipeline -> models/cw-256-LogisticRegression/pipeline.joblib\n",
      "Saved scaler -> models/cw-256-LogisticRegression/scaler.joblib\n",
      "Saved classifier -> models/cw-256-LogisticRegression/clf.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/cw-256-LogisticRegression'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 256\n",
    "ATTACK =  'cw'\n",
    "classifier = 'LogisticRegression'\n",
    "print (f'Training: {IMG_SIZE} - {ATTACK} - {classifier} \\n')\n",
    "train_from_npy( train_npy_path = f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_raw.npy\",\n",
    "                model_out_dir = f\"./models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                train_labels_npy_path=f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/train_labels.npy\",\n",
    "                random_seed=42,\n",
    "                mem_limit_bytes=100_000_000_000,\n",
    "                use_mmap=False,\n",
    "                classifier = classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T12:39:29.082835Z",
     "iopub.status.busy": "2025-10-20T12:39:29.082559Z",
     "iopub.status.idle": "2025-10-20T12:42:00.794917Z",
     "shell.execute_reply": "2025-10-20T12:42:00.793799Z",
     "shell.execute_reply.started": "2025-10-20T12:39:29.082818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Method: fgsm\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.9383  prec=0.9277  recall=0.9506  f1=0.9390\n",
      "  roc_auc=0.9945\n",
      "  confusion_matrix: [[75, 6], [4, 77]]\n",
      "Predictions saved to: eval-VALSET/fgsm-cw-256-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/fgsm-cw-256-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.9382716049382716, 'precision': 0.927710843373494, 'recall': 0.9506172839506173, 'f1': 0.9390243902439024, 'roc_auc': 0.9945130315500685, 'confusion_matrix': [[75, 6], [4, 77]], 'classification_report': {'0': {'precision': 0.9493670886075949, 'recall': 0.9259259259259259, 'f1-score': 0.9375, 'support': 81.0}, '1': {'precision': 0.927710843373494, 'recall': 0.9506172839506173, 'f1-score': 0.9390243902439024, 'support': 81.0}, 'accuracy': 0.9382716049382716, 'macro avg': {'precision': 0.9385389659905444, 'recall': 0.9382716049382716, 'f1-score': 0.9382621951219512, 'support': 162.0}, 'weighted avg': {'precision': 0.9385389659905444, 'recall': 0.9382716049382716, 'f1-score': 0.9382621951219512, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.1s remaining:    0.9s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.9691  prec=0.9634  recall=0.9753  f1=0.9693\n",
      "  roc_auc=0.9973\n",
      "  confusion_matrix: [[78, 3], [2, 79]]\n",
      "Predictions saved to: eval-VALSET/fgsm-cw-256-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/fgsm-cw-256-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.9691358024691358, 'precision': 0.9634146341463414, 'recall': 0.9753086419753086, 'f1': 0.9693251533742331, 'roc_auc': 0.9973327236701722, 'confusion_matrix': [[78, 3], [2, 79]], 'classification_report': {'0': {'precision': 0.975, 'recall': 0.9629629629629629, 'f1-score': 0.968944099378882, 'support': 81.0}, '1': {'precision': 0.9634146341463414, 'recall': 0.9753086419753086, 'f1-score': 0.9693251533742331, 'support': 81.0}, 'accuracy': 0.9691358024691358, 'macro avg': {'precision': 0.9692073170731708, 'recall': 0.9691358024691358, 'f1-score': 0.9691346263765576, 'support': 162.0}, 'weighted avg': {'precision': 0.9692073170731706, 'recall': 0.9691358024691358, 'f1-score': 0.9691346263765576, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: bim\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.9815  prec=0.9756  recall=0.9877  f1=0.9816\n",
      "  roc_auc=0.9979\n",
      "  confusion_matrix: [[79, 2], [1, 80]]\n",
      "Predictions saved to: eval-VALSET/bim-cw-256-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/bim-cw-256-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.9814814814814815, 'precision': 0.975609756097561, 'recall': 0.9876543209876543, 'f1': 0.9815950920245399, 'roc_auc': 0.9978661789361378, 'confusion_matrix': [[79, 2], [1, 80]], 'classification_report': {'0': {'precision': 0.9875, 'recall': 0.9753086419753086, 'f1-score': 0.9813664596273292, 'support': 81.0}, '1': {'precision': 0.975609756097561, 'recall': 0.9876543209876543, 'f1-score': 0.9815950920245399, 'support': 81.0}, 'accuracy': 0.9814814814814815, 'macro avg': {'precision': 0.9815548780487805, 'recall': 0.9814814814814814, 'f1-score': 0.9814807758259345, 'support': 162.0}, 'weighted avg': {'precision': 0.9815548780487804, 'recall': 0.9814814814814815, 'f1-score': 0.9814807758259344, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "  confusion_matrix: [[81, 0], [0, 81]]\n",
      "Predictions saved to: eval-VALSET/bim-cw-256-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/bim-cw-256-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'roc_auc': 1.0, 'confusion_matrix': [[81, 0], [0, 81]], 'classification_report': {'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81.0}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 81.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: pgd\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.9691  prec=0.9750  recall=0.9630  f1=0.9689\n",
      "  roc_auc=0.9977\n",
      "  confusion_matrix: [[79, 2], [3, 78]]\n",
      "Predictions saved to: eval-VALSET/pgd-cw-256-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/pgd-cw-256-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.9691358024691358, 'precision': 0.975, 'recall': 0.9629629629629629, 'f1': 0.968944099378882, 'roc_auc': 0.9977137631458619, 'confusion_matrix': [[79, 2], [3, 78]], 'classification_report': {'0': {'precision': 0.9634146341463414, 'recall': 0.9753086419753086, 'f1-score': 0.9693251533742331, 'support': 81.0}, '1': {'precision': 0.975, 'recall': 0.9629629629629629, 'f1-score': 0.968944099378882, 'support': 81.0}, 'accuracy': 0.9691358024691358, 'macro avg': {'precision': 0.9692073170731708, 'recall': 0.9691358024691358, 'f1-score': 0.9691346263765576, 'support': 162.0}, 'weighted avg': {'precision': 0.9692073170731706, 'recall': 0.9691358024691358, 'f1-score': 0.9691346263765576, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.9877  prec=0.9877  recall=0.9877  f1=0.9877\n",
      "  roc_auc=0.9998\n",
      "  confusion_matrix: [[80, 1], [1, 80]]\n",
      "Predictions saved to: eval-VALSET/pgd-cw-256-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/pgd-cw-256-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.9876543209876543, 'precision': 0.9876543209876543, 'recall': 0.9876543209876543, 'f1': 0.9876543209876543, 'roc_auc': 0.9998475842097241, 'confusion_matrix': [[80, 1], [1, 80]], 'classification_report': {'0': {'precision': 0.9876543209876543, 'recall': 0.9876543209876543, 'f1-score': 0.9876543209876543, 'support': 81.0}, '1': {'precision': 0.9876543209876543, 'recall': 0.9876543209876543, 'f1-score': 0.9876543209876543, 'support': 81.0}, 'accuracy': 0.9876543209876543, 'macro avg': {'precision': 0.9876543209876543, 'recall': 0.9876543209876543, 'f1-score': 0.9876543209876543, 'support': 162.0}, 'weighted avg': {'precision': 0.9876543209876543, 'recall': 0.9876543209876543, 'f1-score': 0.9876543209876543, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: df\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.6420  prec=0.6456  recall=0.6296  f1=0.6375\n",
      "  roc_auc=0.6914\n",
      "  confusion_matrix: [[53, 28], [30, 51]]\n",
      "Predictions saved to: eval-VALSET/df-cw-256-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/df-cw-256-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.6419753086419753, 'precision': 0.6455696202531646, 'recall': 0.6296296296296297, 'f1': 0.6375, 'roc_auc': 0.6913580246913581, 'confusion_matrix': [[53, 28], [30, 51]], 'classification_report': {'0': {'precision': 0.6385542168674698, 'recall': 0.654320987654321, 'f1-score': 0.6463414634146342, 'support': 81.0}, '1': {'precision': 0.6455696202531646, 'recall': 0.6296296296296297, 'f1-score': 0.6375, 'support': 81.0}, 'accuracy': 0.6419753086419753, 'macro avg': {'precision': 0.6420619185603171, 'recall': 0.6419753086419753, 'f1-score': 0.641920731707317, 'support': 162.0}, 'weighted avg': {'precision': 0.6420619185603172, 'recall': 0.6419753086419753, 'f1-score': 0.641920731707317, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.5741  prec=0.5789  recall=0.5432  f1=0.5605\n",
      "  roc_auc=0.6052\n",
      "  confusion_matrix: [[49, 32], [37, 44]]\n",
      "Predictions saved to: eval-VALSET/df-cw-256-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/df-cw-256-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.5740740740740741, 'precision': 0.5789473684210527, 'recall': 0.5432098765432098, 'f1': 0.5605095541401274, 'roc_auc': 0.60524310318549, 'confusion_matrix': [[49, 32], [37, 44]], 'classification_report': {'0': {'precision': 0.5697674418604651, 'recall': 0.6049382716049383, 'f1-score': 0.5868263473053892, 'support': 81.0}, '1': {'precision': 0.5789473684210527, 'recall': 0.5432098765432098, 'f1-score': 0.5605095541401274, 'support': 81.0}, 'accuracy': 0.5740740740740741, 'macro avg': {'precision': 0.574357405140759, 'recall': 0.5740740740740741, 'f1-score': 0.5736679507227582, 'support': 162.0}, 'weighted avg': {'precision': 0.574357405140759, 'recall': 0.5740740740740741, 'f1-score': 0.5736679507227583, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n",
      "Attack Method: cw\n",
      "\n",
      "\n",
      " Classifier: LogisticRegression: \n",
      "\n",
      "VAL Eval results:\n",
      "  acc=0.6790  prec=0.6835  recall=0.6667  f1=0.6750\n",
      "  roc_auc=0.7177\n",
      "  confusion_matrix: [[56, 25], [27, 54]]\n",
      "Predictions saved to: eval-VALSET/cw-cw-256-LogisticRegression_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/cw-cw-256-LogisticRegression_test_result.csv\n",
      "val metrics: {'accuracy': 0.6790123456790124, 'precision': 0.6835443037974683, 'recall': 0.6666666666666666, 'f1': 0.675, 'roc_auc': 0.717725956409084, 'confusion_matrix': [[56, 25], [27, 54]], 'classification_report': {'0': {'precision': 0.6746987951807228, 'recall': 0.691358024691358, 'f1-score': 0.6829268292682927, 'support': 81.0}, '1': {'precision': 0.6835443037974683, 'recall': 0.6666666666666666, 'f1-score': 0.675, 'support': 81.0}, 'accuracy': 0.6790123456790124, 'macro avg': {'precision': 0.6791215494890956, 'recall': 0.6790123456790123, 'f1-score': 0.6789634146341463, 'support': 162.0}, 'weighted avg': {'precision': 0.6791215494890956, 'recall': 0.6790123456790124, 'f1-score': 0.6789634146341463, 'support': 162.0}}}\n",
      "\n",
      " Classifier: RandomForest: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Eval results:\n",
      "  acc=0.5802  prec=0.5823  recall=0.5679  f1=0.5750\n",
      "  roc_auc=0.5749\n",
      "  confusion_matrix: [[48, 33], [35, 46]]\n",
      "Predictions saved to: eval-VALSET/cw-cw-256-RandomForest_test_result_predictions.csv\n",
      "Metrics saved to: eval-VALSET/cw-cw-256-RandomForest_test_result.csv\n",
      "val metrics: {'accuracy': 0.5802469135802469, 'precision': 0.5822784810126582, 'recall': 0.5679012345679012, 'f1': 0.575, 'roc_auc': 0.5749123609205914, 'confusion_matrix': [[48, 33], [35, 46]], 'classification_report': {'0': {'precision': 0.5783132530120482, 'recall': 0.5925925925925926, 'f1-score': 0.5853658536585366, 'support': 81.0}, '1': {'precision': 0.5822784810126582, 'recall': 0.5679012345679012, 'f1-score': 0.575, 'support': 81.0}, 'accuracy': 0.5802469135802469, 'macro avg': {'precision': 0.5802958670123533, 'recall': 0.5802469135802468, 'f1-score': 0.5801829268292682, 'support': 162.0}, 'weighted avg': {'precision': 0.5802958670123533, 'recall': 0.5802469135802469, 'f1-score': 0.5801829268292683, 'support': 162.0}}}\n",
      "_____________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 256\n",
    "ATTACKS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n",
    "classifiers = ['LogisticRegression', 'RandomForest']\n",
    "for ATTACK in ATTACKS:\n",
    "    print (f'Attack Method: {ATTACK}\\n')\n",
    "    for classifier in classifiers:\n",
    "        print (f'\\n Classifier: {classifier}: \\n')\n",
    "        val_res = eval_val_from_npy(\n",
    "             val_npy_path = f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/val_raw.npy\",\n",
    "             val_label_path = f\"/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{ATTACK}/val_labels.npy\",\n",
    "             model_out_dir = f\"/kaggle/working/models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "             return_predictions=True,\n",
    "             use_mmap=False,\n",
    "             csv_path=f\"./eval-VALSET/{ATTACK}-{DATASET}-{IMG_SIZE}-{classifier}_test_result.csv\"\n",
    "        )\n",
    "        print(\"val metrics:\", val_res[\"metrics\"])\n",
    "    print ('_____________________\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T20:18:19.127230Z",
     "iopub.status.busy": "2025-10-18T20:18:19.126993Z",
     "iopub.status.idle": "2025-10-18T20:18:19.449202Z",
     "shell.execute_reply": "2025-10-18T20:18:19.448286Z",
     "shell.execute_reply.started": "2025-10-18T20:18:19.127212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All contents inside /kaggle/working/ have been removed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "WORKING_DIR = \"/kaggle/working/\"\n",
    "\n",
    "for item in os.listdir(WORKING_DIR):\n",
    "    item_path = os.path.join(WORKING_DIR, item)\n",
    "    try:\n",
    "        if os.path.isfile(item_path) or os.path.islink(item_path):\n",
    "            os.unlink(item_path)  # remove file or link\n",
    "        elif os.path.isdir(item_path):\n",
    "            shutil.rmtree(item_path)  # remove directory recursively\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to delete {item_path}: {e}\")\n",
    "\n",
    "print(\"All contents inside /kaggle/working/ have been removed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T12:33:48.668718Z",
     "iopub.status.busy": "2025-10-20T12:33:48.668377Z",
     "iopub.status.idle": "2025-10-20T12:38:54.211416Z",
     "shell.execute_reply": "2025-10-20T12:38:54.210277Z",
     "shell.execute_reply.started": "2025-10-20T12:33:48.668696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: fgsm \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9512  prec=0.9405  recall=0.9634  f1=0.9518\n",
      "  roc_auc=0.9851\n",
      "Metrics saved to: eval/fgsm-fgsm-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: fgsm \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.7683  prec=0.9074  recall=0.5976  f1=0.7206\n",
      "  roc_auc=0.8721\n",
      "Metrics saved to: eval/fgsm-bim-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: fgsm \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.7805  prec=0.9107  recall=0.6220  f1=0.7391\n",
      "  roc_auc=0.8859\n",
      "Metrics saved to: eval/fgsm-pgd-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: fgsm \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5244  prec=0.6429  recall=0.1098  f1=0.1875\n",
      "  roc_auc=0.5376\n",
      "Metrics saved to: eval/fgsm-df-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: fgsm \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5122  prec=0.5833  recall=0.0854  f1=0.1489\n",
      "  roc_auc=0.5402\n",
      "Metrics saved to: eval/fgsm-cw-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: bim \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5671  prec=1.0000  recall=0.1341  f1=0.2366\n",
      "  roc_auc=0.6944\n",
      "Metrics saved to: eval/bim-fgsm-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: bim \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9756  prec=1.0000  recall=0.9512  f1=0.9750\n",
      "  roc_auc=0.9990\n",
      "Metrics saved to: eval/bim-bim-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: bim \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9878  prec=1.0000  recall=0.9756  f1=0.9877\n",
      "  roc_auc=0.9999\n",
      "Metrics saved to: eval/bim-pgd-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: bim \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.4520\n",
      "Metrics saved to: eval/bim-df-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: bim \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5061  prec=1.0000  recall=0.0122  f1=0.0241\n",
      "  roc_auc=0.4911\n",
      "Metrics saved to: eval/bim-cw-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: pgd \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5488  prec=1.0000  recall=0.0976  f1=0.1778\n",
      "  roc_auc=0.6927\n",
      "Metrics saved to: eval/pgd-fgsm-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: pgd \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9817  prec=1.0000  recall=0.9634  f1=0.9814\n",
      "  roc_auc=0.9970\n",
      "Metrics saved to: eval/pgd-bim-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: pgd \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.9878  prec=1.0000  recall=0.9756  f1=0.9877\n",
      "  roc_auc=0.9991\n",
      "Metrics saved to: eval/pgd-pgd-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: pgd \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.4494\n",
      "Metrics saved to: eval/pgd-df-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: pgd \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5061  prec=1.0000  recall=0.0122  f1=0.0241\n",
      "  roc_auc=0.4921\n",
      "Metrics saved to: eval/pgd-cw-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: df \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6585  prec=0.6327  recall=0.7561  f1=0.6889\n",
      "  roc_auc=0.7304\n",
      "Metrics saved to: eval/df-fgsm-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: df \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.2805  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.0526\n",
      "Metrics saved to: eval/df-bim-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: df \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.2805  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.0448\n",
      "Metrics saved to: eval/df-pgd-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: df \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6402  prec=0.6211  recall=0.7195  f1=0.6667\n",
      "  roc_auc=0.6997\n",
      "Metrics saved to: eval/df-df-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: df \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5976  prec=0.5909  recall=0.6341  f1=0.6118\n",
      "  roc_auc=0.6474\n",
      "Metrics saved to: eval/df-cw-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: cw \n",
      " Dataset: fgsm \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6463  prec=0.6714  recall=0.5732  f1=0.6184\n",
      "  roc_auc=0.7119\n",
      "Metrics saved to: eval/cw-fgsm-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: cw \n",
      " Dataset: bim \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5610  prec=0.5893  recall=0.4024  f1=0.4783\n",
      "  roc_auc=0.4468\n",
      "Metrics saved to: eval/cw-bim-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: cw \n",
      " Dataset: pgd \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.5366  prec=0.5577  recall=0.3537  f1=0.4328\n",
      "  roc_auc=0.4030\n",
      "Metrics saved to: eval/cw-pgd-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: cw \n",
      " Dataset: df \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6098  prec=0.6406  recall=0.5000  f1=0.5616\n",
      "  roc_auc=0.6474\n",
      "Metrics saved to: eval/cw-df-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: cw \n",
      " Dataset: cw \n",
      " Classifier: LogisticRegression \n",
      "\n",
      "TEST Eval results:\n",
      "  acc=0.6463  prec=0.6714  recall=0.5732  f1=0.6184\n",
      "  roc_auc=0.6956\n",
      "Metrics saved to: eval/cw-cw-256-LogisticRegression_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: fgsm \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9512  prec=0.9405  recall=0.9634  f1=0.9518\n",
      "  roc_auc=0.9922\n",
      "Metrics saved to: eval/fgsm-fgsm-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: fgsm \n",
      " Dataset: bim \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.1s remaining:    0.8s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.7744  prec=0.9091  recall=0.6098  f1=0.7299\n",
      "  roc_auc=0.9261\n",
      "Metrics saved to: eval/fgsm-bim-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: fgsm \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.7683  prec=0.9074  recall=0.5976  f1=0.7206\n",
      "  roc_auc=0.9276\n",
      "Metrics saved to: eval/fgsm-pgd-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: fgsm \n",
      " Dataset: df \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.5000  recall=0.0610  f1=0.1087\n",
      "  roc_auc=0.5152\n",
      "Metrics saved to: eval/fgsm-df-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: fgsm \n",
      " Dataset: cw \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4817  prec=0.2857  recall=0.0244  f1=0.0449\n",
      "  roc_auc=0.5285\n",
      "Metrics saved to: eval/fgsm-cw-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: bim \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5183  prec=1.0000  recall=0.0366  f1=0.0706\n",
      "  roc_auc=0.6713\n",
      "Metrics saved to: eval/bim-fgsm-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: bim \n",
      " Dataset: bim \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9939  prec=1.0000  recall=0.9878  f1=0.9939\n",
      "  roc_auc=1.0000\n",
      "Metrics saved to: eval/bim-bim-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: bim \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=1.0000  prec=1.0000  recall=1.0000  f1=1.0000\n",
      "  roc_auc=1.0000\n",
      "Metrics saved to: eval/bim-pgd-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: bim \n",
      " Dataset: df \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.4744\n",
      "Metrics saved to: eval/bim-df-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: bim \n",
      " Dataset: cw \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.4955\n",
      "Metrics saved to: eval/bim-cw-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: pgd \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5061  prec=1.0000  recall=0.0122  f1=0.0241\n",
      "  roc_auc=0.6460\n",
      "Metrics saved to: eval/pgd-fgsm-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: pgd \n",
      " Dataset: bim \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9817  prec=1.0000  recall=0.9634  f1=0.9814\n",
      "  roc_auc=0.9999\n",
      "Metrics saved to: eval/pgd-bim-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: pgd \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.9939  prec=1.0000  recall=0.9878  f1=0.9939\n",
      "  roc_auc=1.0000\n",
      "Metrics saved to: eval/pgd-pgd-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: pgd \n",
      " Dataset: df \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.4506\n",
      "Metrics saved to: eval/pgd-df-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: pgd \n",
      " Dataset: cw \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5000  prec=0.0000  recall=0.0000  f1=0.0000\n",
      "  roc_auc=0.5141\n",
      "Metrics saved to: eval/pgd-cw-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: df \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5549  prec=0.5570  recall=0.5366  f1=0.5466\n",
      "  roc_auc=0.6073\n",
      "Metrics saved to: eval/df-fgsm-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: df \n",
      " Dataset: bim \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.3720  prec=0.2857  recall=0.1707  f1=0.2137\n",
      "  roc_auc=0.2793\n",
      "Metrics saved to: eval/df-bim-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: df \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.3902  prec=0.3269  recall=0.2073  f1=0.2537\n",
      "  roc_auc=0.3104\n",
      "Metrics saved to: eval/df-pgd-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: df \n",
      " Dataset: df \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5732  prec=0.5732  recall=0.5732  f1=0.5732\n",
      "  roc_auc=0.6136\n",
      "Metrics saved to: eval/df-df-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: df \n",
      " Dataset: cw \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5610  prec=0.5625  recall=0.5488  f1=0.5556\n",
      "  roc_auc=0.5956\n",
      "Metrics saved to: eval/df-cw-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: cw \n",
      " Dataset: fgsm \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5488  prec=0.5500  recall=0.5366  f1=0.5432\n",
      "  roc_auc=0.5610\n",
      "Metrics saved to: eval/cw-fgsm-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: cw \n",
      " Dataset: bim \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4817  prec=0.4783  recall=0.4024  f1=0.4371\n",
      "  roc_auc=0.4607\n",
      "Metrics saved to: eval/cw-bim-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: cw \n",
      " Dataset: pgd \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.4756  prec=0.4706  recall=0.3902  f1=0.4267\n",
      "  roc_auc=0.4661\n",
      "Metrics saved to: eval/cw-pgd-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: cw \n",
      " Dataset: df \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5488  prec=0.5500  recall=0.5366  f1=0.5432\n",
      "  roc_auc=0.5068\n",
      "Metrics saved to: eval/cw-df-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "Evaluate Against Test Set (Image Size: 256) \n",
      " Method: cw \n",
      " Dataset: cw \n",
      " Classifier: RandomForest \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Eval results:\n",
      "  acc=0.5732  prec=0.5714  recall=0.5854  f1=0.5783\n",
      "  roc_auc=0.5916\n",
      "Metrics saved to: eval/cw-cw-256-RandomForest_test_result.csv\n",
      "_________________________\n",
      "\n",
      "===============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "classifiers = ['LogisticRegression', 'RandomForest']\n",
    "IMG_SIZE = 256\n",
    "\n",
    "ATTACKS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n",
    "DATASETS = ['fgsm', 'bim', 'pgd', 'df', 'cw']\n",
    "\n",
    "for classifier in classifiers:\n",
    "    for ATTACK in ATTACKS:\n",
    "        for DATASET in DATASETS:\n",
    "            print(f'Evaluate Against Test Set (Image Size: {IMG_SIZE}) \\n Method: {ATTACK} \\n Dataset: {DATASET} \\n Classifier: {classifier} \\n')\n",
    "            eval_test_from_npy(\n",
    "                test_clean_npy_path=f'/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{DATASET}/test_clean_raw.npy',\n",
    "                test_adv_npy_path=f'/kaggle/input/layerpfs/{IMG_SIZE}x{IMG_SIZE}/{DATASET}/test_adv_raw.npy',\n",
    "                model_out_dir=f\"/kaggle/working/models/{ATTACK}-{IMG_SIZE}-{classifier}\",\n",
    "                test_labels_npy_path=None,\n",
    "                return_predictions=False,\n",
    "                use_mmap=False,\n",
    "                csv_path=f\"./eval/{ATTACK}-{DATASET}-{IMG_SIZE}-{classifier}_test_result.csv\"\n",
    "            )\n",
    "            print ('_________________________\\n')\n",
    "    \n",
    "        print ('===============================\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpuV5e8",
   "dataSources": [
    {
     "datasetId": 8509599,
     "sourceId": 13408520,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31155,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
