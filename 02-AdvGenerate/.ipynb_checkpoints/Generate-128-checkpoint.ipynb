{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6b9a479-2c4a-4c17-b469-d447a762b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import foolbox\n",
    "from foolbox import PyTorchModel\n",
    "from foolbox.attacks import (\n",
    "    LinfBasicIterativeAttack,\n",
    "    FGSM,\n",
    "    PGD,\n",
    "    L2DeepFoolAttack,\n",
    "    L2CarliniWagnerAttack,\n",
    ")\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def _load_checkpoint_into_model(model, checkpoint_path, map_location=\"cpu\", strict=True, verbose=False):\n",
    "    ckpt = torch.load(checkpoint_path, map_location=map_location)\n",
    "\n",
    "    if isinstance(ckpt, dict):\n",
    "        for candidate in (\"model_state\", \"model_state_dict\", \"state_dict\", \"state\"):\n",
    "            if candidate in ckpt:\n",
    "                state = ckpt[candidate]\n",
    "                break\n",
    "        else:\n",
    "            if all(isinstance(v, (torch.Tensor, type(None))) or hasattr(v, \"shape\") for v in ckpt.values()):\n",
    "                state = ckpt\n",
    "            else:\n",
    "                nested = None\n",
    "                for v in ckpt.values():\n",
    "                    if isinstance(v, dict):\n",
    "                        if nested is None or len(v) > len(nested):\n",
    "                            nested = v\n",
    "                state = nested if nested is not None else ckpt\n",
    "    else:\n",
    "        state = ckpt\n",
    "\n",
    "    if not isinstance(state, dict):\n",
    "        raise ValueError(f\"Checkpoint {checkpoint_path} does not contain a state-dict (found type: {type(state)})\")\n",
    "\n",
    "    keys = list(state.keys())\n",
    "    prefix = None\n",
    "    for p in (\"module.\", \"model.\"):\n",
    "        cnt = sum(1 for k in keys if k.startswith(p))\n",
    "        if cnt >= max(1, len(keys) // 2):\n",
    "            prefix = p\n",
    "            break\n",
    "\n",
    "    if prefix:\n",
    "        new_state = OrderedDict((k[len(prefix):], v) for k, v in state.items())\n",
    "    else:\n",
    "        new_state = state\n",
    "\n",
    "    try:\n",
    "        model.load_state_dict(new_state, strict=strict)\n",
    "        if verbose:\n",
    "            print(f\"Loaded checkpoint {checkpoint_path} (strict={strict}).\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Strict load failed: {e}. Trying non-strict load ...\")\n",
    "        res = model.load_state_dict(new_state, strict=False)\n",
    "        if verbose:\n",
    "            print(\"Loaded with strict=False. Missing keys:\", getattr(res, \"missing_keys\", None))\n",
    "            print(\"Unexpected keys:\", getattr(res, \"unexpected_keys\", None))\n",
    "        return model\n",
    "\n",
    "\n",
    "def run_attack(\n",
    "    model,\n",
    "    checkpoint_path,\n",
    "    preprocessing = dict(\n",
    "        mean=[0.4812775254249573, 0.4674863815307617, 0.4093940854072571],\n",
    "        std=[0.19709135591983795, 0.1933959424495697, 0.19051066040992737],\n",
    "        axis=-3\n",
    "    ),\n",
    "    attack=\"fgsm\",                  \n",
    "    csv_path=\"./data/clean_data.csv\",\n",
    "    imdir=\"./images\",\n",
    "    outdir=\"./data\",\n",
    "    use_cuda=True,\n",
    "    model_device=None,\n",
    "    load_map_location=None,\n",
    "    batch_size=32,\n",
    "    verbose=True,\n",
    "):\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "\n",
    "    if model_device is None:\n",
    "        device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and use_cuda) else \"cpu\")\n",
    "    else:\n",
    "        device = torch.device(model_device)\n",
    "\n",
    "    if load_map_location is None:\n",
    "        ckpt_map = \"cpu\" if device.type == \"cpu\" else device\n",
    "    else:\n",
    "        ckpt_map = load_map_location\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Loading checkpoint:\", checkpoint_path, \"map_location:\", ckpt_map)\n",
    "    model = _load_checkpoint_into_model(model, checkpoint_path, map_location=ckpt_map, strict=False, verbose=verbose)\n",
    "\n",
    "    model = model.to(device).eval()\n",
    "    fmodel = PyTorchModel(model, bounds=(0, 1), preprocessing=preprocessing)\n",
    "\n",
    "    to_tensor = transforms.ToTensor()\n",
    "\n",
    "    def load_image_tensor(rel_path, base_dir):\n",
    "        p = Path(base_dir) / str(rel_path).lstrip(\"/\")\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        return to_tensor(img)\n",
    "\n",
    "    if attack == \"fgsm\":\n",
    "        atk = FGSM()\n",
    "        epsilons = [0.03]\n",
    "    elif attack == \"bim\":\n",
    "        atk = LinfBasicIterativeAttack()\n",
    "        epsilons = [0.03]\n",
    "    elif attack == \"pgd\":\n",
    "        atk = PGD()\n",
    "        epsilons = [0.03]\n",
    "    elif attack == \"df\":\n",
    "        atk = L2DeepFoolAttack()\n",
    "        epsilons = None\n",
    "    elif attack == \"cw\":\n",
    "        atk = L2CarliniWagnerAttack(steps=1000)\n",
    "        epsilons = None\n",
    "    else:\n",
    "        raise ValueError(\"Unknown attack: \" + str(attack))\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    df_correct = df[df[\"true_idx\"] == df[\"pred_idx\"]].copy()\n",
    "    df_correct['original_index'] = df_correct.index\n",
    "    total_candidates = len(df_correct)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"CSV: {csv_path} rows={len(df)}; correctly-classified candidates={total_candidates}; epsilons={epsilons}\")\n",
    "\n",
    "    out_base = Path(outdir)\n",
    "    out_base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    attempted_count = 0\n",
    "    success_count = 0\n",
    "    saved_count = 0\n",
    "    \n",
    "    candidate_results = {}\n",
    "\n",
    "    for i in tqdm(range(0, total_candidates, batch_size), desc=\"Processing Batches\"):\n",
    "        batch_df = df_correct.iloc[i:i+batch_size]\n",
    "        \n",
    "        images, labels, batch_info = [], [], []\n",
    "        for _, row in batch_df.iterrows():\n",
    "            try:\n",
    "                img_tensor = load_image_tensor(row[\"rel_path\"], imdir)\n",
    "                images.append(img_tensor)\n",
    "                labels.append(int(row[\"true_idx\"]))\n",
    "                batch_info.append(row)\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"Skipping image {row['rel_path']} due to loading error: {e}\")\n",
    "                candidate_results[row['original_index']] = {\"success\": False}\n",
    "        \n",
    "        if not images:\n",
    "            continue\n",
    "            \n",
    "        images_t = torch.stack(images).to(device)\n",
    "        labels_t = torch.tensor(labels, device=device)\n",
    "        \n",
    "        try:\n",
    "            _, advs_t, success_t = atk(fmodel, images_t, criterion=foolbox.criteria.Misclassification(labels_t), epsilons=epsilons)\n",
    "            attempted_count += len(images)\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"Attack failed for a batch: {e}\")\n",
    "            for row in batch_info:\n",
    "                candidate_results[row['original_index']] = {\"success\": False}\n",
    "            continue\n",
    "\n",
    "        for j, row in enumerate(batch_info):\n",
    "            original_idx = row['original_index']\n",
    "            \n",
    "            if epsilons is not None:\n",
    "                is_successful = bool(success_t[0][j].item())\n",
    "                adv_tensor_for_item = advs_t[0][j]\n",
    "            else:\n",
    "                is_successful = bool(success_t[j].item())\n",
    "                adv_tensor_for_item = advs_t[j]\n",
    "\n",
    "            candidate_results[original_idx] = {\"success\": is_successful}\n",
    "            \n",
    "            if is_successful:\n",
    "                success_count += 1\n",
    "                adv_cpu = adv_tensor_for_item.cpu()\n",
    "                \n",
    "                try:\n",
    "                    rel_clean = str(row[\"rel_path\"]).lstrip(\"/\")\n",
    "                    out_rel = Path(rel_clean).with_suffix(\".pt\")\n",
    "                    out_path = out_base / attack / out_rel\n",
    "                    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    torch.save(adv_cpu, out_path)\n",
    "                    saved_count += 1\n",
    "                except Exception as e:\n",
    "                    if verbose:\n",
    "                        print(f\"Failed to save adv tensor for {row['rel_path']}: {e}\")\n",
    "\n",
    "    df['success'] = df.index.map(lambda idx: candidate_results.get(idx, {}).get('success', False))\n",
    "    \n",
    "    meta_df = df[[\"rel_path\", \"true_idx\", \"pred_idx\", \"true_class\", \"pred_class\", \"success\"]]\n",
    "    meta_csv_path = out_base / f\"metadata_{attack}.csv\"\n",
    "    meta_df.to_csv(meta_csv_path, index=False)\n",
    "    if verbose:\n",
    "        print(f\"Wrote metadata CSV to: {meta_csv_path}\")\n",
    "\n",
    "    # compute rates\n",
    "    success_rate_over_candidates = success_count / total_candidates if total_candidates > 0 else 0.0\n",
    "    success_rate_over_attempts = success_count / attempted_count if attempted_count > 0 else 0.0\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Attempted attacks: {attempted_count}/{total_candidates} candidates.\")\n",
    "        print(f\"Successes: {success_count}.\")\n",
    "        print(f\"Saved adv files: {saved_count}.\")\n",
    "        print(f\"Success rate (over candidates): {success_rate_over_candidates:.4f} ({success_count}/{total_candidates})\")\n",
    "        print(f\"Success rate (over attempted):  {success_rate_over_attempts:.4f} ({success_count}/{attempted_count if attempted_count > 0 else 0})\")\n",
    "\n",
    "    return success_rate_over_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde35091-3c7c-4701-840f-1e4bd705ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import VGG16_BN_Weights\n",
    "from torchvision import models, transforms\n",
    "\n",
    "model = models.vgg16_bn(weights=VGG16_BN_Weights.IMAGENET1K_V1)\n",
    "model.avgpool = nn.AdaptiveAvgPool2d((7,7))\n",
    "model.classifier[6] = nn.Linear(4096, 7)\n",
    "\n",
    "img_size = 128\n",
    "checkpoint_path = f'../01-CleanModel/Models/{img_size}x{img_size}/best_min_acc_vgg16_{img_size}x{img_size}_Model-2.pth'\n",
    "csv_path = '../01-CleanModel/Evaluate/correct_in_all_models.csv'\n",
    "imdir = f'../01-CleanModel/Dataset/{img_size}x{img_size}'\n",
    "outdir = f'./generated_images-test/{img_size}x{img_size}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57783663-348b-4365-9d24-e991ae448fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: ../01-CleanModel/Models/128x128/best_min_acc_vgg16_128x128_Model-2.pth map_location: cuda:0\n",
      "Loaded checkpoint ../01-CleanModel/Models/128x128/best_min_acc_vgg16_128x128_Model-2.pth (strict=False).\n",
      "CSV: ../01-CleanModel/Evaluate/correct_in_all_models.csv rows=2225; correctly-classified candidates=2225; epsilons=[0.03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|████████████████████████████████████████████████████████████| 557/557 [01:42<00:00,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote metadata CSV to: generated_images-test\\128x128\\metadata_fgsm.csv\n",
      "Attempted attacks: 2225/2225 candidates.\n",
      "Successes: 1324.\n",
      "Saved adv files: 1324.\n",
      "Success rate (over candidates): 0.5951 (1324/2225)\n",
      "Success rate (over attempted):  0.5951 (1324/2225)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5950561797752809"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_attack(\n",
    "    model=model,\n",
    "    checkpoint_path=checkpoint_path,                  \n",
    "    attack=\"fgsm\",                    \n",
    "    csv_path=csv_path,\n",
    "    imdir=imdir,\n",
    "    outdir=outdir,\n",
    "    batch_size=4,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9acce188-dbfa-40ab-b9d4-d47df0d384e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: ../01-CleanModel/Models/128x128/best_min_acc_vgg16_128x128_Model-2.pth map_location: cuda:0\n",
      "Loaded checkpoint ../01-CleanModel/Models/128x128/best_min_acc_vgg16_128x128_Model-2.pth (strict=False).\n",
      "CSV: ../01-CleanModel/Evaluate/correct_in_all_models.csv rows=2225; correctly-classified candidates=2225; epsilons=[0.03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|████████████████████████████████████████████████████████████| 557/557 [03:36<00:00,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote metadata CSV to: generated_images-test\\128x128\\metadata_bim.csv\n",
      "Attempted attacks: 2225/2225 candidates.\n",
      "Successes: 1723.\n",
      "Saved adv files: 1723.\n",
      "Success rate (over candidates): 0.7744 (1723/2225)\n",
      "Success rate (over attempted):  0.7744 (1723/2225)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7743820224719101"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_attack(\n",
    "    model=model,\n",
    "    checkpoint_path=checkpoint_path,                  \n",
    "    attack=\"bim\",                    \n",
    "    csv_path=csv_path,\n",
    "    imdir=imdir,\n",
    "    outdir=outdir,\n",
    "    batch_size=4,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bf06479-0cd4-433f-9afc-61e5bc6ef371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: ../01-CleanModel/Models/128x128/best_min_acc_vgg16_128x128_Model-2.pth map_location: cuda:0\n",
      "Loaded checkpoint ../01-CleanModel/Models/128x128/best_min_acc_vgg16_128x128_Model-2.pth (strict=False).\n",
      "CSV: ../01-CleanModel/Evaluate/correct_in_all_models.csv rows=2225; correctly-classified candidates=2225; epsilons=[0.03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|████████████████████████████████████████████████████████████| 557/557 [11:22<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote metadata CSV to: generated_images-test\\128x128\\metadata_pgd.csv\n",
      "Attempted attacks: 2225/2225 candidates.\n",
      "Successes: 1766.\n",
      "Saved adv files: 1766.\n",
      "Success rate (over candidates): 0.7937 (1766/2225)\n",
      "Success rate (over attempted):  0.7937 (1766/2225)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7937078651685393"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_attack(\n",
    "    model=model,\n",
    "    checkpoint_path=checkpoint_path,                  \n",
    "    attack=\"pgd\",                    \n",
    "    csv_path=csv_path,\n",
    "    imdir=imdir,\n",
    "    outdir=outdir,\n",
    "    batch_size=4,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedc2c65-2f15-4619-9180-010199d6b22a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: ../01-CleanModel/Models/128x128/best_min_acc_vgg16_128x128_Model-2.pth map_location: cuda:0\n",
      "Loaded checkpoint ../01-CleanModel/Models/128x128/best_min_acc_vgg16_128x128_Model-2.pth (strict=False).\n",
      "CSV: ../01-CleanModel/Evaluate/correct_in_all_models.csv rows=2225; correctly-classified candidates=2225; epsilons=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████████████████████████████████████████████████████| 1113/1113 [12:54<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote metadata CSV to: generated_images-test\\128x128\\metadata_df.csv\n",
      "Attempted attacks: 2225/2225 candidates.\n",
      "Successes: 2225.\n",
      "Saved adv files: 2225.\n",
      "Success rate (over candidates): 1.0000 (2225/2225)\n",
      "Success rate (over attempted):  1.0000 (2225/2225)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_attack(\n",
    "    model=model,\n",
    "    checkpoint_path=checkpoint_path,                  \n",
    "    attack=\"df\",                    \n",
    "    csv_path=csv_path,\n",
    "    imdir=imdir,\n",
    "    outdir=outdir,\n",
    "    batch_size=2,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb54f09e-34b1-4cf1-a218-770552fbb7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: ../01-CleanModel/Models/128x128/best_min_acc_vgg16_128x128_Model-2.pth map_location: cuda:0\n",
      "Loaded checkpoint ../01-CleanModel/Models/128x128/best_min_acc_vgg16_128x128_Model-2.pth (strict=False).\n",
      "CSV: ../01-CleanModel/Evaluate/correct_in_all_models.csv rows=2225; correctly-classified candidates=2225; epsilons=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|█████████████████████████████████████████████████████████| 557/557 [11:04:01<00:00, 71.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote metadata CSV to: generated_images-test\\128x128\\metadata_cw.csv\n",
      "Attempted attacks: 2225/2225 candidates.\n",
      "Successes: 2225.\n",
      "Saved adv files: 2225.\n",
      "Success rate (over candidates): 1.0000 (2225/2225)\n",
      "Success rate (over attempted):  1.0000 (2225/2225)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_attack(\n",
    "    model=model,\n",
    "    checkpoint_path=checkpoint_path,                  \n",
    "    attack=\"cw\",                    \n",
    "    csv_path=csv_path,\n",
    "    imdir=imdir,\n",
    "    outdir=outdir,\n",
    "    batch_size=4,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5842f937-dcc7-474c-8468-bab325c4078a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
