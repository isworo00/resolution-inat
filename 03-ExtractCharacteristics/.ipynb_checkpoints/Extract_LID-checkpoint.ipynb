{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d6f18f-296f-49d6-bfd3-988b6c7bfc2e",
   "metadata": {},
   "source": [
    "# Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9736871-4bd3-457e-be89-6053d3ce94a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from scipy.spatial.distance import cdist\n",
    "import sklearn\n",
    "import sklearn.covariance\n",
    "from PIL import Image\n",
    "from torchvision.models import VGG16_BN_Weights\n",
    "from torchvision import models, transforms\n",
    "from numpy.lib.format import open_memmap\n",
    "import gc\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "def load_clean_image_tensor(rel_path: str):\n",
    "    p = (CLEAN_BASE / str(rel_path).lstrip(\"/\"))\n",
    "    img = Image.open(p).convert(\"RGB\")\n",
    "    return to_tensor(img)  \n",
    "\n",
    "def load_adv_tensor_from_file(rel_path: str, adv_folder: Path):\n",
    "    p = adv_folder / str(rel_path).lstrip(\"/\").replace(\".jpg\", \".pt\")\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Adv file not found: {p}\")\n",
    "    t = torch.load(p) \n",
    "    if isinstance(t, tuple) or isinstance(t, list):\n",
    "        t = t[0]\n",
    "    if t.dim() == 4 and t.shape[0] == 1:\n",
    "        t = t.squeeze(0)\n",
    "    return t\n",
    "\n",
    "def build_stacks_from_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    adv_folder = ADV_BASE_ROOT / attack_method\n",
    "\n",
    "    clean_tensors = []\n",
    "    adv_tensors = []\n",
    "    rel_paths = []\n",
    "    skipped = 0\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Loading images and advs\"):\n",
    "        rel = row[\"rel_path\"]\n",
    "        try:\n",
    "            clean_t = load_clean_image_tensor(rel)\n",
    "        except Exception as e:\n",
    "            print(f\"Skip clean {rel}: {e}\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            adv_t = load_adv_tensor_from_file(rel, adv_folder)\n",
    "        except Exception as e:\n",
    "            print(f\"Skip adv {rel}: {e}\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        if clean_t.shape != adv_t.shape:\n",
    "            print ('Missmatch')\n",
    "\n",
    "        clean_tensors.append(clean_t)\n",
    "        adv_tensors.append(adv_t)\n",
    "        rel_paths.append(rel)\n",
    "\n",
    "    if len(clean_tensors) == 0:\n",
    "        raise RuntimeError(\"No pairs loaded. Check CSV paths and adv folder.\")\n",
    "\n",
    "    images_stack = torch.stack(clean_tensors)   \n",
    "    advs_stack = torch.stack(adv_tensors)       \n",
    "    print(f\"Built stacks: {len(clean_tensors)} pairs (skipped {skipped}).\")\n",
    "    return images_stack, advs_stack, rel_paths\n",
    "\n",
    "\n",
    "def load_model_for_net(checkpoint_path, strict=True):\n",
    "    print(\"Loading model...\")\n",
    "    \n",
    "    model = models.vgg16_bn(weights=VGG16_BN_Weights.IMAGENET1K_V1)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d((7,7))\n",
    "    model.classifier[6] = nn.Linear(4096, 7)\n",
    "    \n",
    "    ckpt = torch.load(checkpoint_path, map_location='cpu')  \n",
    "\n",
    "    if isinstance(ckpt, dict):\n",
    "        for candidate in (\"model_state\", \"model_state_dict\", \"state_dict\", \"state\"):\n",
    "            if candidate in ckpt:\n",
    "                state = ckpt[candidate]\n",
    "                break\n",
    "        else:\n",
    "            if all(isinstance(v, (torch.Tensor, type(None))) or hasattr(v, \"shape\") for v in ckpt.values()):\n",
    "                state = ckpt\n",
    "            else:\n",
    "                nested = None\n",
    "                for v in ckpt.values():\n",
    "                    if isinstance(v, dict):\n",
    "                        if nested is None or len(v) > len(nested):\n",
    "                            nested = v\n",
    "                state = nested if nested is not None else ckpt\n",
    "    else:\n",
    "        state = ckpt\n",
    "\n",
    "    if not isinstance(state, dict):\n",
    "        raise ValueError(f\"Checkpoint {checkpoint_path} does not contain a state-dict (found type: {type(state)})\")\n",
    "\n",
    "    keys = list(state.keys())\n",
    "    prefix = None\n",
    "    for p in (\"module.\", \"model.\"):\n",
    "        cnt = sum(1 for k in keys if k.startswith(p))\n",
    "        if cnt >= max(1, len(keys) // 2):\n",
    "            prefix = p\n",
    "            break\n",
    "\n",
    "    if prefix:\n",
    "        new_state = OrderedDict((k[len(prefix):], v) for k, v in state.items())\n",
    "    else:\n",
    "        new_state = state\n",
    "\n",
    "    try:\n",
    "        model.load_state_dict(new_state, strict=strict)\n",
    "        print(f\"Loaded checkpoint {checkpoint_path} (strict={strict}).\")\n",
    "    except Exception as e:\n",
    "        print(f\"Strict load failed: {e}. Trying non-strict load ...\")\n",
    "        res = model.load_state_dict(new_state, strict=False)\n",
    "        print(\"Loaded with strict=False. Missing keys:\", getattr(res, \"missing_keys\", None))\n",
    "        print(\"Unexpected keys:\", getattr(res, \"unexpected_keys\", None))\n",
    "\n",
    "    # ensure model is on the same device you'll use and in eval mode\n",
    "    model = model.to(device).eval()\n",
    "    return model\n",
    "\n",
    "def get_layer_feature_maps(X, layers, model_features):\n",
    "    X_l = []\n",
    "    X = X.to(device)\n",
    "    for i in range(len(model_features)):\n",
    "        X = model_features[i](X)\n",
    "        if i in layers:\n",
    "            X_l.append(X)\n",
    "    return X_l\n",
    "\n",
    "def cifar_normalize(images, net_name='inat'):\n",
    "    if net_name == 'cif10':\n",
    "        images[:,0,:,:] = (images[:,0,:,:] - 0.4914)/0.2023\n",
    "        images[:,1,:,:] = (images[:,1,:,:] - 0.4822)/0.1994\n",
    "        images[:,2,:,:] = (images[:,2,:,:] - 0.4465)/0.2010\n",
    "    elif net_name == 'cif100':\n",
    "        images[:,0,:,:] = (images[:,0,:,:] - 0.5071)/0.2675\n",
    "        images[:,1,:,:] = (images[:,1,:,:] - 0.4867)/0.2565\n",
    "        images[:,2,:,:] = (images[:,2,:,:] - 0.4408)/0.2761\n",
    "    else:\n",
    "        MEAN = [0.4812775254249573, 0.4674863815307617, 0.4093940854072571]\n",
    "        STD  = [0.19709135591983795, 0.1933959424495697, 0.19051066040992737]\n",
    "        images[:,0,:,:] = (images[:,0,:,:] - MEAN[0]) / STD[0]\n",
    "        images[:,1,:,:] = (images[:,1,:,:] - MEAN[1]) / STD[1]\n",
    "        images[:,2,:,:] = (images[:,2,:,:] - MEAN[2]) / STD[2]\n",
    "    return images\n",
    "\n",
    "def calculate_fourier_spectrum(im, typ='MFS'):\n",
    "    im = im.float()\n",
    "    im = im.cpu().numpy()\n",
    "    fft = np.fft.fft2(im)\n",
    "    if typ == 'MFS':\n",
    "        fourier_spectrum = np.abs(fft)\n",
    "    elif typ == 'PFS':\n",
    "        fourier_spectrum = np.abs(np.angle(fft))\n",
    "    if net == 'cif100' and (attack_method in ('cw','df')):\n",
    "        fourier_spectrum *= 1/np.max(fourier_spectrum)\n",
    "    return fourier_spectrum\n",
    "\n",
    "def calculate_spectra(images, typ='MFS'):\n",
    "    fs = []\n",
    "    if isinstance(images, torch.Tensor):\n",
    "        images = [images[i] for i in range(images.shape[0])]\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        fourier_image = calculate_fourier_spectrum(image, typ=typ)\n",
    "        fs.append(fourier_image.flatten())\n",
    "    return fs\n",
    "\n",
    "def mle_batch(data, batch, k):\n",
    "    data = np.asarray(data, dtype=np.float32)\n",
    "    batch = np.asarray(batch, dtype=np.float32)\n",
    "    k = min(k, len(data)-1)\n",
    "    f = lambda v: - k / np.sum(np.log(v/v[-1]))\n",
    "    a = cdist(batch, data)\n",
    "    a = np.apply_along_axis(np.sort, axis=1, arr=a)[:,1:k+1]\n",
    "    a = np.apply_along_axis(f, axis=1, arr=a)\n",
    "    return a\n",
    "\n",
    "def extract_characteristics_from_stacks(images, images_advs, model, detector_name, net_name):\n",
    "    number_images = images.shape[0]\n",
    "\n",
    "    model_features = model.features\n",
    "    act_layers= [2,5,9,12,16,19,22,26,29,32,36,39,42]\n",
    "    fourier_act_layers = [9,16,22,29,36,42]\n",
    "\n",
    "    print('Extracting ' + detector_name + ' characteristic...')\n",
    "    if detector_name == 'LID':\n",
    "        batch_size = 11\n",
    "        if net_name == 'cif10':\n",
    "            k = 20\n",
    "        else:\n",
    "            k = 10\n",
    "\n",
    "        lids = []\n",
    "        lids_adv = []\n",
    "        lid_dim = len(act_layers)\n",
    "        shape = np.shape(images[0])\n",
    "\n",
    "        def estimate(i_batch):\n",
    "            start = i_batch * batch_size\n",
    "            end = np.minimum(len(images), (i_batch + 1) * batch_size)\n",
    "            n_feed = end - start\n",
    "            lid_batch       = np.zeros(shape=(n_feed, lid_dim))\n",
    "            lid_batch_adv   = np.zeros(shape=(n_feed, lid_dim))\n",
    "            batch= torch.Tensor(n_feed, shape[0], shape[1], shape[2])\n",
    "            batch_adv= torch.Tensor(n_feed, shape[0], shape[1], shape[2])\n",
    "            for j in range(n_feed):\n",
    "                batch[j,:,:,:] = images[start + j]\n",
    "                batch_adv[j,:,:,:] = images_advs[start + j]\n",
    "            batch = cifar_normalize(batch)\n",
    "            batch_adv = cifar_normalize(batch_adv)\n",
    "            X_act       = get_layer_feature_maps(batch.to(device), act_layers, model_features)\n",
    "            X_adv_act   = get_layer_feature_maps(batch_adv.to(device), act_layers, model_features)\n",
    "            for i in range(lid_dim):\n",
    "                X_act[i]       = np.asarray(X_act[i].cpu().detach().numpy()    , dtype=np.float32).reshape((n_feed, -1))\n",
    "                X_adv_act[i]   = np.asarray(X_adv_act[i].cpu().detach().numpy()  , dtype=np.float32).reshape((n_feed, -1))\n",
    "                lid_batch[:, i]       = mle_batch(X_act[i], X_act[i]      , k=k)\n",
    "                lid_batch_adv[:, i]   = mle_batch(X_act[i], X_adv_act[i]  , k=k)\n",
    "            return lid_batch, lid_batch_adv\n",
    "\n",
    "        n_batches = int(np.ceil(len(images) / float(batch_size)))\n",
    "        for i_batch in tqdm(range(n_batches)):\n",
    "            lid_batch, lid_batch_adv = estimate(i_batch)\n",
    "            lids.extend(lid_batch)\n",
    "            lids_adv.extend(lid_batch_adv)\n",
    "\n",
    "        characteristics       = np.asarray(lids, dtype=np.float32)\n",
    "        characteristics_adv   = np.asarray(lids_adv, dtype=np.float32)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"unknown detector\")\n",
    "\n",
    "    return characteristics, characteristics_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "853aebda-d1dc-4985-8e55-d286b4e754b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(IMG_SIZE, CSV_PATH, CLEAN_BASE, ADV_BASE_ROOT, TRAIN_CSV_FOR_MAH,\n",
    "            attack_method, detector, net):\n",
    "    OUT_CHAR_DIR = Path(f\"./data/characteristics/{IMG_SIZE}/\")\n",
    "    OUT_CHAR_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"Building stacks from CSV...\")\n",
    "    images_stack, advs_stack, rels = build_stacks_from_csv(CSV_PATH)\n",
    "    \n",
    "    assert images_stack.shape == advs_stack.shape, \"Clean/adversarial stacks must have same shape\"\n",
    "    print(\"Stack shapes:\", images_stack.shape)\n",
    "    \n",
    "    model = load_model_for_net(f'../01-CleanModel/Models/{IMG_SIZE}x{IMG_SIZE}/best_min_acc_vgg16_{IMG_SIZE}x{IMG_SIZE}_Model-2.pth')\n",
    "    \n",
    "    characteristics, characteristics_adv = extract_characteristics_from_stacks(images_stack, advs_stack, model, detector, net)\n",
    "    \n",
    "    prefix = f\"{net}_{attack_method}_{detector}\"\n",
    "    np.save(str(OUT_CHAR_DIR / (prefix + f\"_{IMG_SIZE}\")), characteristics)\n",
    "    np.save(str(OUT_CHAR_DIR / (prefix + f\"_{IMG_SIZE}_adv\")), characteristics_adv)\n",
    "    print(\"Saved characteristics:\", OUT_CHAR_DIR / prefix)\n",
    "    print(\"Saved characteristics adv:\", OUT_CHAR_DIR / (prefix + \"_adv\"))\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a649e95-4047-461e-a8cf-1acf6dbc1a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [02:58<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 32, 32])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/32x32/best_min_acc_vgg16_32x32_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:09<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\32\\inat_fgsm_LID\n",
      "Saved characteristics adv: data\\characteristics\\32\\inat_fgsm_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [00:22<00:00, 28.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 32, 32])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/32x32/best_min_acc_vgg16_32x32_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:10<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\32\\inat_bim_LID\n",
      "Saved characteristics adv: data\\characteristics\\32\\inat_bim_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [00:22<00:00, 28.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 32, 32])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/32x32/best_min_acc_vgg16_32x32_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:10<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\32\\inat_pgd_LID\n",
      "Saved characteristics adv: data\\characteristics\\32\\inat_pgd_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [00:22<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 32, 32])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/32x32/best_min_acc_vgg16_32x32_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:10<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\32\\inat_df_LID\n",
      "Saved characteristics adv: data\\characteristics\\32\\inat_df_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [00:25<00:00, 25.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 32, 32])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/32x32/best_min_acc_vgg16_32x32_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:11<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\32\\inat_cw_LID\n",
      "Saved characteristics adv: data\\characteristics\\32\\inat_cw_LID_adv\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 32\n",
    "CSV_PATH = Path(\"../02-AdvGenerate/Evaluate/common_success_details.csv\")\n",
    "CLEAN_BASE = Path(f\"../01-CleanModel/Dataset/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "ADV_BASE_ROOT = Path(f\"../02-AdvGenerate/generated_images-test/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "TRAIN_CSV_FOR_MAH = Path(\"../01-CleanModel/Dataset/clean_model_train.csv\") \n",
    "\n",
    "attack_methods = ['fgsm', 'bim', 'pgd', 'df', 'cw']  \n",
    "detector = \"LID\"  \n",
    "net = \"inat\" \n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    extract(IMG_SIZE, CSV_PATH, CLEAN_BASE, ADV_BASE_ROOT, TRAIN_CSV_FOR_MAH,  attack_method, detector, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ac2591b-837c-445d-9143-cf1ac352be9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [00:33<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 64, 64])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/64x64/best_min_acc_vgg16_64x64_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:35<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\64\\inat_fgsm_LID\n",
      "Saved characteristics adv: data\\characteristics\\64\\inat_fgsm_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [00:29<00:00, 21.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 64, 64])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/64x64/best_min_acc_vgg16_64x64_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:35<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\64\\inat_bim_LID\n",
      "Saved characteristics adv: data\\characteristics\\64\\inat_bim_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [00:30<00:00, 21.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 64, 64])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/64x64/best_min_acc_vgg16_64x64_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:35<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\64\\inat_pgd_LID\n",
      "Saved characteristics adv: data\\characteristics\\64\\inat_pgd_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [00:31<00:00, 20.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 64, 64])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/64x64/best_min_acc_vgg16_64x64_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:35<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\64\\inat_df_LID\n",
      "Saved characteristics adv: data\\characteristics\\64\\inat_df_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [00:26<00:00, 24.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 64, 64])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/64x64/best_min_acc_vgg16_64x64_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:35<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\64\\inat_cw_LID\n",
      "Saved characteristics adv: data\\characteristics\\64\\inat_cw_LID_adv\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 64\n",
    "CSV_PATH = Path(\"../02-AdvGenerate/Evaluate/common_success_details.csv\")\n",
    "CLEAN_BASE = Path(f\"../01-CleanModel/Dataset/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "ADV_BASE_ROOT = Path(f\"../02-AdvGenerate/generated_images-test/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "TRAIN_CSV_FOR_MAH = Path(\"../01-CleanModel/Dataset/clean_model_train.csv\") \n",
    "\n",
    "attack_methods = ['fgsm', 'bim', 'pgd', 'df', 'cw']  \n",
    "detector = \"LID\"  \n",
    "net = \"inat\" \n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    extract(IMG_SIZE, CSV_PATH, CLEAN_BASE, ADV_BASE_ROOT, TRAIN_CSV_FOR_MAH,  attack_method, detector, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe52cecd-aca3-44ac-93a3-bc8ddb111210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [01:01<00:00, 10.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 128, 128])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/128x128/best_min_acc_vgg16_128x128_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [02:34<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\128\\inat_fgsm_LID\n",
      "Saved characteristics adv: data\\characteristics\\128\\inat_fgsm_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [00:59<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 128, 128])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/128x128/best_min_acc_vgg16_128x128_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [02:33<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\128\\inat_bim_LID\n",
      "Saved characteristics adv: data\\characteristics\\128\\inat_bim_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [01:12<00:00,  8.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 128, 128])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/128x128/best_min_acc_vgg16_128x128_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [02:33<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\128\\inat_pgd_LID\n",
      "Saved characteristics adv: data\\characteristics\\128\\inat_pgd_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [01:08<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 128, 128])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/128x128/best_min_acc_vgg16_128x128_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [02:34<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\128\\inat_df_LID\n",
      "Saved characteristics adv: data\\characteristics\\128\\inat_df_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [01:04<00:00, 10.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 128, 128])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/128x128/best_min_acc_vgg16_128x128_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [02:32<00:00,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\128\\inat_cw_LID\n",
      "Saved characteristics adv: data\\characteristics\\128\\inat_cw_LID_adv\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 128\n",
    "CSV_PATH = Path(\"../02-AdvGenerate/Evaluate/common_success_details.csv\")\n",
    "CLEAN_BASE = Path(f\"../01-CleanModel/Dataset/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "ADV_BASE_ROOT = Path(f\"../02-AdvGenerate/generated_images-test/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "TRAIN_CSV_FOR_MAH = Path(\"../01-CleanModel/Dataset/clean_model_train.csv\") \n",
    "\n",
    "attack_methods = ['fgsm', 'bim', 'pgd', 'df', 'cw']  \n",
    "detector = \"LID\"  \n",
    "net = \"inat\" \n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    extract(IMG_SIZE, CSV_PATH, CLEAN_BASE, ADV_BASE_ROOT, TRAIN_CSV_FOR_MAH,  attack_method, detector, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "129ed931-e725-4bf2-9545-34e882becf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [01:19<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 256, 256])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/256x256/best_min_acc_vgg16_256x256_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [10:45<00:00, 10.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\256\\inat_fgsm_LID\n",
      "Saved characteristics adv: data\\characteristics\\256\\inat_fgsm_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [00:52<00:00, 12.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 256, 256])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/256x256/best_min_acc_vgg16_256x256_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [10:56<00:00, 11.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\256\\inat_bim_LID\n",
      "Saved characteristics adv: data\\characteristics\\256\\inat_bim_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [02:06<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 256, 256])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/256x256/best_min_acc_vgg16_256x256_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [10:48<00:00, 10.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\256\\inat_pgd_LID\n",
      "Saved characteristics adv: data\\characteristics\\256\\inat_pgd_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [01:48<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 256, 256])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/256x256/best_min_acc_vgg16_256x256_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [10:47<00:00, 10.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\256\\inat_df_LID\n",
      "Saved characteristics adv: data\\characteristics\\256\\inat_df_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [01:37<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 256, 256])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/256x256/best_min_acc_vgg16_256x256_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [11:05<00:00, 11.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\256\\inat_cw_LID\n",
      "Saved characteristics adv: data\\characteristics\\256\\inat_cw_LID_adv\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 256\n",
    "CSV_PATH = Path(\"../02-AdvGenerate/Evaluate/common_success_details.csv\")\n",
    "CLEAN_BASE = Path(f\"../01-CleanModel/Dataset/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "ADV_BASE_ROOT = Path(f\"../02-AdvGenerate/generated_images-test/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "TRAIN_CSV_FOR_MAH = Path(\"../01-CleanModel/Dataset/clean_model_train.csv\") \n",
    "\n",
    "attack_methods = ['fgsm', 'bim', 'pgd', 'df', 'cw']  \n",
    "detector = \"LID\"  \n",
    "net = \"inat\" \n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    extract(IMG_SIZE, CSV_PATH, CLEAN_BASE, ADV_BASE_ROOT, TRAIN_CSV_FOR_MAH,  attack_method, detector, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6e45512-7e08-4f00-9b4e-828e312f0ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [01:03<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 512, 512])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/512x512/best_min_acc_vgg16_512x512_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [53:50<00:00, 54.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\512\\inat_fgsm_LID\n",
      "Saved characteristics adv: data\\characteristics\\512\\inat_fgsm_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [01:01<00:00, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 512, 512])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/512x512/best_min_acc_vgg16_512x512_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [52:59<00:00, 53.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\512\\inat_bim_LID\n",
      "Saved characteristics adv: data\\characteristics\\512\\inat_bim_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [01:23<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 512, 512])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/512x512/best_min_acc_vgg16_512x512_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [53:01<00:00, 53.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\512\\inat_pgd_LID\n",
      "Saved characteristics adv: data\\characteristics\\512\\inat_pgd_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [01:19<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 512, 512])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/512x512/best_min_acc_vgg16_512x512_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [52:52<00:00, 53.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\512\\inat_df_LID\n",
      "Saved characteristics adv: data\\characteristics\\512\\inat_df_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [03:22<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 512, 512])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/512x512/best_min_acc_vgg16_512x512_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [53:10<00:00, 54.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\512\\inat_cw_LID\n",
      "Saved characteristics adv: data\\characteristics\\512\\inat_cw_LID_adv\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 512\n",
    "CSV_PATH = Path(\"../02-AdvGenerate/Evaluate/common_success_details.csv\")\n",
    "CLEAN_BASE = Path(f\"../01-CleanModel/Dataset/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "ADV_BASE_ROOT = Path(f\"../02-AdvGenerate/generated_images-test/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "TRAIN_CSV_FOR_MAH = Path(\"../01-CleanModel/Dataset/clean_model_train.csv\") \n",
    "\n",
    "attack_methods = ['fgsm', 'bim', 'pgd', 'df', 'cw']  \n",
    "detector = \"LID\"  \n",
    "net = \"inat\" \n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    extract(IMG_SIZE, CSV_PATH, CLEAN_BASE, ADV_BASE_ROOT, TRAIN_CSV_FOR_MAH,  attack_method, detector, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce2d0b-fe90-43ef-b671-179d326a7ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [03:56<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 1024, 1024])\n",
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to D:\\Users\\a1901443/.cache\\torch\\hub\\checkpoints\\vgg16_bn-6c64b313.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 528M/528M [00:13<00:00, 42.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint ../01-CleanModel/Models/1024x1024/best_min_acc_vgg16_1024x1024_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 59/59 [3:21:50<00:00, 205.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\1024\\inat_fgsm_LID\n",
      "Saved characteristics adv: data\\characteristics\\1024\\inat_fgsm_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [03:55<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 1024, 1024])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/1024x1024/best_min_acc_vgg16_1024x1024_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▍                                                                          | 4/59 [13:38<3:07:28, 204.52s/it]"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 1024\n",
    "CSV_PATH = Path(\"../02-AdvGenerate/Evaluate/common_success_details.csv\")\n",
    "CLEAN_BASE = Path(f\"../01-CleanModel/Dataset/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "ADV_BASE_ROOT = Path(f\"../02-AdvGenerate/generated_images-test/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "TRAIN_CSV_FOR_MAH = Path(\"../01-CleanModel/Dataset/clean_model_train.csv\") \n",
    "\n",
    "attack_methods = ['fgsm', 'bim', 'pgd', 'df', 'cw']  \n",
    "detector = \"LID\"  \n",
    "net = \"inat\" \n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    extract(IMG_SIZE, CSV_PATH, CLEAN_BASE, ADV_BASE_ROOT, TRAIN_CSV_FOR_MAH,  attack_method, detector, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa11664-aa84-4c21-b914-2fd19d17147b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [04:09<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 1024, 1024])\n",
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to D:\\Users\\a1901443/.cache\\torch\\hub\\checkpoints\\vgg16_bn-6c64b313.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 528M/528M [00:12<00:00, 44.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint ../01-CleanModel/Models/1024x1024/best_min_acc_vgg16_1024x1024_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 59/59 [3:20:29<00:00, 203.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\1024\\inat_bim_LID\n",
      "Saved characteristics adv: data\\characteristics\\1024\\inat_bim_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [04:01<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 1024, 1024])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/1024x1024/best_min_acc_vgg16_1024x1024_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 59/59 [3:21:13<00:00, 204.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\1024\\inat_pgd_LID\n",
      "Saved characteristics adv: data\\characteristics\\1024\\inat_pgd_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [04:36<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 1024, 1024])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/1024x1024/best_min_acc_vgg16_1024x1024_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 59/59 [3:21:07<00:00, 204.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\1024\\inat_df_LID\n",
      "Saved characteristics adv: data\\characteristics\\1024\\inat_df_LID_adv\n",
      "Done.\n",
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [03:09<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 1024, 1024])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/1024x1024/best_min_acc_vgg16_1024x1024_Model-2.pth (strict=True).\n",
      "Extracting LID characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 59/59 [3:21:07<00:00, 204.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\1024\\inat_cw_LID\n",
      "Saved characteristics adv: data\\characteristics\\1024\\inat_cw_LID_adv\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 1024\n",
    "CSV_PATH = Path(\"../02-AdvGenerate/Evaluate/common_success_details.csv\")\n",
    "CLEAN_BASE = Path(f\"../01-CleanModel/Dataset/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "ADV_BASE_ROOT = Path(f\"../02-AdvGenerate/generated_images-test/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "TRAIN_CSV_FOR_MAH = Path(\"../01-CleanModel/Dataset/clean_model_train.csv\") \n",
    "\n",
    "attack_methods = ['bim', 'pgd', 'df', 'cw']  \n",
    "detector = \"LID\"  \n",
    "net = \"inat\" \n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    extract(IMG_SIZE, CSV_PATH, CLEAN_BASE, ADV_BASE_ROOT, TRAIN_CSV_FOR_MAH,  attack_method, detector, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67331d1e-dd47-42ee-85e3-2436cf27d355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
