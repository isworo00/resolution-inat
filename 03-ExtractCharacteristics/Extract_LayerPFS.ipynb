{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d6f18f-296f-49d6-bfd3-988b6c7bfc2e",
   "metadata": {},
   "source": [
    "# Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9736871-4bd3-457e-be89-6053d3ce94a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from scipy.spatial.distance import cdist\n",
    "import sklearn\n",
    "import sklearn.covariance\n",
    "from PIL import Image\n",
    "from torchvision.models import VGG16_BN_Weights\n",
    "from torchvision import models, transforms\n",
    "from numpy.lib.format import open_memmap\n",
    "import gc\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "def load_clean_image_tensor(rel_path: str):\n",
    "    p = (CLEAN_BASE / str(rel_path).lstrip(\"/\"))\n",
    "    img = Image.open(p).convert(\"RGB\")\n",
    "    return to_tensor(img)  \n",
    "\n",
    "def load_adv_tensor_from_file(rel_path: str, adv_folder: Path):\n",
    "    p = adv_folder / str(rel_path).lstrip(\"/\").replace(\".jpg\", \".pt\")\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Adv file not found: {p}\")\n",
    "    t = torch.load(p) \n",
    "    if isinstance(t, tuple) or isinstance(t, list):\n",
    "        t = t[0]\n",
    "    if t.dim() == 4 and t.shape[0] == 1:\n",
    "        t = t.squeeze(0)\n",
    "    return t\n",
    "\n",
    "def build_stacks_from_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    adv_folder = ADV_BASE_ROOT / attack_method\n",
    "\n",
    "    clean_tensors = []\n",
    "    adv_tensors = []\n",
    "    rel_paths = []\n",
    "    skipped = 0\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Loading images and advs\"):\n",
    "        rel = row[\"rel_path\"]\n",
    "        try:\n",
    "            clean_t = load_clean_image_tensor(rel)\n",
    "        except Exception as e:\n",
    "            print(f\"Skip clean {rel}: {e}\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            adv_t = load_adv_tensor_from_file(rel, adv_folder)\n",
    "        except Exception as e:\n",
    "            print(f\"Skip adv {rel}: {e}\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        if clean_t.shape != adv_t.shape:\n",
    "            print ('Missmatch')\n",
    "\n",
    "        clean_tensors.append(clean_t)\n",
    "        adv_tensors.append(adv_t)\n",
    "        rel_paths.append(rel)\n",
    "\n",
    "    if len(clean_tensors) == 0:\n",
    "        raise RuntimeError(\"No pairs loaded. Check CSV paths and adv folder.\")\n",
    "\n",
    "    images_stack = torch.stack(clean_tensors)   \n",
    "    advs_stack = torch.stack(adv_tensors)       \n",
    "    print(f\"Built stacks: {len(clean_tensors)} pairs (skipped {skipped}).\")\n",
    "    return images_stack, advs_stack, rel_paths\n",
    "\n",
    "\n",
    "def load_model_for_net(checkpoint_path, strict=True):\n",
    "    print(\"Loading model...\")\n",
    "    \n",
    "    model = models.vgg16_bn(weights=VGG16_BN_Weights.IMAGENET1K_V1)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d((7,7))\n",
    "    model.classifier[6] = nn.Linear(4096, 7)\n",
    "    \n",
    "    ckpt = torch.load(checkpoint_path, map_location='cpu')  \n",
    "\n",
    "    if isinstance(ckpt, dict):\n",
    "        for candidate in (\"model_state\", \"model_state_dict\", \"state_dict\", \"state\"):\n",
    "            if candidate in ckpt:\n",
    "                state = ckpt[candidate]\n",
    "                break\n",
    "        else:\n",
    "            if all(isinstance(v, (torch.Tensor, type(None))) or hasattr(v, \"shape\") for v in ckpt.values()):\n",
    "                state = ckpt\n",
    "            else:\n",
    "                nested = None\n",
    "                for v in ckpt.values():\n",
    "                    if isinstance(v, dict):\n",
    "                        if nested is None or len(v) > len(nested):\n",
    "                            nested = v\n",
    "                state = nested if nested is not None else ckpt\n",
    "    else:\n",
    "        state = ckpt\n",
    "\n",
    "    if not isinstance(state, dict):\n",
    "        raise ValueError(f\"Checkpoint {checkpoint_path} does not contain a state-dict (found type: {type(state)})\")\n",
    "\n",
    "    keys = list(state.keys())\n",
    "    prefix = None\n",
    "    for p in (\"module.\", \"model.\"):\n",
    "        cnt = sum(1 for k in keys if k.startswith(p))\n",
    "        if cnt >= max(1, len(keys) // 2):\n",
    "            prefix = p\n",
    "            break\n",
    "\n",
    "    if prefix:\n",
    "        new_state = OrderedDict((k[len(prefix):], v) for k, v in state.items())\n",
    "    else:\n",
    "        new_state = state\n",
    "\n",
    "    try:\n",
    "        model.load_state_dict(new_state, strict=strict)\n",
    "        print(f\"Loaded checkpoint {checkpoint_path} (strict={strict}).\")\n",
    "    except Exception as e:\n",
    "        print(f\"Strict load failed: {e}. Trying non-strict load ...\")\n",
    "        res = model.load_state_dict(new_state, strict=False)\n",
    "        print(\"Loaded with strict=False. Missing keys:\", getattr(res, \"missing_keys\", None))\n",
    "        print(\"Unexpected keys:\", getattr(res, \"unexpected_keys\", None))\n",
    "\n",
    "    model = model.to(device).eval()\n",
    "    return model\n",
    "\n",
    "def get_layer_feature_maps(X, layers, model_features):\n",
    "    X_l = []\n",
    "    X = X.to(device)\n",
    "    for i in range(len(model_features)):\n",
    "        X = model_features[i](X)\n",
    "        if i in layers:\n",
    "            X_l.append(X)\n",
    "    return X_l\n",
    "\n",
    "def cifar_normalize(images, net_name='inat'):\n",
    "    if net_name == 'cif10':\n",
    "        images[:,0,:,:] = (images[:,0,:,:] - 0.4914)/0.2023\n",
    "        images[:,1,:,:] = (images[:,1,:,:] - 0.4822)/0.1994\n",
    "        images[:,2,:,:] = (images[:,2,:,:] - 0.4465)/0.2010\n",
    "    elif net_name == 'cif100':\n",
    "        images[:,0,:,:] = (images[:,0,:,:] - 0.5071)/0.2675\n",
    "        images[:,1,:,:] = (images[:,1,:,:] - 0.4867)/0.2565\n",
    "        images[:,2,:,:] = (images[:,2,:,:] - 0.4408)/0.2761\n",
    "    else:\n",
    "        MEAN = [0.4812775254249573, 0.4674863815307617, 0.4093940854072571]\n",
    "        STD  = [0.19709135591983795, 0.1933959424495697, 0.19051066040992737]\n",
    "        images[:,0,:,:] = (images[:,0,:,:] - MEAN[0]) / STD[0]\n",
    "        images[:,1,:,:] = (images[:,1,:,:] - MEAN[1]) / STD[1]\n",
    "        images[:,2,:,:] = (images[:,2,:,:] - MEAN[2]) / STD[2]\n",
    "    return images\n",
    "\n",
    "def calculate_fourier_spectrum(im, typ='MFS'):\n",
    "    im = im.float()\n",
    "    im = im.cpu().numpy()\n",
    "    fft = np.fft.fft2(im)\n",
    "    if typ == 'MFS':\n",
    "        fourier_spectrum = np.abs(fft)\n",
    "    elif typ == 'PFS':\n",
    "        fourier_spectrum = np.abs(np.angle(fft))\n",
    "    if net == 'cif100' and (attack_method in ('cw','df')):\n",
    "        fourier_spectrum *= 1/np.max(fourier_spectrum)\n",
    "    return fourier_spectrum\n",
    "\n",
    "def calculate_spectra(images, typ='MFS'):\n",
    "    fs = []\n",
    "    if isinstance(images, torch.Tensor):\n",
    "        images = [images[i] for i in range(images.shape[0])]\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        fourier_image = calculate_fourier_spectrum(image, typ=typ)\n",
    "        fs.append(fourier_image.flatten())\n",
    "    return fs\n",
    "\n",
    "def mle_batch(data, batch, k):\n",
    "    data = np.asarray(data, dtype=np.float32)\n",
    "    batch = np.asarray(batch, dtype=np.float32)\n",
    "    k = min(k, len(data)-1)\n",
    "    f = lambda v: - k / np.sum(np.log(v/v[-1]))\n",
    "    a = cdist(batch, data)\n",
    "    a = np.apply_along_axis(np.sort, axis=1, arr=a)[:,1:k+1]\n",
    "    a = np.apply_along_axis(f, axis=1, arr=a)\n",
    "    return a\n",
    "\n",
    "def extract_characteristics_from_stacks(images, images_advs, model, detector_name, net_name):\n",
    "    number_images = images.shape[0]\n",
    "\n",
    "    model_features = model.features\n",
    "    act_layers= [2,5,9,12,16,19,22,26,29,32,36,39,42]\n",
    "    fourier_act_layers = [9,16,22,29,36,42]\n",
    "\n",
    "    print('Extracting ' + detector_name + ' characteristic...')\n",
    "\n",
    "    if detector_name == 'InputMFS':\n",
    "        mfs = calculate_spectra(images)\n",
    "        mfs_advs = calculate_spectra(images_advs)\n",
    "        characteristics       = np.asarray(mfs, dtype=np.float32)\n",
    "        characteristics_adv   = np.asarray(mfs_advs, dtype=np.float32)\n",
    "\n",
    "    elif detector_name == 'InputPFS':\n",
    "        pfs = calculate_spectra(images, typ='PFS')\n",
    "        pfs_advs = calculate_spectra(images_advs, typ='PFS')\n",
    "        characteristics       = np.asarray(pfs, dtype=np.float32)\n",
    "        characteristics_adv   = np.asarray(pfs_advs, dtype=np.float32)\n",
    "\n",
    "    elif detector_name == 'LayerMFS':\n",
    "        mfs = []\n",
    "        mfs_advs = []\n",
    "        if net_name == 'cif100' and (attack_method in ('cw','df')):\n",
    "            layers = [42]\n",
    "        else:\n",
    "            layers = fourier_act_layers\n",
    "        for i in tqdm(range(number_images)):\n",
    "            image = images[i].unsqueeze_(0)\n",
    "            adv = images_advs[i].unsqueeze_(0)\n",
    "            image = cifar_normalize(image, net_name)\n",
    "            adv = cifar_normalize(adv, net_name)\n",
    "            image_feature_maps = get_layer_feature_maps(image.to(device), layers, model_features)\n",
    "            adv_feature_maps = get_layer_feature_maps(adv.to(device), layers, model_features)\n",
    "            fourier_maps = calculate_spectra(image_feature_maps)\n",
    "            fourier_maps_adv = calculate_spectra(adv_feature_maps)\n",
    "            mfs.append(np.hstack(fourier_maps))\n",
    "            mfs_advs.append(np.hstack(fourier_maps_adv))\n",
    "        characteristics       = np.asarray(mfs, dtype=np.float32)\n",
    "        characteristics_adv   = np.asarray(mfs_advs, dtype=np.float32)\n",
    "\n",
    "    elif detector_name == 'LayerPFS':\n",
    "        pfs = []\n",
    "        pfs_advs = []\n",
    "        if net_name == 'cif100' and (attack_method in ('cw','df')):\n",
    "            layers = [42]\n",
    "        else:\n",
    "            layers = fourier_act_layers\n",
    "        for i in tqdm(range(number_images)):\n",
    "            image = images[i].unsqueeze_(0)\n",
    "            adv = images_advs[i].unsqueeze_(0)\n",
    "            image = cifar_normalize(image, net_name)\n",
    "            adv = cifar_normalize(adv, net_name)\n",
    "            with torch.no_grad(): \n",
    "                image_feature_maps = get_layer_feature_maps(image.to(device), layers, model_features)\n",
    "                adv_feature_maps = get_layer_feature_maps(adv.to(device), layers, model_features)\n",
    "            fourier_maps = calculate_spectra(image_feature_maps, typ='PFS')\n",
    "            fourier_maps_adv = calculate_spectra(adv_feature_maps, typ='PFS')\n",
    "            pfs.append(np.hstack(fourier_maps))\n",
    "            pfs_advs.append(np.hstack(fourier_maps_adv))\n",
    "        characteristics       = np.asarray(pfs, dtype=np.float32)\n",
    "        characteristics_adv   = np.asarray(pfs_advs, dtype=np.float32)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"unknown detector\")\n",
    "\n",
    "    return characteristics, characteristics_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "853aebda-d1dc-4985-8e55-d286b4e754b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(IMG_SIZE, CSV_PATH, CLEAN_BASE, ADV_BASE_ROOT, TRAIN_CSV_FOR_MAH,\n",
    "            attack_method, detector, net):\n",
    "    OUT_CHAR_DIR = Path(f\"./data/characteristics/{IMG_SIZE}/\")\n",
    "    OUT_CHAR_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"Building stacks from CSV...\")\n",
    "    images_stack, advs_stack, rels = build_stacks_from_csv(CSV_PATH)\n",
    "    \n",
    "    assert images_stack.shape == advs_stack.shape, \"Clean/adversarial stacks must have same shape\"\n",
    "    print(\"Stack shapes:\", images_stack.shape)\n",
    "    \n",
    "    model = load_model_for_net(f'../01-CleanModel/Models/{IMG_SIZE}x{IMG_SIZE}/best_min_acc_vgg16_{IMG_SIZE}x{IMG_SIZE}_Model-2.pth')\n",
    "    \n",
    "    characteristics, characteristics_adv = extract_characteristics_from_stacks(images_stack, advs_stack, model, detector, net)\n",
    "    \n",
    "    prefix = f\"{net}_{attack_method}_{detector}\"\n",
    "    np.save(str(OUT_CHAR_DIR / (prefix + f\"_{IMG_SIZE}\")), characteristics)\n",
    "    np.save(str(OUT_CHAR_DIR / (prefix + f\"_{IMG_SIZE}_adv\")), characteristics_adv)\n",
    "    print(\"Saved characteristics:\", OUT_CHAR_DIR / prefix)\n",
    "    print(\"Saved characteristics adv:\", OUT_CHAR_DIR / (prefix + \"_adv\"))\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a649e95-4047-461e-a8cf-1acf6dbc1a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs:   8%|████▋                                                   | 54/649 [00:02<00:23, 25.04it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 32\n",
    "CSV_PATH = Path(\"../02-AdvGenerate/Evaluate/common_success_details.csv\")\n",
    "CLEAN_BASE = Path(f\"../01-CleanModel/Dataset/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "ADV_BASE_ROOT = Path(f\"../02-AdvGenerate/generated_images-test/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "TRAIN_CSV_FOR_MAH = Path(\"../01-CleanModel/Dataset/clean_model_train.csv\") \n",
    "\n",
    "attack_methods = ['fgsm', 'bim', 'pgd', 'df', 'cw']  \n",
    "detector = \"LayerPFS\"  \n",
    "net = \"inat\" \n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    extract(IMG_SIZE, CSV_PATH, CLEAN_BASE, ADV_BASE_ROOT, TRAIN_CSV_FOR_MAH,  attack_method, detector, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac2591b-837c-445d-9143-cf1ac352be9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "CSV_PATH = Path(\"../02-AdvGenerate/Evaluate/common_success_details.csv\")\n",
    "CLEAN_BASE = Path(f\"../01-CleanModel/Dataset/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "ADV_BASE_ROOT = Path(f\"../02-AdvGenerate/generated_images-test/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "TRAIN_CSV_FOR_MAH = Path(\"../01-CleanModel/Dataset/clean_model_train.csv\") \n",
    "\n",
    "attack_methods = ['fgsm', 'bim', 'pgd', 'df', 'cw']  \n",
    "detector = \"LayerPFS\"  \n",
    "net = \"inat\" \n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    extract(IMG_SIZE, CSV_PATH, CLEAN_BASE, ADV_BASE_ROOT, TRAIN_CSV_FOR_MAH,  attack_method, detector, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe52cecd-aca3-44ac-93a3-bc8ddb111210",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "CSV_PATH = Path(\"../02-AdvGenerate/Evaluate/common_success_details.csv\")\n",
    "CLEAN_BASE = Path(f\"../01-CleanModel/Dataset/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "ADV_BASE_ROOT = Path(f\"../02-AdvGenerate/generated_images-test/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "TRAIN_CSV_FOR_MAH = Path(\"../01-CleanModel/Dataset/clean_model_train.csv\") \n",
    "\n",
    "attack_methods = ['fgsm', 'bim', 'pgd', 'df', 'cw']  \n",
    "detector = \"LayerPFS\"  \n",
    "net = \"inat\" \n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    extract(IMG_SIZE, CSV_PATH, CLEAN_BASE, ADV_BASE_ROOT, TRAIN_CSV_FOR_MAH,  attack_method, detector, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ed931-e725-4bf2-9545-34e882becf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "CSV_PATH = Path(\"../02-AdvGenerate/Evaluate/common_success_details.csv\")\n",
    "CLEAN_BASE = Path(f\"../01-CleanModel/Dataset/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "ADV_BASE_ROOT = Path(f\"../02-AdvGenerate/generated_images-test/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "TRAIN_CSV_FOR_MAH = Path(\"../01-CleanModel/Dataset/clean_model_train.csv\") \n",
    "\n",
    "attack_methods = ['fgsm', 'bim', 'pgd', 'df', 'cw']  \n",
    "detector = \"LayerPFS\"  \n",
    "net = \"inat\" \n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    extract(IMG_SIZE, CSV_PATH, CLEAN_BASE, ADV_BASE_ROOT, TRAIN_CSV_FOR_MAH,  attack_method, detector, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7581a321-036a-421c-a693-b8e862301988",
   "metadata": {},
   "source": [
    "# Using memmap - Limited RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3caa216a-1139-4dae-bd1d-7ccb268ddee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_characteristics_from_stacks(images, images_advs, model, detector_name, net_name):\n",
    "    number_images = images.shape[0]\n",
    "\n",
    "    model_features = model.features\n",
    "    act_layers= [2,5,9,12,16,19,22,26,29,32,36,39,42]\n",
    "    fourier_act_layers = [9,16,22,29,36,42]\n",
    "\n",
    "    print('Extracting ' + detector_name + ' characteristic...')\n",
    "\n",
    "    use_mmap_out = IMG_SIZE in (512, 1024)\n",
    "    MEMMAP_DIR = Path(\"./memmap_cache\")\n",
    "    \n",
    "    MEMMAP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if detector_name == 'LayerMFS' or detector_name == 'LayerPFS':\n",
    "        typ = 'MFS' if detector_name == 'LayerMFS' else 'PFS'\n",
    "        if net_name == 'cif100' and (attack_method in ('cw','df')):\n",
    "            layers = [42]\n",
    "        else:\n",
    "            layers = fourier_act_layers\n",
    "\n",
    "        sample_t = images[0]\n",
    "        sample_tensor = sample_t.unsqueeze(0) if isinstance(sample_t, torch.Tensor) and sample_t.dim()==3 else torch.from_numpy(np.asarray(sample_t)).unsqueeze(0)\n",
    "        sample_norm = cifar_normalize(sample_tensor, net_name)\n",
    "        with torch.no_grad():\n",
    "            sample_maps = get_layer_feature_maps(sample_norm.to(device), layers, model_features)\n",
    "        sample_parts = []\n",
    "        for m in sample_maps:\n",
    "            m_single = m[0] if isinstance(m, torch.Tensor) and m.dim()==4 else (m if isinstance(m, torch.Tensor) else torch.from_numpy(np.asarray(m)))\n",
    "            sample_parts.append(calculate_fourier_spectrum(m_single.cpu(), typ=typ).flatten())\n",
    "        feat_dim = sum(p.size for p in sample_parts)\n",
    "\n",
    "        if use_mmap_out:\n",
    "            mm_path = MEMMAP_DIR / f\"char_{detector_name}_{IMG_SIZE}.npy\"\n",
    "            mm_path_adv = MEMMAP_DIR / f\"char_{detector_name}_{IMG_SIZE}_adv.npy\"\n",
    "            out_mm = open_memmap(str(mm_path), mode='w+', dtype=np.float32, shape=(number_images, feat_dim))\n",
    "            out_mm_adv = open_memmap(str(mm_path_adv), mode='w+', dtype=np.float32, shape=(number_images, feat_dim))\n",
    "\n",
    "            for i in tqdm(range(number_images)):\n",
    "                s = images[i]\n",
    "                a = images_advs[i]\n",
    "                s_t = s.unsqueeze(0) if isinstance(s, torch.Tensor) and s.dim()==3 else torch.from_numpy(np.asarray(s)).unsqueeze(0)\n",
    "                a_t = a.unsqueeze(0) if isinstance(a, torch.Tensor) and a.dim()==3 else torch.from_numpy(np.asarray(a)).unsqueeze(0)\n",
    "                s_t = cifar_normalize(s_t, net_name)\n",
    "                a_t = cifar_normalize(a_t, net_name)\n",
    "                with torch.no_grad():\n",
    "                    s_maps = get_layer_feature_maps(s_t.to(device), layers, model_features)\n",
    "                    a_maps = get_layer_feature_maps(a_t.to(device), layers, model_features)\n",
    "                s_parts = [calculate_fourier_spectrum(m[0].cpu(), typ=typ).flatten() for m in s_maps]\n",
    "                a_parts = [calculate_fourier_spectrum(m[0].cpu(), typ=typ).flatten() for m in a_maps]\n",
    "                out_mm[i, :] = np.hstack(s_parts).astype(np.float32)\n",
    "                out_mm_adv[i, :] = np.hstack(a_parts).astype(np.float32)\n",
    "\n",
    "                del s_maps, a_maps, s_parts, a_parts\n",
    "                if (i+1) % 50 == 0:\n",
    "                    out_mm.flush()\n",
    "                    out_mm_adv.flush()\n",
    "                    gc.collect()\n",
    "\n",
    "            out_mm.flush(); out_mm_adv.flush()\n",
    "            return out_mm, out_mm_adv\n",
    "    else:\n",
    "        raise ValueError(\"unknown detector\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a8db99-7159-4bab-aae2-9a377ee949b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 512\n",
    "CSV_PATH = Path(\"../02-AdvGenerate/Evaluate/common_success_details.csv\")\n",
    "CLEAN_BASE = Path(f\"../01-CleanModel/Dataset/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "ADV_BASE_ROOT = Path(f\"../02-AdvGenerate/generated_images-test/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "TRAIN_CSV_FOR_MAH = Path(\"../01-CleanModel/Dataset/clean_model_train.csv\") \n",
    "\n",
    "attack_methods = ['fgsm', 'bim', 'pgd', 'df', 'cw']  \n",
    "detector = \"LayerPFS\"  \n",
    "net = \"inat\" \n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    extract(IMG_SIZE, CSV_PATH, CLEAN_BASE, ADV_BASE_ROOT, TRAIN_CSV_FOR_MAH,  attack_method, detector, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d6613e-8550-480b-ab6a-c370abcdfb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 1024\n",
    "CSV_PATH = Path(\"../02-AdvGenerate/Evaluate/common_success_details.csv\")\n",
    "CLEAN_BASE = Path(f\"../01-CleanModel/Dataset/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "ADV_BASE_ROOT = Path(f\"../02-AdvGenerate/generated_images-test/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "TRAIN_CSV_FOR_MAH = Path(\"../01-CleanModel/Dataset/clean_model_train.csv\") \n",
    "\n",
    "attack_methods = ['fgsm', 'bim', 'pgd', 'df']  \n",
    "detector = \"LayerPFS\"  \n",
    "net = \"inat\" \n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    extract(IMG_SIZE, CSV_PATH, CLEAN_BASE, ADV_BASE_ROOT, TRAIN_CSV_FOR_MAH,  attack_method, detector, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28686030-6ece-4e75-b908-f3b5d7e6030b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building stacks from CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and advs: 100%|███████████████████████████████████████████████████████| 649/649 [02:52<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built stacks: 649 pairs (skipped 0).\n",
      "Stack shapes: torch.Size([649, 3, 1024, 1024])\n",
      "Loading model...\n",
      "Loaded checkpoint ../01-CleanModel/Models/1024x1024/best_min_acc_vgg16_1024x1024_Model-2.pth (strict=True).\n",
      "Extracting LayerPFS characteristic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 649/649 [5:30:18<00:00, 30.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved characteristics: data\\characteristics\\1024\\inat_cw_LayerPFS\n",
      "Saved characteristics adv: data\\characteristics\\1024\\inat_cw_LayerPFS_adv\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 1024\n",
    "CSV_PATH = Path(\"../02-AdvGenerate/Evaluate/common_success_details.csv\")\n",
    "CLEAN_BASE = Path(f\"../01-CleanModel/Dataset/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "ADV_BASE_ROOT = Path(f\"../02-AdvGenerate/generated_images-test/{IMG_SIZE}x{IMG_SIZE}\")\n",
    "TRAIN_CSV_FOR_MAH = Path(\"../01-CleanModel/Dataset/clean_model_train.csv\") \n",
    "\n",
    "attack_methods = ['cw']  \n",
    "detector = \"LayerPFS\"  \n",
    "net = \"inat\" \n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    extract(IMG_SIZE, CSV_PATH, CLEAN_BASE, ADV_BASE_ROOT, TRAIN_CSV_FOR_MAH,  attack_method, detector, net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
